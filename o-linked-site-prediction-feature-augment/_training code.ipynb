{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# function ConnectButton(){\n",
    "#     console.log(\"Connect pushed\");\n",
    "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
    "# }\n",
    "\n",
    "# setInterval(ConnectButton,60000);\n",
    "# '''\n",
    "\n",
    "# from google.colab import drive\n",
    "# from os import chdir\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# project_path = '/content/drive/MyDrive/Gproject/o-linked-site-prediction-feature-augment'\n",
    "# chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed for the reproducible result\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of initial proteins: 104\n",
      "['A2ABU4', 'A2AHJ4', 'A2AKB9', 'A2AQ25', 'E9Q1P8', 'E9Q5G3', 'O08537', 'O09061', 'O35303', 'O70263']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/integrated_features' # we will get names from the augmented proteins\n",
    "protein_names = [x.split('.')[0] for x in os.listdir(data_dir) if x.split('.')[1] == 'csv'] # get protein name list to be processed for building machine learning models\n",
    "print('the number of initial proteins:', len(protein_names))\n",
    "print(protein_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameter optimization by K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from ml_models import *\n",
    "\n",
    "epochs = 1000\n",
    "from keras.callbacks import EarlyStopping\n",
    "patience = 30\n",
    "callbacks = [EarlyStopping(patience=patience, restore_best_weights=True, monitor='val_loss')]\n",
    "\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters\n",
      "rnn_layers     : 1\n",
      "rnn_neurons    : 64\n",
      "dnn_layers     : 3\n",
      "dnn_neurons    : 64\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "initial_params = default_params.copy()\n",
    "initial_params.update({\n",
    "    'window_size'    : 10\n",
    "    })\n",
    "\n",
    "print('initial parameters')\n",
    "for key, value in initial_params.items():\n",
    "    print(f'{key:<14} : {value}')\n",
    "\n",
    "search_space = {\n",
    "    'rnn_layers'    : [1, 2, 3, 4, 5],\n",
    "    'rnn_neurons'   : [32, 64, 128, 256],\n",
    "    'dnn_layers'    : [1, 2, 3, 4, 5],\n",
    "    'dnn_neurons'   : [32, 64, 128, 256],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of augmented features: 498\n",
      "continuous features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'number_hydrophobic_0A',\n",
       " 1: 'number_hydrophilic_0A',\n",
       " 2: 'number_polar_0A',\n",
       " 3: 'number_aromatic_0A',\n",
       " 4: 'number_aliphatic_0A',\n",
       " 5: 'number_charged_0A',\n",
       " 6: 'number_positive_0A',\n",
       " 7: 'number_negative_0A',\n",
       " 8: 'number_gly_0A',\n",
       " 9: 'number_very_small_0A',\n",
       " 10: 'number_small_0A',\n",
       " 11: 'number_normal_0A',\n",
       " 12: 'number_long_0A',\n",
       " 13: 'number_pro_0A',\n",
       " 14: 'number_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 15: 'number_b_polar_uncharged_with_amide_0A',\n",
       " 16: 'number_d_negatively_charged_polar_0A',\n",
       " 17: 'number_e_non_polar_suffered_0A',\n",
       " 18: 'number_f_non_polar_aromatic_0A',\n",
       " 19: 'number_ala_0A',\n",
       " 20: 'number_cys_0A',\n",
       " 21: 'number_asp_0A',\n",
       " 22: 'number_glu_0A',\n",
       " 23: 'number_phe_0A',\n",
       " 24: 'number_his_0A',\n",
       " 25: 'number_ile_0A',\n",
       " 26: 'number_lys_0A',\n",
       " 27: 'number_leu_0A',\n",
       " 28: 'number_met_0A',\n",
       " 29: 'number_asn_0A',\n",
       " 30: 'number_gln_0A',\n",
       " 31: 'number_arg_0A',\n",
       " 32: 'number_ser_0A',\n",
       " 33: 'number_thr_0A',\n",
       " 34: 'number_val_0A',\n",
       " 35: 'number_trp_0A',\n",
       " 36: 'number_tyr_0A',\n",
       " 37: 'sasa_hydrophobic_0A',\n",
       " 38: 'sasa_hydrophilic_0A',\n",
       " 39: 'sasa_polar_0A',\n",
       " 40: 'sasa_aromatic_0A',\n",
       " 41: 'sasa_aliphatic_0A',\n",
       " 42: 'sasa_charged_0A',\n",
       " 43: 'sasa_positive_0A',\n",
       " 44: 'sasa_negative_0A',\n",
       " 45: 'sasa_gly_0A',\n",
       " 46: 'sasa_very_small_0A',\n",
       " 47: 'sasa_small_0A',\n",
       " 48: 'sasa_normal_0A',\n",
       " 49: 'sasa_long_0A',\n",
       " 50: 'sasa_pro_0A',\n",
       " 51: 'sasa_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 52: 'sasa_b_polar_uncharged_with_amide_0A',\n",
       " 53: 'sasa_d_negatively_charged_polar_0A',\n",
       " 54: 'sasa_e_non_polar_suffered_0A',\n",
       " 55: 'sasa_f_non_polar_aromatic_0A',\n",
       " 56: 'sasa_ala_0A',\n",
       " 57: 'sasa_cys_0A',\n",
       " 58: 'sasa_asp_0A',\n",
       " 59: 'sasa_glu_0A',\n",
       " 60: 'sasa_phe_0A',\n",
       " 61: 'sasa_his_0A',\n",
       " 62: 'sasa_ile_0A',\n",
       " 63: 'sasa_lys_0A',\n",
       " 64: 'sasa_leu_0A',\n",
       " 65: 'sasa_met_0A',\n",
       " 66: 'sasa_asn_0A',\n",
       " 67: 'sasa_gln_0A',\n",
       " 68: 'sasa_arg_0A',\n",
       " 69: 'sasa_ser_0A',\n",
       " 70: 'sasa_thr_0A',\n",
       " 71: 'sasa_val_0A',\n",
       " 72: 'sasa_trp_0A',\n",
       " 73: 'sasa_tyr_0A',\n",
       " 74: 'sasa_back_0A',\n",
       " 75: 'sasa_side_0A',\n",
       " 76: 'sasa_target_ser_thr_0A',\n",
       " 77: 'net_charge_all_0A',\n",
       " 78: 'net_charge_backbone_0A',\n",
       " 79: 'net_charge_sidechain_0A',\n",
       " 80: 'net_charge_all_exposed_0A',\n",
       " 81: 'net_charge_backbone_exposed_0A',\n",
       " 82: 'net_charge_sidechain_exposed_0A',\n",
       " 83: 'number_hydrophobic_5A',\n",
       " 84: 'number_hydrophilic_5A',\n",
       " 85: 'number_polar_5A',\n",
       " 86: 'number_aromatic_5A',\n",
       " 87: 'number_aliphatic_5A',\n",
       " 88: 'number_charged_5A',\n",
       " 89: 'number_positive_5A',\n",
       " 90: 'number_negative_5A',\n",
       " 91: 'number_gly_5A',\n",
       " 92: 'number_very_small_5A',\n",
       " 93: 'number_small_5A',\n",
       " 94: 'number_normal_5A',\n",
       " 95: 'number_long_5A',\n",
       " 96: 'number_pro_5A',\n",
       " 97: 'number_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 98: 'number_b_polar_uncharged_with_amide_5A',\n",
       " 99: 'number_d_negatively_charged_polar_5A',\n",
       " 100: 'number_e_non_polar_suffered_5A',\n",
       " 101: 'number_f_non_polar_aromatic_5A',\n",
       " 102: 'number_ala_5A',\n",
       " 103: 'number_cys_5A',\n",
       " 104: 'number_asp_5A',\n",
       " 105: 'number_glu_5A',\n",
       " 106: 'number_phe_5A',\n",
       " 107: 'number_his_5A',\n",
       " 108: 'number_ile_5A',\n",
       " 109: 'number_lys_5A',\n",
       " 110: 'number_leu_5A',\n",
       " 111: 'number_met_5A',\n",
       " 112: 'number_asn_5A',\n",
       " 113: 'number_gln_5A',\n",
       " 114: 'number_arg_5A',\n",
       " 115: 'number_ser_5A',\n",
       " 116: 'number_thr_5A',\n",
       " 117: 'number_val_5A',\n",
       " 118: 'number_trp_5A',\n",
       " 119: 'number_tyr_5A',\n",
       " 120: 'sasa_hydrophobic_5A',\n",
       " 121: 'sasa_hydrophilic_5A',\n",
       " 122: 'sasa_polar_5A',\n",
       " 123: 'sasa_aromatic_5A',\n",
       " 124: 'sasa_aliphatic_5A',\n",
       " 125: 'sasa_charged_5A',\n",
       " 126: 'sasa_positive_5A',\n",
       " 127: 'sasa_negative_5A',\n",
       " 128: 'sasa_gly_5A',\n",
       " 129: 'sasa_very_small_5A',\n",
       " 130: 'sasa_small_5A',\n",
       " 131: 'sasa_normal_5A',\n",
       " 132: 'sasa_long_5A',\n",
       " 133: 'sasa_pro_5A',\n",
       " 134: 'sasa_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 135: 'sasa_b_polar_uncharged_with_amide_5A',\n",
       " 136: 'sasa_d_negatively_charged_polar_5A',\n",
       " 137: 'sasa_e_non_polar_suffered_5A',\n",
       " 138: 'sasa_f_non_polar_aromatic_5A',\n",
       " 139: 'sasa_ala_5A',\n",
       " 140: 'sasa_cys_5A',\n",
       " 141: 'sasa_asp_5A',\n",
       " 142: 'sasa_glu_5A',\n",
       " 143: 'sasa_phe_5A',\n",
       " 144: 'sasa_his_5A',\n",
       " 145: 'sasa_ile_5A',\n",
       " 146: 'sasa_lys_5A',\n",
       " 147: 'sasa_leu_5A',\n",
       " 148: 'sasa_met_5A',\n",
       " 149: 'sasa_asn_5A',\n",
       " 150: 'sasa_gln_5A',\n",
       " 151: 'sasa_arg_5A',\n",
       " 152: 'sasa_ser_5A',\n",
       " 153: 'sasa_thr_5A',\n",
       " 154: 'sasa_val_5A',\n",
       " 155: 'sasa_trp_5A',\n",
       " 156: 'sasa_tyr_5A',\n",
       " 157: 'sasa_back_5A',\n",
       " 158: 'sasa_side_5A',\n",
       " 159: 'sasa_target_ser_thr_5A',\n",
       " 160: 'net_charge_all_5A',\n",
       " 161: 'net_charge_backbone_5A',\n",
       " 162: 'net_charge_sidechain_5A',\n",
       " 163: 'net_charge_all_exposed_5A',\n",
       " 164: 'net_charge_backbone_exposed_5A',\n",
       " 165: 'net_charge_sidechain_exposed_5A',\n",
       " 166: 'number_hydrophobic_10A',\n",
       " 167: 'number_hydrophilic_10A',\n",
       " 168: 'number_polar_10A',\n",
       " 169: 'number_aromatic_10A',\n",
       " 170: 'number_aliphatic_10A',\n",
       " 171: 'number_charged_10A',\n",
       " 172: 'number_positive_10A',\n",
       " 173: 'number_negative_10A',\n",
       " 174: 'number_gly_10A',\n",
       " 175: 'number_very_small_10A',\n",
       " 176: 'number_small_10A',\n",
       " 177: 'number_normal_10A',\n",
       " 178: 'number_long_10A',\n",
       " 179: 'number_pro_10A',\n",
       " 180: 'number_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 181: 'number_b_polar_uncharged_with_amide_10A',\n",
       " 182: 'number_d_negatively_charged_polar_10A',\n",
       " 183: 'number_e_non_polar_suffered_10A',\n",
       " 184: 'number_f_non_polar_aromatic_10A',\n",
       " 185: 'number_ala_10A',\n",
       " 186: 'number_cys_10A',\n",
       " 187: 'number_asp_10A',\n",
       " 188: 'number_glu_10A',\n",
       " 189: 'number_phe_10A',\n",
       " 190: 'number_his_10A',\n",
       " 191: 'number_ile_10A',\n",
       " 192: 'number_lys_10A',\n",
       " 193: 'number_leu_10A',\n",
       " 194: 'number_met_10A',\n",
       " 195: 'number_asn_10A',\n",
       " 196: 'number_gln_10A',\n",
       " 197: 'number_arg_10A',\n",
       " 198: 'number_ser_10A',\n",
       " 199: 'number_thr_10A',\n",
       " 200: 'number_val_10A',\n",
       " 201: 'number_trp_10A',\n",
       " 202: 'number_tyr_10A',\n",
       " 203: 'sasa_hydrophobic_10A',\n",
       " 204: 'sasa_hydrophilic_10A',\n",
       " 205: 'sasa_polar_10A',\n",
       " 206: 'sasa_aromatic_10A',\n",
       " 207: 'sasa_aliphatic_10A',\n",
       " 208: 'sasa_charged_10A',\n",
       " 209: 'sasa_positive_10A',\n",
       " 210: 'sasa_negative_10A',\n",
       " 211: 'sasa_gly_10A',\n",
       " 212: 'sasa_very_small_10A',\n",
       " 213: 'sasa_small_10A',\n",
       " 214: 'sasa_normal_10A',\n",
       " 215: 'sasa_long_10A',\n",
       " 216: 'sasa_pro_10A',\n",
       " 217: 'sasa_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 218: 'sasa_b_polar_uncharged_with_amide_10A',\n",
       " 219: 'sasa_d_negatively_charged_polar_10A',\n",
       " 220: 'sasa_e_non_polar_suffered_10A',\n",
       " 221: 'sasa_f_non_polar_aromatic_10A',\n",
       " 222: 'sasa_ala_10A',\n",
       " 223: 'sasa_cys_10A',\n",
       " 224: 'sasa_asp_10A',\n",
       " 225: 'sasa_glu_10A',\n",
       " 226: 'sasa_phe_10A',\n",
       " 227: 'sasa_his_10A',\n",
       " 228: 'sasa_ile_10A',\n",
       " 229: 'sasa_lys_10A',\n",
       " 230: 'sasa_leu_10A',\n",
       " 231: 'sasa_met_10A',\n",
       " 232: 'sasa_asn_10A',\n",
       " 233: 'sasa_gln_10A',\n",
       " 234: 'sasa_arg_10A',\n",
       " 235: 'sasa_ser_10A',\n",
       " 236: 'sasa_thr_10A',\n",
       " 237: 'sasa_val_10A',\n",
       " 238: 'sasa_trp_10A',\n",
       " 239: 'sasa_tyr_10A',\n",
       " 240: 'sasa_back_10A',\n",
       " 241: 'sasa_side_10A',\n",
       " 242: 'sasa_target_ser_thr_10A',\n",
       " 243: 'net_charge_all_10A',\n",
       " 244: 'net_charge_backbone_10A',\n",
       " 245: 'net_charge_sidechain_10A',\n",
       " 246: 'net_charge_all_exposed_10A',\n",
       " 247: 'net_charge_backbone_exposed_10A',\n",
       " 248: 'net_charge_sidechain_exposed_10A',\n",
       " 249: 'number_hydrophobic_15A',\n",
       " 250: 'number_hydrophilic_15A',\n",
       " 251: 'number_polar_15A',\n",
       " 252: 'number_aromatic_15A',\n",
       " 253: 'number_aliphatic_15A',\n",
       " 254: 'number_charged_15A',\n",
       " 255: 'number_positive_15A',\n",
       " 256: 'number_negative_15A',\n",
       " 257: 'number_gly_15A',\n",
       " 258: 'number_very_small_15A',\n",
       " 259: 'number_small_15A',\n",
       " 260: 'number_normal_15A',\n",
       " 261: 'number_long_15A',\n",
       " 262: 'number_pro_15A',\n",
       " 263: 'number_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 264: 'number_b_polar_uncharged_with_amide_15A',\n",
       " 265: 'number_d_negatively_charged_polar_15A',\n",
       " 266: 'number_e_non_polar_suffered_15A',\n",
       " 267: 'number_f_non_polar_aromatic_15A',\n",
       " 268: 'number_ala_15A',\n",
       " 269: 'number_cys_15A',\n",
       " 270: 'number_asp_15A',\n",
       " 271: 'number_glu_15A',\n",
       " 272: 'number_phe_15A',\n",
       " 273: 'number_his_15A',\n",
       " 274: 'number_ile_15A',\n",
       " 275: 'number_lys_15A',\n",
       " 276: 'number_leu_15A',\n",
       " 277: 'number_met_15A',\n",
       " 278: 'number_asn_15A',\n",
       " 279: 'number_gln_15A',\n",
       " 280: 'number_arg_15A',\n",
       " 281: 'number_ser_15A',\n",
       " 282: 'number_thr_15A',\n",
       " 283: 'number_val_15A',\n",
       " 284: 'number_trp_15A',\n",
       " 285: 'number_tyr_15A',\n",
       " 286: 'sasa_hydrophobic_15A',\n",
       " 287: 'sasa_hydrophilic_15A',\n",
       " 288: 'sasa_polar_15A',\n",
       " 289: 'sasa_aromatic_15A',\n",
       " 290: 'sasa_aliphatic_15A',\n",
       " 291: 'sasa_charged_15A',\n",
       " 292: 'sasa_positive_15A',\n",
       " 293: 'sasa_negative_15A',\n",
       " 294: 'sasa_gly_15A',\n",
       " 295: 'sasa_very_small_15A',\n",
       " 296: 'sasa_small_15A',\n",
       " 297: 'sasa_normal_15A',\n",
       " 298: 'sasa_long_15A',\n",
       " 299: 'sasa_pro_15A',\n",
       " 300: 'sasa_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 301: 'sasa_b_polar_uncharged_with_amide_15A',\n",
       " 302: 'sasa_d_negatively_charged_polar_15A',\n",
       " 303: 'sasa_e_non_polar_suffered_15A',\n",
       " 304: 'sasa_f_non_polar_aromatic_15A',\n",
       " 305: 'sasa_ala_15A',\n",
       " 306: 'sasa_cys_15A',\n",
       " 307: 'sasa_asp_15A',\n",
       " 308: 'sasa_glu_15A',\n",
       " 309: 'sasa_phe_15A',\n",
       " 310: 'sasa_his_15A',\n",
       " 311: 'sasa_ile_15A',\n",
       " 312: 'sasa_lys_15A',\n",
       " 313: 'sasa_leu_15A',\n",
       " 314: 'sasa_met_15A',\n",
       " 315: 'sasa_asn_15A',\n",
       " 316: 'sasa_gln_15A',\n",
       " 317: 'sasa_arg_15A',\n",
       " 318: 'sasa_ser_15A',\n",
       " 319: 'sasa_thr_15A',\n",
       " 320: 'sasa_val_15A',\n",
       " 321: 'sasa_trp_15A',\n",
       " 322: 'sasa_tyr_15A',\n",
       " 323: 'sasa_back_15A',\n",
       " 324: 'sasa_side_15A',\n",
       " 325: 'sasa_target_ser_thr_15A',\n",
       " 326: 'net_charge_all_15A',\n",
       " 327: 'net_charge_backbone_15A',\n",
       " 328: 'net_charge_sidechain_15A',\n",
       " 329: 'net_charge_all_exposed_15A',\n",
       " 330: 'net_charge_backbone_exposed_15A',\n",
       " 331: 'net_charge_sidechain_exposed_15A',\n",
       " 332: 'number_hydrophobic_20A',\n",
       " 333: 'number_hydrophilic_20A',\n",
       " 334: 'number_polar_20A',\n",
       " 335: 'number_aromatic_20A',\n",
       " 336: 'number_aliphatic_20A',\n",
       " 337: 'number_charged_20A',\n",
       " 338: 'number_positive_20A',\n",
       " 339: 'number_negative_20A',\n",
       " 340: 'number_gly_20A',\n",
       " 341: 'number_very_small_20A',\n",
       " 342: 'number_small_20A',\n",
       " 343: 'number_normal_20A',\n",
       " 344: 'number_long_20A',\n",
       " 345: 'number_pro_20A',\n",
       " 346: 'number_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 347: 'number_b_polar_uncharged_with_amide_20A',\n",
       " 348: 'number_d_negatively_charged_polar_20A',\n",
       " 349: 'number_e_non_polar_suffered_20A',\n",
       " 350: 'number_f_non_polar_aromatic_20A',\n",
       " 351: 'number_ala_20A',\n",
       " 352: 'number_cys_20A',\n",
       " 353: 'number_asp_20A',\n",
       " 354: 'number_glu_20A',\n",
       " 355: 'number_phe_20A',\n",
       " 356: 'number_his_20A',\n",
       " 357: 'number_ile_20A',\n",
       " 358: 'number_lys_20A',\n",
       " 359: 'number_leu_20A',\n",
       " 360: 'number_met_20A',\n",
       " 361: 'number_asn_20A',\n",
       " 362: 'number_gln_20A',\n",
       " 363: 'number_arg_20A',\n",
       " 364: 'number_ser_20A',\n",
       " 365: 'number_thr_20A',\n",
       " 366: 'number_val_20A',\n",
       " 367: 'number_trp_20A',\n",
       " 368: 'number_tyr_20A',\n",
       " 369: 'sasa_hydrophobic_20A',\n",
       " 370: 'sasa_hydrophilic_20A',\n",
       " 371: 'sasa_polar_20A',\n",
       " 372: 'sasa_aromatic_20A',\n",
       " 373: 'sasa_aliphatic_20A',\n",
       " 374: 'sasa_charged_20A',\n",
       " 375: 'sasa_positive_20A',\n",
       " 376: 'sasa_negative_20A',\n",
       " 377: 'sasa_gly_20A',\n",
       " 378: 'sasa_very_small_20A',\n",
       " 379: 'sasa_small_20A',\n",
       " 380: 'sasa_normal_20A',\n",
       " 381: 'sasa_long_20A',\n",
       " 382: 'sasa_pro_20A',\n",
       " 383: 'sasa_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 384: 'sasa_b_polar_uncharged_with_amide_20A',\n",
       " 385: 'sasa_d_negatively_charged_polar_20A',\n",
       " 386: 'sasa_e_non_polar_suffered_20A',\n",
       " 387: 'sasa_f_non_polar_aromatic_20A',\n",
       " 388: 'sasa_ala_20A',\n",
       " 389: 'sasa_cys_20A',\n",
       " 390: 'sasa_asp_20A',\n",
       " 391: 'sasa_glu_20A',\n",
       " 392: 'sasa_phe_20A',\n",
       " 393: 'sasa_his_20A',\n",
       " 394: 'sasa_ile_20A',\n",
       " 395: 'sasa_lys_20A',\n",
       " 396: 'sasa_leu_20A',\n",
       " 397: 'sasa_met_20A',\n",
       " 398: 'sasa_asn_20A',\n",
       " 399: 'sasa_gln_20A',\n",
       " 400: 'sasa_arg_20A',\n",
       " 401: 'sasa_ser_20A',\n",
       " 402: 'sasa_thr_20A',\n",
       " 403: 'sasa_val_20A',\n",
       " 404: 'sasa_trp_20A',\n",
       " 405: 'sasa_tyr_20A',\n",
       " 406: 'sasa_back_20A',\n",
       " 407: 'sasa_side_20A',\n",
       " 408: 'sasa_target_ser_thr_20A',\n",
       " 409: 'net_charge_all_20A',\n",
       " 410: 'net_charge_backbone_20A',\n",
       " 411: 'net_charge_sidechain_20A',\n",
       " 412: 'net_charge_all_exposed_20A',\n",
       " 413: 'net_charge_backbone_exposed_20A',\n",
       " 414: 'net_charge_sidechain_exposed_20A',\n",
       " 415: 'number_hydrophobic_25A',\n",
       " 416: 'number_hydrophilic_25A',\n",
       " 417: 'number_polar_25A',\n",
       " 418: 'number_aromatic_25A',\n",
       " 419: 'number_aliphatic_25A',\n",
       " 420: 'number_charged_25A',\n",
       " 421: 'number_positive_25A',\n",
       " 422: 'number_negative_25A',\n",
       " 423: 'number_gly_25A',\n",
       " 424: 'number_very_small_25A',\n",
       " 425: 'number_small_25A',\n",
       " 426: 'number_normal_25A',\n",
       " 427: 'number_long_25A',\n",
       " 428: 'number_pro_25A',\n",
       " 429: 'number_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 430: 'number_b_polar_uncharged_with_amide_25A',\n",
       " 431: 'number_d_negatively_charged_polar_25A',\n",
       " 432: 'number_e_non_polar_suffered_25A',\n",
       " 433: 'number_f_non_polar_aromatic_25A',\n",
       " 434: 'number_ala_25A',\n",
       " 435: 'number_cys_25A',\n",
       " 436: 'number_asp_25A',\n",
       " 437: 'number_glu_25A',\n",
       " 438: 'number_phe_25A',\n",
       " 439: 'number_his_25A',\n",
       " 440: 'number_ile_25A',\n",
       " 441: 'number_lys_25A',\n",
       " 442: 'number_leu_25A',\n",
       " 443: 'number_met_25A',\n",
       " 444: 'number_asn_25A',\n",
       " 445: 'number_gln_25A',\n",
       " 446: 'number_arg_25A',\n",
       " 447: 'number_ser_25A',\n",
       " 448: 'number_thr_25A',\n",
       " 449: 'number_val_25A',\n",
       " 450: 'number_trp_25A',\n",
       " 451: 'number_tyr_25A',\n",
       " 452: 'sasa_hydrophobic_25A',\n",
       " 453: 'sasa_hydrophilic_25A',\n",
       " 454: 'sasa_polar_25A',\n",
       " 455: 'sasa_aromatic_25A',\n",
       " 456: 'sasa_aliphatic_25A',\n",
       " 457: 'sasa_charged_25A',\n",
       " 458: 'sasa_positive_25A',\n",
       " 459: 'sasa_negative_25A',\n",
       " 460: 'sasa_gly_25A',\n",
       " 461: 'sasa_very_small_25A',\n",
       " 462: 'sasa_small_25A',\n",
       " 463: 'sasa_normal_25A',\n",
       " 464: 'sasa_long_25A',\n",
       " 465: 'sasa_pro_25A',\n",
       " 466: 'sasa_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 467: 'sasa_b_polar_uncharged_with_amide_25A',\n",
       " 468: 'sasa_d_negatively_charged_polar_25A',\n",
       " 469: 'sasa_e_non_polar_suffered_25A',\n",
       " 470: 'sasa_f_non_polar_aromatic_25A',\n",
       " 471: 'sasa_ala_25A',\n",
       " 472: 'sasa_cys_25A',\n",
       " 473: 'sasa_asp_25A',\n",
       " 474: 'sasa_glu_25A',\n",
       " 475: 'sasa_phe_25A',\n",
       " 476: 'sasa_his_25A',\n",
       " 477: 'sasa_ile_25A',\n",
       " 478: 'sasa_lys_25A',\n",
       " 479: 'sasa_leu_25A',\n",
       " 480: 'sasa_met_25A',\n",
       " 481: 'sasa_asn_25A',\n",
       " 482: 'sasa_gln_25A',\n",
       " 483: 'sasa_arg_25A',\n",
       " 484: 'sasa_ser_25A',\n",
       " 485: 'sasa_thr_25A',\n",
       " 486: 'sasa_val_25A',\n",
       " 487: 'sasa_trp_25A',\n",
       " 488: 'sasa_tyr_25A',\n",
       " 489: 'sasa_back_25A',\n",
       " 490: 'sasa_side_25A',\n",
       " 491: 'sasa_target_ser_thr_25A',\n",
       " 492: 'net_charge_all_25A',\n",
       " 493: 'net_charge_backbone_25A',\n",
       " 494: 'net_charge_sidechain_25A',\n",
       " 495: 'net_charge_all_exposed_25A',\n",
       " 496: 'net_charge_backbone_exposed_25A',\n",
       " 497: 'net_charge_sidechain_exposed_25A'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:\n",
      "{0: 'residue'}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'LSTM_UP'\n",
    "\n",
    "basic_columns = dict(pd.read_csv('./data/basic_columns.csv', header=0).values.squeeze())\n",
    "print('# of augmented features:', len(basic_columns))\n",
    "\n",
    "# set continuous input features\n",
    "x_cts = []\n",
    "print('continuous features:')\n",
    "display(dict(zip(range(len(x_cts)), x_cts)))\n",
    "\n",
    "# set categorical input features\n",
    "x_cat = ['residue']\n",
    "print('categorical features:')\n",
    "print(dict(zip(range(len(x_cat)), x_cat)))\n",
    "\n",
    "# input features\n",
    "x_var = x_cts + x_cat\n",
    "\n",
    "# set continuos output feature\n",
    "y_cts = []\n",
    "\n",
    "# set categorical output feature\n",
    "y_cat = ['positivity']\n",
    "\n",
    "# output features\n",
    "y_var = y_cts + y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build amino acid sequence dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model training with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_layers     : [1, 2, 3, 4, 5]\n",
      "rnn_neurons    : [32, 64, 128, 256]\n",
      "dnn_layers     : [1, 2, 3, 4, 5]\n",
      "dnn_neurons    : [32, 64, 128, 256]\n",
      "learning_rate  : [0.0001, 0.001, 0.01]\n",
      "data x shape: (11858, 21, 73)\n",
      "data y shape: (11858, 2)\n",
      "class y counts: [11429   429]\n",
      "class y ratio: [0.9638 0.0362]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[12], line 81\u001b[0m\n",
      "\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path) \u001b[38;5;129;01mor\u001b[39;00m model_update:\n",
      "\u001b[0;32m     80\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;32m---> 81\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[0;32m     82\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     83\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y_kf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     84\u001b[0m     time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;32m     85\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((time_end \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n",
      "\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n",
      "\u001b[0;32m   1562\u001b[0m ):\n",
      "\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n",
      "\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n",
      "\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n",
      "\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n",
      "\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n",
      "\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\u001b[0;32m   2494\u001b[0m   (graph_function,\n",
      "\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\u001b[0;32m   1865\u001b[0m     args,\n",
      "\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n",
      "\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n",
      "\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n",
      "\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n",
      "\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update  = False\n",
    "\n",
    "params = initial_params.copy()\n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "model_id = 1\n",
    "verbose = 0\n",
    "for param_name, space in search_space.items():\n",
    "    for point in space:\n",
    "        clear_output(wait=True)\n",
    "        display(METRIC_MEAN)\n",
    "        params[param_name] = point\n",
    "        for key, value in search_space.items():\n",
    "            print(f'{key:<14} : {value}')\n",
    "        \n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        for name in protein_names:\n",
    "            data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "            ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "            \n",
    "            # get X dataset\n",
    "            x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "            x_features = list(x_onehot.columns)\n",
    "            \n",
    "            # get Y dataset\n",
    "            y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "            y_labels = list(y_onehot.columns)\n",
    "            \n",
    "            for idx in ST_idx:\n",
    "                window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "                label_y  = np.array(y_onehot.iloc[idx])\n",
    "                \n",
    "                data_x.append(window_x)\n",
    "                data_y.append(label_y)\n",
    "                \n",
    "        data_x = np.array(data_x)\n",
    "        data_y = np.array(data_y)\n",
    "        model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "        print('data x shape:', data_x.shape)\n",
    "        print('data y shape:', data_y.shape)\n",
    "        print('class y counts:', data_y.sum(0))\n",
    "        print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "        \n",
    "        splitter = StratifiedShuffleSplit(n_splits = 1, test_size = test_size, random_state = SEED)\n",
    "        train_idx, test_idx = list(splitter.split(data_x, data_y))[0]\n",
    "        \n",
    "        train_x = data_x[train_idx]\n",
    "        train_y = data_y[train_idx]\n",
    "        \n",
    "        test_x = data_x[test_idx]\n",
    "        test_y = data_y[test_idx]\n",
    "        \n",
    "        train_x, test_x = data_scaling(train_x, test_x)\n",
    "        \n",
    "        splitter_kf = KFold(n_splits = 5)\n",
    "        for cv_idx, (train_idx_kf, test_idx_kf) in enumerate(splitter_kf.split(train_x, train_y)):\n",
    "            train_x_kf, train_y_kf = train_x[train_idx_kf], train_y[train_idx_kf]\n",
    "            test_x_kf, test_y_kf   = train_x[test_idx_kf],  train_y[test_idx_kf]\n",
    "            \n",
    "            # up-sample the training dataset\n",
    "            train_x_kf, train_y_kf = upsample_data(train_x_kf, train_y_kf) \n",
    "            \n",
    "            model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) \n",
    "            model_name = name_model(f'{model_type}_KFOLD', params)\n",
    "            \n",
    "            model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "            if not os.path.exists(model_folder):\n",
    "                os.makedirs(model_folder)\n",
    "            model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "            metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(model_path) or model_update:\n",
    "                time_start = time.time()\n",
    "                history = model.fit(train_x_kf, train_y_kf, verbose=verbose, \n",
    "                                    epochs = 10000, callbacks = callbacks,\n",
    "                                    validation_data = (test_x_kf, test_y_kf))\n",
    "                time_end = time.time()\n",
    "                training_time = round((time_end - time_start)/60, 3)\n",
    "                \n",
    "                model.save_weights(model_path)\n",
    "                \n",
    "                test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "                model_metrics = {\n",
    "                    'model_id' : model_id,\n",
    "                    'cv_idx'   : cv_idx,\n",
    "                    **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "                    'train_y'     : train_y.shape[-1],\n",
    "                    'test_size'   : test_x.shape[0],\n",
    "                    **params,\n",
    "                    'regularizer_input' : params['regularizer']['input'],\n",
    "                    'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "                    'regularizer_bias' : params['regularizer']['bias'],\n",
    "                    'training_time': training_time,\n",
    "                    'test_loss': test_loss,\n",
    "                    'accuracy': accuracy,\n",
    "                    **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "                    **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "                    **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "                \n",
    "                model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "                model_metrics.to_csv(metric_path, index=False)\n",
    "                \n",
    "            else:\n",
    "                model.load_weights(model_path)\n",
    "                model_metrics = pd.read_csv(metric_path, header=0)\n",
    "                \n",
    "            print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "            \n",
    "            model_metrics['model_id'] = model_id\n",
    "            METRICs.append(model_metrics)\n",
    "            MODELs.append(model)\n",
    "        \n",
    "        METRIC_MEAN = pd.concat(METRICs).groupby('model_id').mean()\n",
    "        f1_best = METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0].f1_1\n",
    "        print(f'best f1 score: {f1_best}')\n",
    "        model_id += 1\n",
    "    if param_name in ['learning_rate']: # for float-type parameters\n",
    "        best_value = float(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "    else: # for int-type parameters\n",
    "        best_value = int(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(METRIC_MEAN)\n",
    "for key, value in search_space.items():\n",
    "    print(f'{key:<14} : {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape:  (12120, 420)\n",
      "data y shape:  (12120, 2)\n",
      "train x shape: (9696, 420)\n",
      "test  x shape: (2424, 2)\n"
     ]
    }
   ],
   "source": [
    "print('data x shape: ', data_x.shape)\n",
    "print('data y shape: ', data_y.shape)\n",
    "print('train x shape:', train_x.shape)\n",
    "print('test  x shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "for key, value in params.items():\n",
    "    print(f'{key:<14} : {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate model's general performance through Monte-Carlo cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape: (12120, 420)\n",
      "data y shape: (12120, 2)\n",
      "class y counts: [11672   448]\n",
      "class y ratio: [0.963 0.037]\n",
      "Epoch 1/10000\n",
      "228/228 - 1s - loss: 0.1746 - accuracy: 0.9570 - val_loss: 0.1436 - val_accuracy: 0.9662 - 1s/epoch - 5ms/step\n",
      "Epoch 2/10000\n",
      "228/228 - 1s - loss: 0.1394 - accuracy: 0.9630 - val_loss: 0.1442 - val_accuracy: 0.9662 - 602ms/epoch - 3ms/step\n",
      "Epoch 3/10000\n",
      "228/228 - 1s - loss: 0.1356 - accuracy: 0.9627 - val_loss: 0.1518 - val_accuracy: 0.9662 - 599ms/epoch - 3ms/step\n",
      "Epoch 4/10000\n",
      "228/228 - 1s - loss: 0.1298 - accuracy: 0.9630 - val_loss: 0.1530 - val_accuracy: 0.9658 - 711ms/epoch - 3ms/step\n",
      "Epoch 5/10000\n",
      "228/228 - 1s - loss: 0.1293 - accuracy: 0.9634 - val_loss: 0.1530 - val_accuracy: 0.9662 - 615ms/epoch - 3ms/step\n",
      "Epoch 6/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\n",
      "Cell \u001b[1;32mIn[13], line 60\u001b[0m\n",
      "\n",
      "\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path) \u001b[38;5;129;01mor\u001b[39;00m model_update:\n",
      "\n",
      "\u001b[0;32m     59\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\n",
      "\u001b[1;32m---> 60\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\n",
      "\u001b[0;32m     61\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m     62\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m     63\u001b[0m     time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\n",
      "\u001b[0;32m     64\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((time_end \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n",
      "\n",
      "\u001b[0;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n",
      "\n",
      "\u001b[0;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n",
      "\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n",
      "\n",
      "\u001b[0;32m   1605\u001b[0m     )\n",
      "\n",
      "\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n",
      "\n",
      "\u001b[0;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n",
      "\n",
      "\u001b[0;32m   1621\u001b[0m }\n",
      "\n",
      "\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n",
      "\n",
      "\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\n",
      "\u001b[0;32m   1945\u001b[0m ):\n",
      "\n",
      "\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n",
      "\n",
      "\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "\n",
      "\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\n",
      "\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\n",
      "\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\n",
      "\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\n",
      "\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\n",
      "\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n",
      "\n",
      "\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\n",
      "\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n",
      "\n",
      "\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\n",
      "\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\n",
      "\u001b[0;32m   2494\u001b[0m   (graph_function,\n",
      "\n",
      "\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "\n",
      "\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\n",
      "\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\n",
      "\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\n",
      "\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\n",
      "\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\n",
      "\u001b[0;32m   1865\u001b[0m     args,\n",
      "\n",
      "\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n",
      "\n",
      "\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n",
      "\n",
      "\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n",
      "\n",
      "\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\n",
      "\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n",
      "\n",
      "\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n",
      "\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n",
      "\n",
      "\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\n",
      "\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\n",
      "\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update = False\n",
    "            \n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "verbose = 0\n",
    "        \n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for name in protein_names:\n",
    "    data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "    ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "    \n",
    "    # get X dataset\n",
    "    x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "    x_features = list(x_onehot.columns)\n",
    "    \n",
    "    # get Y dataset\n",
    "    y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "    y_labels = list(y_onehot.columns)\n",
    "    \n",
    "    for idx in ST_idx:\n",
    "        window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "        label_y  = np.array(y_onehot.iloc[idx])\n",
    "        \n",
    "        data_x.append(window_x)\n",
    "        data_y.append(label_y)\n",
    "        \n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "print('data x shape:', data_x.shape)\n",
    "print('data y shape:', data_y.shape)\n",
    "print('class y counts:', data_y.sum(0))\n",
    "print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits = 5, test_size = test_size, random_state = SEED)\n",
    "for cv_idx, (train_idx, test_idx) in enumerate(splitter.split(data_x, data_y)):\n",
    "    train_x, train_y = data_x[train_idx], data_y[train_idx]\n",
    "    train_x, train_y = upsample_data(train_x, train_y) # up-sample the training dataset\n",
    "    test_x , test_y  = data_x[test_idx],  data_y[test_idx]\n",
    "    \n",
    "    train_x, test_x = data_scaling(train_x, test_x)\n",
    "    \n",
    "    model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params)\n",
    "    model_name = name_model(f'{model_type}', params)\n",
    "    \n",
    "    \n",
    "    model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "    model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "    metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(model_path) or model_update:\n",
    "        time_start = time.time()\n",
    "        history = model.fit(train_x, train_y, verbose=verbose, \n",
    "                            epochs = 10000, callbacks = callbacks,\n",
    "                            validation_split = test_size/(1-test_size))\n",
    "        time_end = time.time()\n",
    "        training_time = round((time_end - time_start)/60, 3)\n",
    "        \n",
    "        model.save_weights(model_path)\n",
    "        \n",
    "        test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "        model_metrics = {\n",
    "            'model_id' : model_id,\n",
    "            'cv_idx'   : cv_idx,\n",
    "            **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "            'train_y'     : train_y.shape[-1],\n",
    "            'test_size'   : test_x.shape[0],\n",
    "            **params,\n",
    "            'regularizer_input' : params['regularizer']['input'],\n",
    "            'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "            'regularizer_bias' : params['regularizer']['bias'],\n",
    "            'training_time': training_time,\n",
    "            'test_loss': test_loss,\n",
    "            'accuracy': accuracy,\n",
    "            **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "            **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "            **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "        model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "        model_metrics.to_csv(metric_path, index=False)\n",
    "        \n",
    "    else:\n",
    "        model.load_weights(model_path)\n",
    "        model_metrics = pd.read_csv(metric_path, header=0)\n",
    "        \n",
    "    print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "    \n",
    "    METRICs.append(model_metrics)\n",
    "    MODELs.append(model)\n",
    "\n",
    "METRICs = pd.concat(METRICs)\n",
    "METRIC_MEAN = METRICs.groupby('model_id').mean()\n",
    "METRIC_STD = METRICs.groupby('model_id').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# function ConnectButton(){\n",
    "#     console.log(\"Connect pushed\");\n",
    "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
    "# }\n",
    "\n",
    "# setInterval(ConnectButton,60000);\n",
    "# '''\n",
    "\n",
    "# from google.colab import drive\n",
    "# from os import chdir\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# project_path = '/content/drive/MyDrive/Gproject/o-linked-site-prediction-feature-augment'\n",
    "# chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed for the reproducible result\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of initial proteins: 104\n",
      "['A2ABU4', 'A2AHJ4', 'A2AKB9', 'A2AQ25', 'E9Q1P8', 'E9Q5G3', 'O08537', 'O09061', 'O35303', 'O70263']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/integrated_features' # we will get names from the augmented proteins\n",
    "protein_names = [x.split('.')[0] for x in os.listdir(data_dir) if x.split('.')[1] == 'csv'] # get protein name list to be processed for building machine learning models\n",
    "print('the number of initial proteins:', len(protein_names))\n",
    "print(protein_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameter optimization by K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from ml_models import *\n",
    "\n",
    "epochs = 1000\n",
    "from keras.callbacks import EarlyStopping\n",
    "patience = 30\n",
    "callbacks = [EarlyStopping(patience=patience, restore_best_weights=True, monitor='val_loss')]\n",
    "\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters\n",
      "rnn_layers     : 1\n",
      "rnn_neurons    : 64\n",
      "dnn_layers     : 3\n",
      "dnn_neurons    : 64\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "initial_params = default_params.copy()\n",
    "initial_params.update({\n",
    "    'window_size'    : 10\n",
    "    })\n",
    "\n",
    "print('initial parameters')\n",
    "for key, value in initial_params.items():\n",
    "    print(f'{key:<14} : {value}')\n",
    "\n",
    "search_space = {\n",
    "    'rnn_layers'    : [1, 2, 3, 4, 5],\n",
    "    'rnn_neurons'   : [32, 64, 128, 256],\n",
    "    'dnn_layers'    : [1, 2, 3, 4, 5],\n",
    "    'dnn_neurons'   : [32, 64, 128, 256],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of augmented features: 498\n",
      "continuous features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'number_hydrophobic_0A',\n",
       " 1: 'number_hydrophilic_0A',\n",
       " 2: 'number_polar_0A',\n",
       " 3: 'number_aromatic_0A',\n",
       " 4: 'number_aliphatic_0A',\n",
       " 5: 'number_charged_0A',\n",
       " 6: 'number_positive_0A',\n",
       " 7: 'number_negative_0A',\n",
       " 8: 'number_gly_0A',\n",
       " 9: 'number_very_small_0A',\n",
       " 10: 'number_small_0A',\n",
       " 11: 'number_normal_0A',\n",
       " 12: 'number_long_0A',\n",
       " 13: 'number_pro_0A',\n",
       " 14: 'number_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 15: 'number_b_polar_uncharged_with_amide_0A',\n",
       " 16: 'number_d_negatively_charged_polar_0A',\n",
       " 17: 'number_e_non_polar_suffered_0A',\n",
       " 18: 'number_f_non_polar_aromatic_0A',\n",
       " 19: 'number_ala_0A',\n",
       " 20: 'number_cys_0A',\n",
       " 21: 'number_asp_0A',\n",
       " 22: 'number_glu_0A',\n",
       " 23: 'number_phe_0A',\n",
       " 24: 'number_his_0A',\n",
       " 25: 'number_ile_0A',\n",
       " 26: 'number_lys_0A',\n",
       " 27: 'number_leu_0A',\n",
       " 28: 'number_met_0A',\n",
       " 29: 'number_asn_0A',\n",
       " 30: 'number_gln_0A',\n",
       " 31: 'number_arg_0A',\n",
       " 32: 'number_ser_0A',\n",
       " 33: 'number_thr_0A',\n",
       " 34: 'number_val_0A',\n",
       " 35: 'number_trp_0A',\n",
       " 36: 'number_tyr_0A',\n",
       " 37: 'sasa_hydrophobic_0A',\n",
       " 38: 'sasa_hydrophilic_0A',\n",
       " 39: 'sasa_polar_0A',\n",
       " 40: 'sasa_aromatic_0A',\n",
       " 41: 'sasa_aliphatic_0A',\n",
       " 42: 'sasa_charged_0A',\n",
       " 43: 'sasa_positive_0A',\n",
       " 44: 'sasa_negative_0A',\n",
       " 45: 'sasa_gly_0A',\n",
       " 46: 'sasa_very_small_0A',\n",
       " 47: 'sasa_small_0A',\n",
       " 48: 'sasa_normal_0A',\n",
       " 49: 'sasa_long_0A',\n",
       " 50: 'sasa_pro_0A',\n",
       " 51: 'sasa_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 52: 'sasa_b_polar_uncharged_with_amide_0A',\n",
       " 53: 'sasa_d_negatively_charged_polar_0A',\n",
       " 54: 'sasa_e_non_polar_suffered_0A',\n",
       " 55: 'sasa_f_non_polar_aromatic_0A',\n",
       " 56: 'sasa_ala_0A',\n",
       " 57: 'sasa_cys_0A',\n",
       " 58: 'sasa_asp_0A',\n",
       " 59: 'sasa_glu_0A',\n",
       " 60: 'sasa_phe_0A',\n",
       " 61: 'sasa_his_0A',\n",
       " 62: 'sasa_ile_0A',\n",
       " 63: 'sasa_lys_0A',\n",
       " 64: 'sasa_leu_0A',\n",
       " 65: 'sasa_met_0A',\n",
       " 66: 'sasa_asn_0A',\n",
       " 67: 'sasa_gln_0A',\n",
       " 68: 'sasa_arg_0A',\n",
       " 69: 'sasa_ser_0A',\n",
       " 70: 'sasa_thr_0A',\n",
       " 71: 'sasa_val_0A',\n",
       " 72: 'sasa_trp_0A',\n",
       " 73: 'sasa_tyr_0A',\n",
       " 74: 'sasa_back_0A',\n",
       " 75: 'sasa_side_0A',\n",
       " 76: 'sasa_target_ser_thr_0A',\n",
       " 77: 'net_charge_all_0A',\n",
       " 78: 'net_charge_backbone_0A',\n",
       " 79: 'net_charge_sidechain_0A',\n",
       " 80: 'net_charge_all_exposed_0A',\n",
       " 81: 'net_charge_backbone_exposed_0A',\n",
       " 82: 'net_charge_sidechain_exposed_0A',\n",
       " 83: 'number_hydrophobic_5A',\n",
       " 84: 'number_hydrophilic_5A',\n",
       " 85: 'number_polar_5A',\n",
       " 86: 'number_aromatic_5A',\n",
       " 87: 'number_aliphatic_5A',\n",
       " 88: 'number_charged_5A',\n",
       " 89: 'number_positive_5A',\n",
       " 90: 'number_negative_5A',\n",
       " 91: 'number_gly_5A',\n",
       " 92: 'number_very_small_5A',\n",
       " 93: 'number_small_5A',\n",
       " 94: 'number_normal_5A',\n",
       " 95: 'number_long_5A',\n",
       " 96: 'number_pro_5A',\n",
       " 97: 'number_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 98: 'number_b_polar_uncharged_with_amide_5A',\n",
       " 99: 'number_d_negatively_charged_polar_5A',\n",
       " 100: 'number_e_non_polar_suffered_5A',\n",
       " 101: 'number_f_non_polar_aromatic_5A',\n",
       " 102: 'number_ala_5A',\n",
       " 103: 'number_cys_5A',\n",
       " 104: 'number_asp_5A',\n",
       " 105: 'number_glu_5A',\n",
       " 106: 'number_phe_5A',\n",
       " 107: 'number_his_5A',\n",
       " 108: 'number_ile_5A',\n",
       " 109: 'number_lys_5A',\n",
       " 110: 'number_leu_5A',\n",
       " 111: 'number_met_5A',\n",
       " 112: 'number_asn_5A',\n",
       " 113: 'number_gln_5A',\n",
       " 114: 'number_arg_5A',\n",
       " 115: 'number_ser_5A',\n",
       " 116: 'number_thr_5A',\n",
       " 117: 'number_val_5A',\n",
       " 118: 'number_trp_5A',\n",
       " 119: 'number_tyr_5A',\n",
       " 120: 'sasa_hydrophobic_5A',\n",
       " 121: 'sasa_hydrophilic_5A',\n",
       " 122: 'sasa_polar_5A',\n",
       " 123: 'sasa_aromatic_5A',\n",
       " 124: 'sasa_aliphatic_5A',\n",
       " 125: 'sasa_charged_5A',\n",
       " 126: 'sasa_positive_5A',\n",
       " 127: 'sasa_negative_5A',\n",
       " 128: 'sasa_gly_5A',\n",
       " 129: 'sasa_very_small_5A',\n",
       " 130: 'sasa_small_5A',\n",
       " 131: 'sasa_normal_5A',\n",
       " 132: 'sasa_long_5A',\n",
       " 133: 'sasa_pro_5A',\n",
       " 134: 'sasa_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 135: 'sasa_b_polar_uncharged_with_amide_5A',\n",
       " 136: 'sasa_d_negatively_charged_polar_5A',\n",
       " 137: 'sasa_e_non_polar_suffered_5A',\n",
       " 138: 'sasa_f_non_polar_aromatic_5A',\n",
       " 139: 'sasa_ala_5A',\n",
       " 140: 'sasa_cys_5A',\n",
       " 141: 'sasa_asp_5A',\n",
       " 142: 'sasa_glu_5A',\n",
       " 143: 'sasa_phe_5A',\n",
       " 144: 'sasa_his_5A',\n",
       " 145: 'sasa_ile_5A',\n",
       " 146: 'sasa_lys_5A',\n",
       " 147: 'sasa_leu_5A',\n",
       " 148: 'sasa_met_5A',\n",
       " 149: 'sasa_asn_5A',\n",
       " 150: 'sasa_gln_5A',\n",
       " 151: 'sasa_arg_5A',\n",
       " 152: 'sasa_ser_5A',\n",
       " 153: 'sasa_thr_5A',\n",
       " 154: 'sasa_val_5A',\n",
       " 155: 'sasa_trp_5A',\n",
       " 156: 'sasa_tyr_5A',\n",
       " 157: 'sasa_back_5A',\n",
       " 158: 'sasa_side_5A',\n",
       " 159: 'sasa_target_ser_thr_5A',\n",
       " 160: 'net_charge_all_5A',\n",
       " 161: 'net_charge_backbone_5A',\n",
       " 162: 'net_charge_sidechain_5A',\n",
       " 163: 'net_charge_all_exposed_5A',\n",
       " 164: 'net_charge_backbone_exposed_5A',\n",
       " 165: 'net_charge_sidechain_exposed_5A',\n",
       " 166: 'number_hydrophobic_10A',\n",
       " 167: 'number_hydrophilic_10A',\n",
       " 168: 'number_polar_10A',\n",
       " 169: 'number_aromatic_10A',\n",
       " 170: 'number_aliphatic_10A',\n",
       " 171: 'number_charged_10A',\n",
       " 172: 'number_positive_10A',\n",
       " 173: 'number_negative_10A',\n",
       " 174: 'number_gly_10A',\n",
       " 175: 'number_very_small_10A',\n",
       " 176: 'number_small_10A',\n",
       " 177: 'number_normal_10A',\n",
       " 178: 'number_long_10A',\n",
       " 179: 'number_pro_10A',\n",
       " 180: 'number_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 181: 'number_b_polar_uncharged_with_amide_10A',\n",
       " 182: 'number_d_negatively_charged_polar_10A',\n",
       " 183: 'number_e_non_polar_suffered_10A',\n",
       " 184: 'number_f_non_polar_aromatic_10A',\n",
       " 185: 'number_ala_10A',\n",
       " 186: 'number_cys_10A',\n",
       " 187: 'number_asp_10A',\n",
       " 188: 'number_glu_10A',\n",
       " 189: 'number_phe_10A',\n",
       " 190: 'number_his_10A',\n",
       " 191: 'number_ile_10A',\n",
       " 192: 'number_lys_10A',\n",
       " 193: 'number_leu_10A',\n",
       " 194: 'number_met_10A',\n",
       " 195: 'number_asn_10A',\n",
       " 196: 'number_gln_10A',\n",
       " 197: 'number_arg_10A',\n",
       " 198: 'number_ser_10A',\n",
       " 199: 'number_thr_10A',\n",
       " 200: 'number_val_10A',\n",
       " 201: 'number_trp_10A',\n",
       " 202: 'number_tyr_10A',\n",
       " 203: 'sasa_hydrophobic_10A',\n",
       " 204: 'sasa_hydrophilic_10A',\n",
       " 205: 'sasa_polar_10A',\n",
       " 206: 'sasa_aromatic_10A',\n",
       " 207: 'sasa_aliphatic_10A',\n",
       " 208: 'sasa_charged_10A',\n",
       " 209: 'sasa_positive_10A',\n",
       " 210: 'sasa_negative_10A',\n",
       " 211: 'sasa_gly_10A',\n",
       " 212: 'sasa_very_small_10A',\n",
       " 213: 'sasa_small_10A',\n",
       " 214: 'sasa_normal_10A',\n",
       " 215: 'sasa_long_10A',\n",
       " 216: 'sasa_pro_10A',\n",
       " 217: 'sasa_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 218: 'sasa_b_polar_uncharged_with_amide_10A',\n",
       " 219: 'sasa_d_negatively_charged_polar_10A',\n",
       " 220: 'sasa_e_non_polar_suffered_10A',\n",
       " 221: 'sasa_f_non_polar_aromatic_10A',\n",
       " 222: 'sasa_ala_10A',\n",
       " 223: 'sasa_cys_10A',\n",
       " 224: 'sasa_asp_10A',\n",
       " 225: 'sasa_glu_10A',\n",
       " 226: 'sasa_phe_10A',\n",
       " 227: 'sasa_his_10A',\n",
       " 228: 'sasa_ile_10A',\n",
       " 229: 'sasa_lys_10A',\n",
       " 230: 'sasa_leu_10A',\n",
       " 231: 'sasa_met_10A',\n",
       " 232: 'sasa_asn_10A',\n",
       " 233: 'sasa_gln_10A',\n",
       " 234: 'sasa_arg_10A',\n",
       " 235: 'sasa_ser_10A',\n",
       " 236: 'sasa_thr_10A',\n",
       " 237: 'sasa_val_10A',\n",
       " 238: 'sasa_trp_10A',\n",
       " 239: 'sasa_tyr_10A',\n",
       " 240: 'sasa_back_10A',\n",
       " 241: 'sasa_side_10A',\n",
       " 242: 'sasa_target_ser_thr_10A',\n",
       " 243: 'net_charge_all_10A',\n",
       " 244: 'net_charge_backbone_10A',\n",
       " 245: 'net_charge_sidechain_10A',\n",
       " 246: 'net_charge_all_exposed_10A',\n",
       " 247: 'net_charge_backbone_exposed_10A',\n",
       " 248: 'net_charge_sidechain_exposed_10A',\n",
       " 249: 'number_hydrophobic_15A',\n",
       " 250: 'number_hydrophilic_15A',\n",
       " 251: 'number_polar_15A',\n",
       " 252: 'number_aromatic_15A',\n",
       " 253: 'number_aliphatic_15A',\n",
       " 254: 'number_charged_15A',\n",
       " 255: 'number_positive_15A',\n",
       " 256: 'number_negative_15A',\n",
       " 257: 'number_gly_15A',\n",
       " 258: 'number_very_small_15A',\n",
       " 259: 'number_small_15A',\n",
       " 260: 'number_normal_15A',\n",
       " 261: 'number_long_15A',\n",
       " 262: 'number_pro_15A',\n",
       " 263: 'number_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 264: 'number_b_polar_uncharged_with_amide_15A',\n",
       " 265: 'number_d_negatively_charged_polar_15A',\n",
       " 266: 'number_e_non_polar_suffered_15A',\n",
       " 267: 'number_f_non_polar_aromatic_15A',\n",
       " 268: 'number_ala_15A',\n",
       " 269: 'number_cys_15A',\n",
       " 270: 'number_asp_15A',\n",
       " 271: 'number_glu_15A',\n",
       " 272: 'number_phe_15A',\n",
       " 273: 'number_his_15A',\n",
       " 274: 'number_ile_15A',\n",
       " 275: 'number_lys_15A',\n",
       " 276: 'number_leu_15A',\n",
       " 277: 'number_met_15A',\n",
       " 278: 'number_asn_15A',\n",
       " 279: 'number_gln_15A',\n",
       " 280: 'number_arg_15A',\n",
       " 281: 'number_ser_15A',\n",
       " 282: 'number_thr_15A',\n",
       " 283: 'number_val_15A',\n",
       " 284: 'number_trp_15A',\n",
       " 285: 'number_tyr_15A',\n",
       " 286: 'sasa_hydrophobic_15A',\n",
       " 287: 'sasa_hydrophilic_15A',\n",
       " 288: 'sasa_polar_15A',\n",
       " 289: 'sasa_aromatic_15A',\n",
       " 290: 'sasa_aliphatic_15A',\n",
       " 291: 'sasa_charged_15A',\n",
       " 292: 'sasa_positive_15A',\n",
       " 293: 'sasa_negative_15A',\n",
       " 294: 'sasa_gly_15A',\n",
       " 295: 'sasa_very_small_15A',\n",
       " 296: 'sasa_small_15A',\n",
       " 297: 'sasa_normal_15A',\n",
       " 298: 'sasa_long_15A',\n",
       " 299: 'sasa_pro_15A',\n",
       " 300: 'sasa_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 301: 'sasa_b_polar_uncharged_with_amide_15A',\n",
       " 302: 'sasa_d_negatively_charged_polar_15A',\n",
       " 303: 'sasa_e_non_polar_suffered_15A',\n",
       " 304: 'sasa_f_non_polar_aromatic_15A',\n",
       " 305: 'sasa_ala_15A',\n",
       " 306: 'sasa_cys_15A',\n",
       " 307: 'sasa_asp_15A',\n",
       " 308: 'sasa_glu_15A',\n",
       " 309: 'sasa_phe_15A',\n",
       " 310: 'sasa_his_15A',\n",
       " 311: 'sasa_ile_15A',\n",
       " 312: 'sasa_lys_15A',\n",
       " 313: 'sasa_leu_15A',\n",
       " 314: 'sasa_met_15A',\n",
       " 315: 'sasa_asn_15A',\n",
       " 316: 'sasa_gln_15A',\n",
       " 317: 'sasa_arg_15A',\n",
       " 318: 'sasa_ser_15A',\n",
       " 319: 'sasa_thr_15A',\n",
       " 320: 'sasa_val_15A',\n",
       " 321: 'sasa_trp_15A',\n",
       " 322: 'sasa_tyr_15A',\n",
       " 323: 'sasa_back_15A',\n",
       " 324: 'sasa_side_15A',\n",
       " 325: 'sasa_target_ser_thr_15A',\n",
       " 326: 'net_charge_all_15A',\n",
       " 327: 'net_charge_backbone_15A',\n",
       " 328: 'net_charge_sidechain_15A',\n",
       " 329: 'net_charge_all_exposed_15A',\n",
       " 330: 'net_charge_backbone_exposed_15A',\n",
       " 331: 'net_charge_sidechain_exposed_15A',\n",
       " 332: 'number_hydrophobic_20A',\n",
       " 333: 'number_hydrophilic_20A',\n",
       " 334: 'number_polar_20A',\n",
       " 335: 'number_aromatic_20A',\n",
       " 336: 'number_aliphatic_20A',\n",
       " 337: 'number_charged_20A',\n",
       " 338: 'number_positive_20A',\n",
       " 339: 'number_negative_20A',\n",
       " 340: 'number_gly_20A',\n",
       " 341: 'number_very_small_20A',\n",
       " 342: 'number_small_20A',\n",
       " 343: 'number_normal_20A',\n",
       " 344: 'number_long_20A',\n",
       " 345: 'number_pro_20A',\n",
       " 346: 'number_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 347: 'number_b_polar_uncharged_with_amide_20A',\n",
       " 348: 'number_d_negatively_charged_polar_20A',\n",
       " 349: 'number_e_non_polar_suffered_20A',\n",
       " 350: 'number_f_non_polar_aromatic_20A',\n",
       " 351: 'number_ala_20A',\n",
       " 352: 'number_cys_20A',\n",
       " 353: 'number_asp_20A',\n",
       " 354: 'number_glu_20A',\n",
       " 355: 'number_phe_20A',\n",
       " 356: 'number_his_20A',\n",
       " 357: 'number_ile_20A',\n",
       " 358: 'number_lys_20A',\n",
       " 359: 'number_leu_20A',\n",
       " 360: 'number_met_20A',\n",
       " 361: 'number_asn_20A',\n",
       " 362: 'number_gln_20A',\n",
       " 363: 'number_arg_20A',\n",
       " 364: 'number_ser_20A',\n",
       " 365: 'number_thr_20A',\n",
       " 366: 'number_val_20A',\n",
       " 367: 'number_trp_20A',\n",
       " 368: 'number_tyr_20A',\n",
       " 369: 'sasa_hydrophobic_20A',\n",
       " 370: 'sasa_hydrophilic_20A',\n",
       " 371: 'sasa_polar_20A',\n",
       " 372: 'sasa_aromatic_20A',\n",
       " 373: 'sasa_aliphatic_20A',\n",
       " 374: 'sasa_charged_20A',\n",
       " 375: 'sasa_positive_20A',\n",
       " 376: 'sasa_negative_20A',\n",
       " 377: 'sasa_gly_20A',\n",
       " 378: 'sasa_very_small_20A',\n",
       " 379: 'sasa_small_20A',\n",
       " 380: 'sasa_normal_20A',\n",
       " 381: 'sasa_long_20A',\n",
       " 382: 'sasa_pro_20A',\n",
       " 383: 'sasa_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 384: 'sasa_b_polar_uncharged_with_amide_20A',\n",
       " 385: 'sasa_d_negatively_charged_polar_20A',\n",
       " 386: 'sasa_e_non_polar_suffered_20A',\n",
       " 387: 'sasa_f_non_polar_aromatic_20A',\n",
       " 388: 'sasa_ala_20A',\n",
       " 389: 'sasa_cys_20A',\n",
       " 390: 'sasa_asp_20A',\n",
       " 391: 'sasa_glu_20A',\n",
       " 392: 'sasa_phe_20A',\n",
       " 393: 'sasa_his_20A',\n",
       " 394: 'sasa_ile_20A',\n",
       " 395: 'sasa_lys_20A',\n",
       " 396: 'sasa_leu_20A',\n",
       " 397: 'sasa_met_20A',\n",
       " 398: 'sasa_asn_20A',\n",
       " 399: 'sasa_gln_20A',\n",
       " 400: 'sasa_arg_20A',\n",
       " 401: 'sasa_ser_20A',\n",
       " 402: 'sasa_thr_20A',\n",
       " 403: 'sasa_val_20A',\n",
       " 404: 'sasa_trp_20A',\n",
       " 405: 'sasa_tyr_20A',\n",
       " 406: 'sasa_back_20A',\n",
       " 407: 'sasa_side_20A',\n",
       " 408: 'sasa_target_ser_thr_20A',\n",
       " 409: 'net_charge_all_20A',\n",
       " 410: 'net_charge_backbone_20A',\n",
       " 411: 'net_charge_sidechain_20A',\n",
       " 412: 'net_charge_all_exposed_20A',\n",
       " 413: 'net_charge_backbone_exposed_20A',\n",
       " 414: 'net_charge_sidechain_exposed_20A',\n",
       " 415: 'number_hydrophobic_25A',\n",
       " 416: 'number_hydrophilic_25A',\n",
       " 417: 'number_polar_25A',\n",
       " 418: 'number_aromatic_25A',\n",
       " 419: 'number_aliphatic_25A',\n",
       " 420: 'number_charged_25A',\n",
       " 421: 'number_positive_25A',\n",
       " 422: 'number_negative_25A',\n",
       " 423: 'number_gly_25A',\n",
       " 424: 'number_very_small_25A',\n",
       " 425: 'number_small_25A',\n",
       " 426: 'number_normal_25A',\n",
       " 427: 'number_long_25A',\n",
       " 428: 'number_pro_25A',\n",
       " 429: 'number_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 430: 'number_b_polar_uncharged_with_amide_25A',\n",
       " 431: 'number_d_negatively_charged_polar_25A',\n",
       " 432: 'number_e_non_polar_suffered_25A',\n",
       " 433: 'number_f_non_polar_aromatic_25A',\n",
       " 434: 'number_ala_25A',\n",
       " 435: 'number_cys_25A',\n",
       " 436: 'number_asp_25A',\n",
       " 437: 'number_glu_25A',\n",
       " 438: 'number_phe_25A',\n",
       " 439: 'number_his_25A',\n",
       " 440: 'number_ile_25A',\n",
       " 441: 'number_lys_25A',\n",
       " 442: 'number_leu_25A',\n",
       " 443: 'number_met_25A',\n",
       " 444: 'number_asn_25A',\n",
       " 445: 'number_gln_25A',\n",
       " 446: 'number_arg_25A',\n",
       " 447: 'number_ser_25A',\n",
       " 448: 'number_thr_25A',\n",
       " 449: 'number_val_25A',\n",
       " 450: 'number_trp_25A',\n",
       " 451: 'number_tyr_25A',\n",
       " 452: 'sasa_hydrophobic_25A',\n",
       " 453: 'sasa_hydrophilic_25A',\n",
       " 454: 'sasa_polar_25A',\n",
       " 455: 'sasa_aromatic_25A',\n",
       " 456: 'sasa_aliphatic_25A',\n",
       " 457: 'sasa_charged_25A',\n",
       " 458: 'sasa_positive_25A',\n",
       " 459: 'sasa_negative_25A',\n",
       " 460: 'sasa_gly_25A',\n",
       " 461: 'sasa_very_small_25A',\n",
       " 462: 'sasa_small_25A',\n",
       " 463: 'sasa_normal_25A',\n",
       " 464: 'sasa_long_25A',\n",
       " 465: 'sasa_pro_25A',\n",
       " 466: 'sasa_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 467: 'sasa_b_polar_uncharged_with_amide_25A',\n",
       " 468: 'sasa_d_negatively_charged_polar_25A',\n",
       " 469: 'sasa_e_non_polar_suffered_25A',\n",
       " 470: 'sasa_f_non_polar_aromatic_25A',\n",
       " 471: 'sasa_ala_25A',\n",
       " 472: 'sasa_cys_25A',\n",
       " 473: 'sasa_asp_25A',\n",
       " 474: 'sasa_glu_25A',\n",
       " 475: 'sasa_phe_25A',\n",
       " 476: 'sasa_his_25A',\n",
       " 477: 'sasa_ile_25A',\n",
       " 478: 'sasa_lys_25A',\n",
       " 479: 'sasa_leu_25A',\n",
       " 480: 'sasa_met_25A',\n",
       " 481: 'sasa_asn_25A',\n",
       " 482: 'sasa_gln_25A',\n",
       " 483: 'sasa_arg_25A',\n",
       " 484: 'sasa_ser_25A',\n",
       " 485: 'sasa_thr_25A',\n",
       " 486: 'sasa_val_25A',\n",
       " 487: 'sasa_trp_25A',\n",
       " 488: 'sasa_tyr_25A',\n",
       " 489: 'sasa_back_25A',\n",
       " 490: 'sasa_side_25A',\n",
       " 491: 'sasa_target_ser_thr_25A',\n",
       " 492: 'net_charge_all_25A',\n",
       " 493: 'net_charge_backbone_25A',\n",
       " 494: 'net_charge_sidechain_25A',\n",
       " 495: 'net_charge_all_exposed_25A',\n",
       " 496: 'net_charge_backbone_exposed_25A',\n",
       " 497: 'net_charge_sidechain_exposed_25A'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:\n",
      "{0: 'residue'}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'LSTM_UP_BASIC'\n",
    "\n",
    "basic_columns = dict(pd.read_csv('./data/basic_columns.csv', header=0).values.squeeze())\n",
    "print('# of augmented features:', len(basic_columns))\n",
    "\n",
    "# set continuous input features\n",
    "x_cts = [x for x in basic_columns.keys() if basic_columns.get(x) != 'object']\n",
    "print('continuous features:')\n",
    "display(dict(zip(range(len(x_cts)), x_cts)))\n",
    "\n",
    "# set categorical input features\n",
    "x_cat = ['residue'] + \\\n",
    "        [x for x in basic_columns.keys() if basic_columns.get(x) == 'object']\n",
    "print('categorical features:')\n",
    "print(dict(zip(range(len(x_cat)), x_cat)))\n",
    "\n",
    "# input features\n",
    "x_var = x_cts + x_cat\n",
    "\n",
    "# set continuos output feature\n",
    "y_cts = []\n",
    "\n",
    "# set categorical output feature\n",
    "y_cat = ['positivity']\n",
    "\n",
    "# output features\n",
    "y_var = y_cts + y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build amino acid sequence dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model training with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_layers     : [1, 2, 3, 4, 5]\n",
      "rnn_neurons    : [32, 64, 128, 256]\n",
      "dnn_layers     : [1, 2, 3, 4, 5]\n",
      "dnn_neurons    : [32, 64, 128, 256]\n",
      "learning_rate  : [0.0001, 0.001, 0.01]\n",
      "data x shape: (11858, 21, 73)\n",
      "data y shape: (11858, 2)\n",
      "class y counts: [11429   429]\n",
      "class y ratio: [0.9638 0.0362]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[12], line 81\u001b[0m\n",
      "\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path) \u001b[38;5;129;01mor\u001b[39;00m model_update:\n",
      "\u001b[0;32m     80\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;32m---> 81\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[0;32m     82\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     83\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y_kf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     84\u001b[0m     time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;32m     85\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((time_end \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n",
      "\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n",
      "\u001b[0;32m   1562\u001b[0m ):\n",
      "\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n",
      "\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n",
      "\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n",
      "\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n",
      "\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n",
      "\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\u001b[0;32m   2494\u001b[0m   (graph_function,\n",
      "\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\u001b[0;32m   1865\u001b[0m     args,\n",
      "\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n",
      "\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n",
      "\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n",
      "\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n",
      "\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update  = False\n",
    "\n",
    "params = initial_params.copy()\n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "model_id = 1\n",
    "verbose = 0\n",
    "for param_name, space in search_space.items():\n",
    "    for point in space:\n",
    "        clear_output(wait=True)\n",
    "        display(METRIC_MEAN)\n",
    "        params[param_name] = point\n",
    "        for key, value in search_space.items():\n",
    "            print(f'{key:<14} : {value}')\n",
    "        \n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        for name in protein_names:\n",
    "            data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "            ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "            \n",
    "            # get X dataset\n",
    "            x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "            x_features = list(x_onehot.columns)\n",
    "            \n",
    "            # get Y dataset\n",
    "            y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "            y_labels = list(y_onehot.columns)\n",
    "            \n",
    "            for idx in ST_idx:\n",
    "                window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "                label_y  = np.array(y_onehot.iloc[idx])\n",
    "                \n",
    "                data_x.append(window_x)\n",
    "                data_y.append(label_y)\n",
    "                \n",
    "        data_x = np.array(data_x)\n",
    "        data_y = np.array(data_y)\n",
    "        model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "        print('data x shape:', data_x.shape)\n",
    "        print('data y shape:', data_y.shape)\n",
    "        print('class y counts:', data_y.sum(0))\n",
    "        print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "        \n",
    "        splitter = StratifiedShuffleSplit(n_splits = 1, test_size = test_size, random_state = SEED)\n",
    "        train_idx, test_idx = list(splitter.split(data_x, data_y))[0]\n",
    "        \n",
    "        train_x = data_x[train_idx]\n",
    "        train_y = data_y[train_idx]\n",
    "        \n",
    "        test_x = data_x[test_idx]\n",
    "        test_y = data_y[test_idx]\n",
    "        \n",
    "        train_x, test_x = data_scaling(train_x, test_x)\n",
    "        \n",
    "        splitter_kf = KFold(n_splits = 5)\n",
    "        for cv_idx, (train_idx_kf, test_idx_kf) in enumerate(splitter_kf.split(train_x, train_y)):\n",
    "            train_x_kf, train_y_kf = train_x[train_idx_kf], train_y[train_idx_kf]\n",
    "            test_x_kf, test_y_kf   = train_x[test_idx_kf],  train_y[test_idx_kf]\n",
    "            \n",
    "            # up-sample the training dataset\n",
    "            train_x_kf, train_y_kf = upsample_data(train_x_kf, train_y_kf) \n",
    "            \n",
    "            model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) \n",
    "            model_name = name_model(f'{model_type}_KFOLD', params)\n",
    "            \n",
    "            model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "            if not os.path.exists(model_folder):\n",
    "                os.makedirs(model_folder)\n",
    "            model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "            metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(model_path) or model_update:\n",
    "                time_start = time.time()\n",
    "                history = model.fit(train_x_kf, train_y_kf, verbose=verbose, \n",
    "                                    epochs = 10000, callbacks = callbacks,\n",
    "                                    validation_data = (test_x_kf, test_y_kf))\n",
    "                time_end = time.time()\n",
    "                training_time = round((time_end - time_start)/60, 3)\n",
    "                \n",
    "                model.save_weights(model_path)\n",
    "                \n",
    "                test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "                model_metrics = {\n",
    "                    'model_id' : model_id,\n",
    "                    'cv_idx'   : cv_idx,\n",
    "                    **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "                    'train_y'     : train_y.shape[-1],\n",
    "                    'test_size'   : test_x.shape[0],\n",
    "                    **params,\n",
    "                    'regularizer_input' : params['regularizer']['input'],\n",
    "                    'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "                    'regularizer_bias' : params['regularizer']['bias'],\n",
    "                    'training_time': training_time,\n",
    "                    'test_loss': test_loss,\n",
    "                    'accuracy': accuracy,\n",
    "                    **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "                    **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "                    **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "                \n",
    "                model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "                model_metrics.to_csv(metric_path, index=False)\n",
    "                \n",
    "            else:\n",
    "                model.load_weights(model_path)\n",
    "                model_metrics = pd.read_csv(metric_path, header=0)\n",
    "                \n",
    "            print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "            \n",
    "            model_metrics['model_id'] = model_id\n",
    "            METRICs.append(model_metrics)\n",
    "            MODELs.append(model)\n",
    "        \n",
    "        METRIC_MEAN = pd.concat(METRICs).groupby('model_id').mean()\n",
    "        f1_best = METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0].f1_1\n",
    "        print(f'best f1 score: {f1_best}')\n",
    "        model_id += 1\n",
    "    if param_name in ['learning_rate']: # for float-type parameters\n",
    "        best_value = float(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "    else: # for int-type parameters\n",
    "        best_value = int(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(METRIC_MEAN)\n",
    "for key, value in search_space.items():\n",
    "    print(f'{key:<14} : {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape:  (12120, 420)\n",
      "data y shape:  (12120, 2)\n",
      "train x shape: (9696, 420)\n",
      "test  x shape: (2424, 2)\n"
     ]
    }
   ],
   "source": [
    "print('data x shape: ', data_x.shape)\n",
    "print('data y shape: ', data_y.shape)\n",
    "print('train x shape:', train_x.shape)\n",
    "print('test  x shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "for key, value in params.items():\n",
    "    print(f'{key:<14} : {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate model's general performance through Monte-Carlo cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape: (12120, 420)\n",
      "data y shape: (12120, 2)\n",
      "class y counts: [11672   448]\n",
      "class y ratio: [0.963 0.037]\n",
      "Epoch 1/10000\n",
      "228/228 - 1s - loss: 0.1746 - accuracy: 0.9570 - val_loss: 0.1436 - val_accuracy: 0.9662 - 1s/epoch - 5ms/step\n",
      "Epoch 2/10000\n",
      "228/228 - 1s - loss: 0.1394 - accuracy: 0.9630 - val_loss: 0.1442 - val_accuracy: 0.9662 - 602ms/epoch - 3ms/step\n",
      "Epoch 3/10000\n",
      "228/228 - 1s - loss: 0.1356 - accuracy: 0.9627 - val_loss: 0.1518 - val_accuracy: 0.9662 - 599ms/epoch - 3ms/step\n",
      "Epoch 4/10000\n",
      "228/228 - 1s - loss: 0.1298 - accuracy: 0.9630 - val_loss: 0.1530 - val_accuracy: 0.9658 - 711ms/epoch - 3ms/step\n",
      "Epoch 5/10000\n",
      "228/228 - 1s - loss: 0.1293 - accuracy: 0.9634 - val_loss: 0.1530 - val_accuracy: 0.9662 - 615ms/epoch - 3ms/step\n",
      "Epoch 6/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\n",
      "Cell \u001b[1;32mIn[13], line 60\u001b[0m\n",
      "\n",
      "\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path) \u001b[38;5;129;01mor\u001b[39;00m model_update:\n",
      "\n",
      "\u001b[0;32m     59\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\n",
      "\u001b[1;32m---> 60\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\n",
      "\u001b[0;32m     61\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m     62\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m     63\u001b[0m     time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\n",
      "\u001b[0;32m     64\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((time_end \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n",
      "\n",
      "\u001b[0;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n",
      "\n",
      "\u001b[0;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n",
      "\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n",
      "\n",
      "\u001b[0;32m   1605\u001b[0m     )\n",
      "\n",
      "\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n",
      "\n",
      "\u001b[0;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n",
      "\n",
      "\u001b[0;32m   1621\u001b[0m }\n",
      "\n",
      "\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n",
      "\n",
      "\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\n",
      "\u001b[0;32m   1945\u001b[0m ):\n",
      "\n",
      "\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n",
      "\n",
      "\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "\n",
      "\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\n",
      "\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\n",
      "\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\n",
      "\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\n",
      "\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\n",
      "\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n",
      "\n",
      "\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\n",
      "\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n",
      "\n",
      "\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\n",
      "\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\n",
      "\u001b[0;32m   2494\u001b[0m   (graph_function,\n",
      "\n",
      "\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "\n",
      "\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\n",
      "\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\n",
      "\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\n",
      "\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\n",
      "\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\n",
      "\u001b[0;32m   1865\u001b[0m     args,\n",
      "\n",
      "\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n",
      "\n",
      "\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n",
      "\n",
      "\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n",
      "\n",
      "\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\n",
      "\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n",
      "\n",
      "\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n",
      "\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n",
      "\n",
      "\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\n",
      "\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\n",
      "\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update = False\n",
    "            \n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "verbose = 0\n",
    "        \n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for name in protein_names:\n",
    "    data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "    ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "    \n",
    "    # get X dataset\n",
    "    x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "    x_features = list(x_onehot.columns)\n",
    "    \n",
    "    # get Y dataset\n",
    "    y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "    y_labels = list(y_onehot.columns)\n",
    "    \n",
    "    for idx in ST_idx:\n",
    "        window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "        label_y  = np.array(y_onehot.iloc[idx])\n",
    "        \n",
    "        data_x.append(window_x)\n",
    "        data_y.append(label_y)\n",
    "        \n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "print('data x shape:', data_x.shape)\n",
    "print('data y shape:', data_y.shape)\n",
    "print('class y counts:', data_y.sum(0))\n",
    "print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits = 5, test_size = test_size, random_state = SEED)\n",
    "for cv_idx, (train_idx, test_idx) in enumerate(splitter.split(data_x, data_y)):\n",
    "    train_x, train_y = data_x[train_idx], data_y[train_idx]\n",
    "    train_x, train_y = upsample_data(train_x, train_y) # up-sample the training dataset\n",
    "    test_x , test_y  = data_x[test_idx],  data_y[test_idx]\n",
    "    \n",
    "    train_x, test_x = data_scaling(train_x, test_x)\n",
    "    \n",
    "    model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params)\n",
    "    model_name = name_model(f'{model_type}', params)\n",
    "    \n",
    "    \n",
    "    model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "    model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "    metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(model_path) or model_update:\n",
    "        time_start = time.time()\n",
    "        history = model.fit(train_x, train_y, verbose=verbose, \n",
    "                            epochs = 10000, callbacks = callbacks,\n",
    "                            validation_split = test_size/(1-test_size))\n",
    "        time_end = time.time()\n",
    "        training_time = round((time_end - time_start)/60, 3)\n",
    "        \n",
    "        model.save_weights(model_path)\n",
    "        \n",
    "        test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "        model_metrics = {\n",
    "            'model_id' : model_id,\n",
    "            'cv_idx'   : cv_idx,\n",
    "            **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "            'train_y'     : train_y.shape[-1],\n",
    "            'test_size'   : test_x.shape[0],\n",
    "            **params,\n",
    "            'regularizer_input' : params['regularizer']['input'],\n",
    "            'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "            'regularizer_bias' : params['regularizer']['bias'],\n",
    "            'training_time': training_time,\n",
    "            'test_loss': test_loss,\n",
    "            'accuracy': accuracy,\n",
    "            **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "            **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "            **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "        model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "        model_metrics.to_csv(metric_path, index=False)\n",
    "        \n",
    "    else:\n",
    "        model.load_weights(model_path)\n",
    "        model_metrics = pd.read_csv(metric_path, header=0)\n",
    "        \n",
    "    print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "    \n",
    "    METRICs.append(model_metrics)\n",
    "    MODELs.append(model)\n",
    "\n",
    "METRICs = pd.concat(METRICs)\n",
    "METRIC_MEAN = METRICs.groupby('model_id').mean()\n",
    "METRIC_STD = METRICs.groupby('model_id').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# function ConnectButton(){\n",
    "#     console.log(\"Connect pushed\");\n",
    "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
    "# }\n",
    "\n",
    "# setInterval(ConnectButton,60000);\n",
    "# '''\n",
    "\n",
    "# from google.colab import drive\n",
    "# from os import chdir\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# project_path = '/content/drive/MyDrive/Gproject/o-linked-site-prediction-feature-augment'\n",
    "# chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed for the reproducible result\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of initial proteins: 104\n",
      "['A2ABU4', 'A2AHJ4', 'A2AKB9', 'A2AQ25', 'E9Q1P8', 'E9Q5G3', 'O08537', 'O09061', 'O35303', 'O70263']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/integrated_features' # we will get names from the augmented proteins\n",
    "protein_names = [x.split('.')[0] for x in os.listdir(data_dir) if x.split('.')[1] == 'csv'] # get protein name list to be processed for building machine learning models\n",
    "print('the number of initial proteins:', len(protein_names))\n",
    "print(protein_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameter optimization by K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from ml_models import *\n",
    "\n",
    "epochs = 1000\n",
    "from keras.callbacks import EarlyStopping\n",
    "patience = 30\n",
    "callbacks = [EarlyStopping(patience=patience, restore_best_weights=True, monitor='val_loss')]\n",
    "\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters\n",
      "rnn_layers     : 1\n",
      "rnn_neurons    : 64\n",
      "dnn_layers     : 3\n",
      "dnn_neurons    : 64\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "initial_params = default_params.copy()\n",
    "initial_params.update({\n",
    "    'window_size'    : 10\n",
    "    })\n",
    "\n",
    "print('initial parameters')\n",
    "for key, value in initial_params.items():\n",
    "    print(f'{key:<14} : {value}')\n",
    "\n",
    "search_space = {\n",
    "    'rnn_layers'    : [1, 2, 3, 4, 5],\n",
    "    'rnn_neurons'   : [32, 64, 128, 256],\n",
    "    'dnn_layers'    : [1, 2, 3, 4, 5],\n",
    "    'dnn_neurons'   : [32, 64, 128, 256],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of augmented features: 498\n",
      "continuous features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'number_hydrophobic_0A',\n",
       " 1: 'number_hydrophilic_0A',\n",
       " 2: 'number_polar_0A',\n",
       " 3: 'number_aromatic_0A',\n",
       " 4: 'number_aliphatic_0A',\n",
       " 5: 'number_charged_0A',\n",
       " 6: 'number_positive_0A',\n",
       " 7: 'number_negative_0A',\n",
       " 8: 'number_gly_0A',\n",
       " 9: 'number_very_small_0A',\n",
       " 10: 'number_small_0A',\n",
       " 11: 'number_normal_0A',\n",
       " 12: 'number_long_0A',\n",
       " 13: 'number_pro_0A',\n",
       " 14: 'number_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 15: 'number_b_polar_uncharged_with_amide_0A',\n",
       " 16: 'number_d_negatively_charged_polar_0A',\n",
       " 17: 'number_e_non_polar_suffered_0A',\n",
       " 18: 'number_f_non_polar_aromatic_0A',\n",
       " 19: 'number_ala_0A',\n",
       " 20: 'number_cys_0A',\n",
       " 21: 'number_asp_0A',\n",
       " 22: 'number_glu_0A',\n",
       " 23: 'number_phe_0A',\n",
       " 24: 'number_his_0A',\n",
       " 25: 'number_ile_0A',\n",
       " 26: 'number_lys_0A',\n",
       " 27: 'number_leu_0A',\n",
       " 28: 'number_met_0A',\n",
       " 29: 'number_asn_0A',\n",
       " 30: 'number_gln_0A',\n",
       " 31: 'number_arg_0A',\n",
       " 32: 'number_ser_0A',\n",
       " 33: 'number_thr_0A',\n",
       " 34: 'number_val_0A',\n",
       " 35: 'number_trp_0A',\n",
       " 36: 'number_tyr_0A',\n",
       " 37: 'sasa_hydrophobic_0A',\n",
       " 38: 'sasa_hydrophilic_0A',\n",
       " 39: 'sasa_polar_0A',\n",
       " 40: 'sasa_aromatic_0A',\n",
       " 41: 'sasa_aliphatic_0A',\n",
       " 42: 'sasa_charged_0A',\n",
       " 43: 'sasa_positive_0A',\n",
       " 44: 'sasa_negative_0A',\n",
       " 45: 'sasa_gly_0A',\n",
       " 46: 'sasa_very_small_0A',\n",
       " 47: 'sasa_small_0A',\n",
       " 48: 'sasa_normal_0A',\n",
       " 49: 'sasa_long_0A',\n",
       " 50: 'sasa_pro_0A',\n",
       " 51: 'sasa_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 52: 'sasa_b_polar_uncharged_with_amide_0A',\n",
       " 53: 'sasa_d_negatively_charged_polar_0A',\n",
       " 54: 'sasa_e_non_polar_suffered_0A',\n",
       " 55: 'sasa_f_non_polar_aromatic_0A',\n",
       " 56: 'sasa_ala_0A',\n",
       " 57: 'sasa_cys_0A',\n",
       " 58: 'sasa_asp_0A',\n",
       " 59: 'sasa_glu_0A',\n",
       " 60: 'sasa_phe_0A',\n",
       " 61: 'sasa_his_0A',\n",
       " 62: 'sasa_ile_0A',\n",
       " 63: 'sasa_lys_0A',\n",
       " 64: 'sasa_leu_0A',\n",
       " 65: 'sasa_met_0A',\n",
       " 66: 'sasa_asn_0A',\n",
       " 67: 'sasa_gln_0A',\n",
       " 68: 'sasa_arg_0A',\n",
       " 69: 'sasa_ser_0A',\n",
       " 70: 'sasa_thr_0A',\n",
       " 71: 'sasa_val_0A',\n",
       " 72: 'sasa_trp_0A',\n",
       " 73: 'sasa_tyr_0A',\n",
       " 74: 'sasa_back_0A',\n",
       " 75: 'sasa_side_0A',\n",
       " 76: 'sasa_target_ser_thr_0A',\n",
       " 77: 'net_charge_all_0A',\n",
       " 78: 'net_charge_backbone_0A',\n",
       " 79: 'net_charge_sidechain_0A',\n",
       " 80: 'net_charge_all_exposed_0A',\n",
       " 81: 'net_charge_backbone_exposed_0A',\n",
       " 82: 'net_charge_sidechain_exposed_0A',\n",
       " 83: 'number_hydrophobic_5A',\n",
       " 84: 'number_hydrophilic_5A',\n",
       " 85: 'number_polar_5A',\n",
       " 86: 'number_aromatic_5A',\n",
       " 87: 'number_aliphatic_5A',\n",
       " 88: 'number_charged_5A',\n",
       " 89: 'number_positive_5A',\n",
       " 90: 'number_negative_5A',\n",
       " 91: 'number_gly_5A',\n",
       " 92: 'number_very_small_5A',\n",
       " 93: 'number_small_5A',\n",
       " 94: 'number_normal_5A',\n",
       " 95: 'number_long_5A',\n",
       " 96: 'number_pro_5A',\n",
       " 97: 'number_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 98: 'number_b_polar_uncharged_with_amide_5A',\n",
       " 99: 'number_d_negatively_charged_polar_5A',\n",
       " 100: 'number_e_non_polar_suffered_5A',\n",
       " 101: 'number_f_non_polar_aromatic_5A',\n",
       " 102: 'number_ala_5A',\n",
       " 103: 'number_cys_5A',\n",
       " 104: 'number_asp_5A',\n",
       " 105: 'number_glu_5A',\n",
       " 106: 'number_phe_5A',\n",
       " 107: 'number_his_5A',\n",
       " 108: 'number_ile_5A',\n",
       " 109: 'number_lys_5A',\n",
       " 110: 'number_leu_5A',\n",
       " 111: 'number_met_5A',\n",
       " 112: 'number_asn_5A',\n",
       " 113: 'number_gln_5A',\n",
       " 114: 'number_arg_5A',\n",
       " 115: 'number_ser_5A',\n",
       " 116: 'number_thr_5A',\n",
       " 117: 'number_val_5A',\n",
       " 118: 'number_trp_5A',\n",
       " 119: 'number_tyr_5A',\n",
       " 120: 'sasa_hydrophobic_5A',\n",
       " 121: 'sasa_hydrophilic_5A',\n",
       " 122: 'sasa_polar_5A',\n",
       " 123: 'sasa_aromatic_5A',\n",
       " 124: 'sasa_aliphatic_5A',\n",
       " 125: 'sasa_charged_5A',\n",
       " 126: 'sasa_positive_5A',\n",
       " 127: 'sasa_negative_5A',\n",
       " 128: 'sasa_gly_5A',\n",
       " 129: 'sasa_very_small_5A',\n",
       " 130: 'sasa_small_5A',\n",
       " 131: 'sasa_normal_5A',\n",
       " 132: 'sasa_long_5A',\n",
       " 133: 'sasa_pro_5A',\n",
       " 134: 'sasa_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 135: 'sasa_b_polar_uncharged_with_amide_5A',\n",
       " 136: 'sasa_d_negatively_charged_polar_5A',\n",
       " 137: 'sasa_e_non_polar_suffered_5A',\n",
       " 138: 'sasa_f_non_polar_aromatic_5A',\n",
       " 139: 'sasa_ala_5A',\n",
       " 140: 'sasa_cys_5A',\n",
       " 141: 'sasa_asp_5A',\n",
       " 142: 'sasa_glu_5A',\n",
       " 143: 'sasa_phe_5A',\n",
       " 144: 'sasa_his_5A',\n",
       " 145: 'sasa_ile_5A',\n",
       " 146: 'sasa_lys_5A',\n",
       " 147: 'sasa_leu_5A',\n",
       " 148: 'sasa_met_5A',\n",
       " 149: 'sasa_asn_5A',\n",
       " 150: 'sasa_gln_5A',\n",
       " 151: 'sasa_arg_5A',\n",
       " 152: 'sasa_ser_5A',\n",
       " 153: 'sasa_thr_5A',\n",
       " 154: 'sasa_val_5A',\n",
       " 155: 'sasa_trp_5A',\n",
       " 156: 'sasa_tyr_5A',\n",
       " 157: 'sasa_back_5A',\n",
       " 158: 'sasa_side_5A',\n",
       " 159: 'sasa_target_ser_thr_5A',\n",
       " 160: 'net_charge_all_5A',\n",
       " 161: 'net_charge_backbone_5A',\n",
       " 162: 'net_charge_sidechain_5A',\n",
       " 163: 'net_charge_all_exposed_5A',\n",
       " 164: 'net_charge_backbone_exposed_5A',\n",
       " 165: 'net_charge_sidechain_exposed_5A',\n",
       " 166: 'number_hydrophobic_10A',\n",
       " 167: 'number_hydrophilic_10A',\n",
       " 168: 'number_polar_10A',\n",
       " 169: 'number_aromatic_10A',\n",
       " 170: 'number_aliphatic_10A',\n",
       " 171: 'number_charged_10A',\n",
       " 172: 'number_positive_10A',\n",
       " 173: 'number_negative_10A',\n",
       " 174: 'number_gly_10A',\n",
       " 175: 'number_very_small_10A',\n",
       " 176: 'number_small_10A',\n",
       " 177: 'number_normal_10A',\n",
       " 178: 'number_long_10A',\n",
       " 179: 'number_pro_10A',\n",
       " 180: 'number_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 181: 'number_b_polar_uncharged_with_amide_10A',\n",
       " 182: 'number_d_negatively_charged_polar_10A',\n",
       " 183: 'number_e_non_polar_suffered_10A',\n",
       " 184: 'number_f_non_polar_aromatic_10A',\n",
       " 185: 'number_ala_10A',\n",
       " 186: 'number_cys_10A',\n",
       " 187: 'number_asp_10A',\n",
       " 188: 'number_glu_10A',\n",
       " 189: 'number_phe_10A',\n",
       " 190: 'number_his_10A',\n",
       " 191: 'number_ile_10A',\n",
       " 192: 'number_lys_10A',\n",
       " 193: 'number_leu_10A',\n",
       " 194: 'number_met_10A',\n",
       " 195: 'number_asn_10A',\n",
       " 196: 'number_gln_10A',\n",
       " 197: 'number_arg_10A',\n",
       " 198: 'number_ser_10A',\n",
       " 199: 'number_thr_10A',\n",
       " 200: 'number_val_10A',\n",
       " 201: 'number_trp_10A',\n",
       " 202: 'number_tyr_10A',\n",
       " 203: 'sasa_hydrophobic_10A',\n",
       " 204: 'sasa_hydrophilic_10A',\n",
       " 205: 'sasa_polar_10A',\n",
       " 206: 'sasa_aromatic_10A',\n",
       " 207: 'sasa_aliphatic_10A',\n",
       " 208: 'sasa_charged_10A',\n",
       " 209: 'sasa_positive_10A',\n",
       " 210: 'sasa_negative_10A',\n",
       " 211: 'sasa_gly_10A',\n",
       " 212: 'sasa_very_small_10A',\n",
       " 213: 'sasa_small_10A',\n",
       " 214: 'sasa_normal_10A',\n",
       " 215: 'sasa_long_10A',\n",
       " 216: 'sasa_pro_10A',\n",
       " 217: 'sasa_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 218: 'sasa_b_polar_uncharged_with_amide_10A',\n",
       " 219: 'sasa_d_negatively_charged_polar_10A',\n",
       " 220: 'sasa_e_non_polar_suffered_10A',\n",
       " 221: 'sasa_f_non_polar_aromatic_10A',\n",
       " 222: 'sasa_ala_10A',\n",
       " 223: 'sasa_cys_10A',\n",
       " 224: 'sasa_asp_10A',\n",
       " 225: 'sasa_glu_10A',\n",
       " 226: 'sasa_phe_10A',\n",
       " 227: 'sasa_his_10A',\n",
       " 228: 'sasa_ile_10A',\n",
       " 229: 'sasa_lys_10A',\n",
       " 230: 'sasa_leu_10A',\n",
       " 231: 'sasa_met_10A',\n",
       " 232: 'sasa_asn_10A',\n",
       " 233: 'sasa_gln_10A',\n",
       " 234: 'sasa_arg_10A',\n",
       " 235: 'sasa_ser_10A',\n",
       " 236: 'sasa_thr_10A',\n",
       " 237: 'sasa_val_10A',\n",
       " 238: 'sasa_trp_10A',\n",
       " 239: 'sasa_tyr_10A',\n",
       " 240: 'sasa_back_10A',\n",
       " 241: 'sasa_side_10A',\n",
       " 242: 'sasa_target_ser_thr_10A',\n",
       " 243: 'net_charge_all_10A',\n",
       " 244: 'net_charge_backbone_10A',\n",
       " 245: 'net_charge_sidechain_10A',\n",
       " 246: 'net_charge_all_exposed_10A',\n",
       " 247: 'net_charge_backbone_exposed_10A',\n",
       " 248: 'net_charge_sidechain_exposed_10A',\n",
       " 249: 'number_hydrophobic_15A',\n",
       " 250: 'number_hydrophilic_15A',\n",
       " 251: 'number_polar_15A',\n",
       " 252: 'number_aromatic_15A',\n",
       " 253: 'number_aliphatic_15A',\n",
       " 254: 'number_charged_15A',\n",
       " 255: 'number_positive_15A',\n",
       " 256: 'number_negative_15A',\n",
       " 257: 'number_gly_15A',\n",
       " 258: 'number_very_small_15A',\n",
       " 259: 'number_small_15A',\n",
       " 260: 'number_normal_15A',\n",
       " 261: 'number_long_15A',\n",
       " 262: 'number_pro_15A',\n",
       " 263: 'number_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 264: 'number_b_polar_uncharged_with_amide_15A',\n",
       " 265: 'number_d_negatively_charged_polar_15A',\n",
       " 266: 'number_e_non_polar_suffered_15A',\n",
       " 267: 'number_f_non_polar_aromatic_15A',\n",
       " 268: 'number_ala_15A',\n",
       " 269: 'number_cys_15A',\n",
       " 270: 'number_asp_15A',\n",
       " 271: 'number_glu_15A',\n",
       " 272: 'number_phe_15A',\n",
       " 273: 'number_his_15A',\n",
       " 274: 'number_ile_15A',\n",
       " 275: 'number_lys_15A',\n",
       " 276: 'number_leu_15A',\n",
       " 277: 'number_met_15A',\n",
       " 278: 'number_asn_15A',\n",
       " 279: 'number_gln_15A',\n",
       " 280: 'number_arg_15A',\n",
       " 281: 'number_ser_15A',\n",
       " 282: 'number_thr_15A',\n",
       " 283: 'number_val_15A',\n",
       " 284: 'number_trp_15A',\n",
       " 285: 'number_tyr_15A',\n",
       " 286: 'sasa_hydrophobic_15A',\n",
       " 287: 'sasa_hydrophilic_15A',\n",
       " 288: 'sasa_polar_15A',\n",
       " 289: 'sasa_aromatic_15A',\n",
       " 290: 'sasa_aliphatic_15A',\n",
       " 291: 'sasa_charged_15A',\n",
       " 292: 'sasa_positive_15A',\n",
       " 293: 'sasa_negative_15A',\n",
       " 294: 'sasa_gly_15A',\n",
       " 295: 'sasa_very_small_15A',\n",
       " 296: 'sasa_small_15A',\n",
       " 297: 'sasa_normal_15A',\n",
       " 298: 'sasa_long_15A',\n",
       " 299: 'sasa_pro_15A',\n",
       " 300: 'sasa_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 301: 'sasa_b_polar_uncharged_with_amide_15A',\n",
       " 302: 'sasa_d_negatively_charged_polar_15A',\n",
       " 303: 'sasa_e_non_polar_suffered_15A',\n",
       " 304: 'sasa_f_non_polar_aromatic_15A',\n",
       " 305: 'sasa_ala_15A',\n",
       " 306: 'sasa_cys_15A',\n",
       " 307: 'sasa_asp_15A',\n",
       " 308: 'sasa_glu_15A',\n",
       " 309: 'sasa_phe_15A',\n",
       " 310: 'sasa_his_15A',\n",
       " 311: 'sasa_ile_15A',\n",
       " 312: 'sasa_lys_15A',\n",
       " 313: 'sasa_leu_15A',\n",
       " 314: 'sasa_met_15A',\n",
       " 315: 'sasa_asn_15A',\n",
       " 316: 'sasa_gln_15A',\n",
       " 317: 'sasa_arg_15A',\n",
       " 318: 'sasa_ser_15A',\n",
       " 319: 'sasa_thr_15A',\n",
       " 320: 'sasa_val_15A',\n",
       " 321: 'sasa_trp_15A',\n",
       " 322: 'sasa_tyr_15A',\n",
       " 323: 'sasa_back_15A',\n",
       " 324: 'sasa_side_15A',\n",
       " 325: 'sasa_target_ser_thr_15A',\n",
       " 326: 'net_charge_all_15A',\n",
       " 327: 'net_charge_backbone_15A',\n",
       " 328: 'net_charge_sidechain_15A',\n",
       " 329: 'net_charge_all_exposed_15A',\n",
       " 330: 'net_charge_backbone_exposed_15A',\n",
       " 331: 'net_charge_sidechain_exposed_15A',\n",
       " 332: 'number_hydrophobic_20A',\n",
       " 333: 'number_hydrophilic_20A',\n",
       " 334: 'number_polar_20A',\n",
       " 335: 'number_aromatic_20A',\n",
       " 336: 'number_aliphatic_20A',\n",
       " 337: 'number_charged_20A',\n",
       " 338: 'number_positive_20A',\n",
       " 339: 'number_negative_20A',\n",
       " 340: 'number_gly_20A',\n",
       " 341: 'number_very_small_20A',\n",
       " 342: 'number_small_20A',\n",
       " 343: 'number_normal_20A',\n",
       " 344: 'number_long_20A',\n",
       " 345: 'number_pro_20A',\n",
       " 346: 'number_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 347: 'number_b_polar_uncharged_with_amide_20A',\n",
       " 348: 'number_d_negatively_charged_polar_20A',\n",
       " 349: 'number_e_non_polar_suffered_20A',\n",
       " 350: 'number_f_non_polar_aromatic_20A',\n",
       " 351: 'number_ala_20A',\n",
       " 352: 'number_cys_20A',\n",
       " 353: 'number_asp_20A',\n",
       " 354: 'number_glu_20A',\n",
       " 355: 'number_phe_20A',\n",
       " 356: 'number_his_20A',\n",
       " 357: 'number_ile_20A',\n",
       " 358: 'number_lys_20A',\n",
       " 359: 'number_leu_20A',\n",
       " 360: 'number_met_20A',\n",
       " 361: 'number_asn_20A',\n",
       " 362: 'number_gln_20A',\n",
       " 363: 'number_arg_20A',\n",
       " 364: 'number_ser_20A',\n",
       " 365: 'number_thr_20A',\n",
       " 366: 'number_val_20A',\n",
       " 367: 'number_trp_20A',\n",
       " 368: 'number_tyr_20A',\n",
       " 369: 'sasa_hydrophobic_20A',\n",
       " 370: 'sasa_hydrophilic_20A',\n",
       " 371: 'sasa_polar_20A',\n",
       " 372: 'sasa_aromatic_20A',\n",
       " 373: 'sasa_aliphatic_20A',\n",
       " 374: 'sasa_charged_20A',\n",
       " 375: 'sasa_positive_20A',\n",
       " 376: 'sasa_negative_20A',\n",
       " 377: 'sasa_gly_20A',\n",
       " 378: 'sasa_very_small_20A',\n",
       " 379: 'sasa_small_20A',\n",
       " 380: 'sasa_normal_20A',\n",
       " 381: 'sasa_long_20A',\n",
       " 382: 'sasa_pro_20A',\n",
       " 383: 'sasa_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 384: 'sasa_b_polar_uncharged_with_amide_20A',\n",
       " 385: 'sasa_d_negatively_charged_polar_20A',\n",
       " 386: 'sasa_e_non_polar_suffered_20A',\n",
       " 387: 'sasa_f_non_polar_aromatic_20A',\n",
       " 388: 'sasa_ala_20A',\n",
       " 389: 'sasa_cys_20A',\n",
       " 390: 'sasa_asp_20A',\n",
       " 391: 'sasa_glu_20A',\n",
       " 392: 'sasa_phe_20A',\n",
       " 393: 'sasa_his_20A',\n",
       " 394: 'sasa_ile_20A',\n",
       " 395: 'sasa_lys_20A',\n",
       " 396: 'sasa_leu_20A',\n",
       " 397: 'sasa_met_20A',\n",
       " 398: 'sasa_asn_20A',\n",
       " 399: 'sasa_gln_20A',\n",
       " 400: 'sasa_arg_20A',\n",
       " 401: 'sasa_ser_20A',\n",
       " 402: 'sasa_thr_20A',\n",
       " 403: 'sasa_val_20A',\n",
       " 404: 'sasa_trp_20A',\n",
       " 405: 'sasa_tyr_20A',\n",
       " 406: 'sasa_back_20A',\n",
       " 407: 'sasa_side_20A',\n",
       " 408: 'sasa_target_ser_thr_20A',\n",
       " 409: 'net_charge_all_20A',\n",
       " 410: 'net_charge_backbone_20A',\n",
       " 411: 'net_charge_sidechain_20A',\n",
       " 412: 'net_charge_all_exposed_20A',\n",
       " 413: 'net_charge_backbone_exposed_20A',\n",
       " 414: 'net_charge_sidechain_exposed_20A',\n",
       " 415: 'number_hydrophobic_25A',\n",
       " 416: 'number_hydrophilic_25A',\n",
       " 417: 'number_polar_25A',\n",
       " 418: 'number_aromatic_25A',\n",
       " 419: 'number_aliphatic_25A',\n",
       " 420: 'number_charged_25A',\n",
       " 421: 'number_positive_25A',\n",
       " 422: 'number_negative_25A',\n",
       " 423: 'number_gly_25A',\n",
       " 424: 'number_very_small_25A',\n",
       " 425: 'number_small_25A',\n",
       " 426: 'number_normal_25A',\n",
       " 427: 'number_long_25A',\n",
       " 428: 'number_pro_25A',\n",
       " 429: 'number_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 430: 'number_b_polar_uncharged_with_amide_25A',\n",
       " 431: 'number_d_negatively_charged_polar_25A',\n",
       " 432: 'number_e_non_polar_suffered_25A',\n",
       " 433: 'number_f_non_polar_aromatic_25A',\n",
       " 434: 'number_ala_25A',\n",
       " 435: 'number_cys_25A',\n",
       " 436: 'number_asp_25A',\n",
       " 437: 'number_glu_25A',\n",
       " 438: 'number_phe_25A',\n",
       " 439: 'number_his_25A',\n",
       " 440: 'number_ile_25A',\n",
       " 441: 'number_lys_25A',\n",
       " 442: 'number_leu_25A',\n",
       " 443: 'number_met_25A',\n",
       " 444: 'number_asn_25A',\n",
       " 445: 'number_gln_25A',\n",
       " 446: 'number_arg_25A',\n",
       " 447: 'number_ser_25A',\n",
       " 448: 'number_thr_25A',\n",
       " 449: 'number_val_25A',\n",
       " 450: 'number_trp_25A',\n",
       " 451: 'number_tyr_25A',\n",
       " 452: 'sasa_hydrophobic_25A',\n",
       " 453: 'sasa_hydrophilic_25A',\n",
       " 454: 'sasa_polar_25A',\n",
       " 455: 'sasa_aromatic_25A',\n",
       " 456: 'sasa_aliphatic_25A',\n",
       " 457: 'sasa_charged_25A',\n",
       " 458: 'sasa_positive_25A',\n",
       " 459: 'sasa_negative_25A',\n",
       " 460: 'sasa_gly_25A',\n",
       " 461: 'sasa_very_small_25A',\n",
       " 462: 'sasa_small_25A',\n",
       " 463: 'sasa_normal_25A',\n",
       " 464: 'sasa_long_25A',\n",
       " 465: 'sasa_pro_25A',\n",
       " 466: 'sasa_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 467: 'sasa_b_polar_uncharged_with_amide_25A',\n",
       " 468: 'sasa_d_negatively_charged_polar_25A',\n",
       " 469: 'sasa_e_non_polar_suffered_25A',\n",
       " 470: 'sasa_f_non_polar_aromatic_25A',\n",
       " 471: 'sasa_ala_25A',\n",
       " 472: 'sasa_cys_25A',\n",
       " 473: 'sasa_asp_25A',\n",
       " 474: 'sasa_glu_25A',\n",
       " 475: 'sasa_phe_25A',\n",
       " 476: 'sasa_his_25A',\n",
       " 477: 'sasa_ile_25A',\n",
       " 478: 'sasa_lys_25A',\n",
       " 479: 'sasa_leu_25A',\n",
       " 480: 'sasa_met_25A',\n",
       " 481: 'sasa_asn_25A',\n",
       " 482: 'sasa_gln_25A',\n",
       " 483: 'sasa_arg_25A',\n",
       " 484: 'sasa_ser_25A',\n",
       " 485: 'sasa_thr_25A',\n",
       " 486: 'sasa_val_25A',\n",
       " 487: 'sasa_trp_25A',\n",
       " 488: 'sasa_tyr_25A',\n",
       " 489: 'sasa_back_25A',\n",
       " 490: 'sasa_side_25A',\n",
       " 491: 'sasa_target_ser_thr_25A',\n",
       " 492: 'net_charge_all_25A',\n",
       " 493: 'net_charge_backbone_25A',\n",
       " 494: 'net_charge_sidechain_25A',\n",
       " 495: 'net_charge_all_exposed_25A',\n",
       " 496: 'net_charge_backbone_exposed_25A',\n",
       " 497: 'net_charge_sidechain_exposed_25A'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:\n",
      "{0: 'residue'}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'LSTM_UP_AUGMENT'\n",
    "\n",
    "augmented_columns = dict(pd.read_csv('./data/augmented_columns.csv', header=0).values.squeeze())\n",
    "print('# of augmented features:', len(augmented_columns))\n",
    "\n",
    "# set continuous input features\n",
    "x_cts = [x for x in augmented_columns.keys() if augmented_columns.get(x) != 'object']\n",
    "print('continuous features:')\n",
    "display(dict(zip(range(len(x_cts)), x_cts)))\n",
    "\n",
    "# set categorical input features\n",
    "x_cat = ['residue'] + \\\n",
    "        [x for x in augmented_columns.keys() if augmented_columns.get(x) == 'object']\n",
    "print('categorical features:')\n",
    "print(dict(zip(range(len(x_cat)), x_cat)))\n",
    "\n",
    "# input features\n",
    "x_var = x_cts + x_cat\n",
    "\n",
    "# set continuos output feature\n",
    "y_cts = []\n",
    "\n",
    "# set categorical output feature\n",
    "y_cat = ['positivity']\n",
    "\n",
    "# output features\n",
    "y_var = y_cts + y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build amino acid sequence dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model training with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_layers     : [1, 2, 3, 4, 5]\n",
      "rnn_neurons    : [32, 64, 128, 256]\n",
      "dnn_layers     : [1, 2, 3, 4, 5]\n",
      "dnn_neurons    : [32, 64, 128, 256]\n",
      "learning_rate  : [0.0001, 0.001, 0.01]\n",
      "data x shape: (11858, 21, 73)\n",
      "data y shape: (11858, 2)\n",
      "class y counts: [11429   429]\n",
      "class y ratio: [0.9638 0.0362]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[12], line 81\u001b[0m\n",
      "\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path) \u001b[38;5;129;01mor\u001b[39;00m model_update:\n",
      "\u001b[0;32m     80\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;32m---> 81\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[0;32m     82\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     83\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y_kf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     84\u001b[0m     time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;32m     85\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((time_end \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n",
      "\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n",
      "\u001b[0;32m   1562\u001b[0m ):\n",
      "\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n",
      "\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n",
      "\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n",
      "\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n",
      "\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n",
      "\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\u001b[0;32m   2494\u001b[0m   (graph_function,\n",
      "\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\u001b[0;32m   1865\u001b[0m     args,\n",
      "\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n",
      "\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n",
      "\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n",
      "\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n",
      "\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update  = False\n",
    "\n",
    "params = initial_params.copy()\n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "model_id = 1\n",
    "verbose = 0\n",
    "for param_name, space in search_space.items():\n",
    "    for point in space:\n",
    "        clear_output(wait=True)\n",
    "        display(METRIC_MEAN)\n",
    "        params[param_name] = point\n",
    "        for key, value in search_space.items():\n",
    "            print(f'{key:<14} : {value}')\n",
    "        \n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        for name in protein_names:\n",
    "            data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "            ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "            \n",
    "            # get X dataset\n",
    "            x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "            x_features = list(x_onehot.columns)\n",
    "            \n",
    "            # get Y dataset\n",
    "            y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "            y_labels = list(y_onehot.columns)\n",
    "            \n",
    "            for idx in ST_idx:\n",
    "                window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "                label_y  = np.array(y_onehot.iloc[idx])\n",
    "                \n",
    "                data_x.append(window_x)\n",
    "                data_y.append(label_y)\n",
    "                \n",
    "        data_x = np.array(data_x)\n",
    "        data_y = np.array(data_y)\n",
    "        model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "        print('data x shape:', data_x.shape)\n",
    "        print('data y shape:', data_y.shape)\n",
    "        print('class y counts:', data_y.sum(0))\n",
    "        print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "        \n",
    "        splitter = StratifiedShuffleSplit(n_splits = 1, test_size = test_size, random_state = SEED)\n",
    "        train_idx, test_idx = list(splitter.split(data_x, data_y))[0]\n",
    "        \n",
    "        train_x = data_x[train_idx]\n",
    "        train_y = data_y[train_idx]\n",
    "        \n",
    "        test_x = data_x[test_idx]\n",
    "        test_y = data_y[test_idx]\n",
    "        \n",
    "        train_x, test_x = data_scaling(train_x, test_x)\n",
    "        \n",
    "        splitter_kf = KFold(n_splits = 5)\n",
    "        for cv_idx, (train_idx_kf, test_idx_kf) in enumerate(splitter_kf.split(train_x, train_y)):\n",
    "            train_x_kf, train_y_kf = train_x[train_idx_kf], train_y[train_idx_kf]\n",
    "            test_x_kf, test_y_kf   = train_x[test_idx_kf],  train_y[test_idx_kf]\n",
    "            \n",
    "            # up-sample the training dataset\n",
    "            train_x_kf, train_y_kf = upsample_data(train_x_kf, train_y_kf) \n",
    "            \n",
    "            model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) \n",
    "            model_name = name_model(f'{model_type}_KFOLD', params)\n",
    "            \n",
    "            model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "            if not os.path.exists(model_folder):\n",
    "                os.makedirs(model_folder)\n",
    "            model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "            metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(model_path) or model_update:\n",
    "                time_start = time.time()\n",
    "                history = model.fit(train_x_kf, train_y_kf, verbose=verbose, \n",
    "                                    epochs = 10000, callbacks = callbacks,\n",
    "                                    validation_data = (test_x_kf, test_y_kf))\n",
    "                time_end = time.time()\n",
    "                training_time = round((time_end - time_start)/60, 3)\n",
    "                \n",
    "                model.save_weights(model_path)\n",
    "                \n",
    "                test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "                model_metrics = {\n",
    "                    'model_id' : model_id,\n",
    "                    'cv_idx'   : cv_idx,\n",
    "                    **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "                    'train_y'     : train_y.shape[-1],\n",
    "                    'test_size'   : test_x.shape[0],\n",
    "                    **params,\n",
    "                    'regularizer_input' : params['regularizer']['input'],\n",
    "                    'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "                    'regularizer_bias' : params['regularizer']['bias'],\n",
    "                    'training_time': training_time,\n",
    "                    'test_loss': test_loss,\n",
    "                    'accuracy': accuracy,\n",
    "                    **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "                    **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "                    **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "                \n",
    "                model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "                model_metrics.to_csv(metric_path, index=False)\n",
    "                \n",
    "            else:\n",
    "                model.load_weights(model_path)\n",
    "                model_metrics = pd.read_csv(metric_path, header=0)\n",
    "                \n",
    "            print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "            \n",
    "            model_metrics['model_id'] = model_id\n",
    "            METRICs.append(model_metrics)\n",
    "            MODELs.append(model)\n",
    "        \n",
    "        METRIC_MEAN = pd.concat(METRICs).groupby('model_id').mean()\n",
    "        f1_best = METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0].f1_1\n",
    "        print(f'best f1 score: {f1_best}')\n",
    "        model_id += 1\n",
    "    if param_name in ['learning_rate']: # for float-type parameters\n",
    "        best_value = float(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "    else: # for int-type parameters\n",
    "        best_value = int(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(METRIC_MEAN)\n",
    "for key, value in search_space.items():\n",
    "    print(f'{key:<14} : {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape:  (12120, 420)\n",
      "data y shape:  (12120, 2)\n",
      "train x shape: (9696, 420)\n",
      "test  x shape: (2424, 2)\n"
     ]
    }
   ],
   "source": [
    "print('data x shape: ', data_x.shape)\n",
    "print('data y shape: ', data_y.shape)\n",
    "print('train x shape:', train_x.shape)\n",
    "print('test  x shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "for key, value in params.items():\n",
    "    print(f'{key:<14} : {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate model's general performance through Monte-Carlo cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape: (12120, 420)\n",
      "data y shape: (12120, 2)\n",
      "class y counts: [11672   448]\n",
      "class y ratio: [0.963 0.037]\n",
      "Epoch 1/10000\n",
      "228/228 - 1s - loss: 0.1746 - accuracy: 0.9570 - val_loss: 0.1436 - val_accuracy: 0.9662 - 1s/epoch - 5ms/step\n",
      "Epoch 2/10000\n",
      "228/228 - 1s - loss: 0.1394 - accuracy: 0.9630 - val_loss: 0.1442 - val_accuracy: 0.9662 - 602ms/epoch - 3ms/step\n",
      "Epoch 3/10000\n",
      "228/228 - 1s - loss: 0.1356 - accuracy: 0.9627 - val_loss: 0.1518 - val_accuracy: 0.9662 - 599ms/epoch - 3ms/step\n",
      "Epoch 4/10000\n",
      "228/228 - 1s - loss: 0.1298 - accuracy: 0.9630 - val_loss: 0.1530 - val_accuracy: 0.9658 - 711ms/epoch - 3ms/step\n",
      "Epoch 5/10000\n",
      "228/228 - 1s - loss: 0.1293 - accuracy: 0.9634 - val_loss: 0.1530 - val_accuracy: 0.9662 - 615ms/epoch - 3ms/step\n",
      "Epoch 6/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\n",
      "Cell \u001b[1;32mIn[13], line 60\u001b[0m\n",
      "\n",
      "\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path) \u001b[38;5;129;01mor\u001b[39;00m model_update:\n",
      "\n",
      "\u001b[0;32m     59\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\n",
      "\u001b[1;32m---> 60\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\n",
      "\u001b[0;32m     61\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m     62\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m     63\u001b[0m     time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\n",
      "\u001b[0;32m     64\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((time_end \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n",
      "\n",
      "\u001b[0;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n",
      "\n",
      "\u001b[0;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n",
      "\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n",
      "\n",
      "\u001b[0;32m   1605\u001b[0m     )\n",
      "\n",
      "\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n",
      "\n",
      "\u001b[0;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n",
      "\n",
      "\u001b[0;32m   1621\u001b[0m }\n",
      "\n",
      "\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n",
      "\n",
      "\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\n",
      "\u001b[0;32m   1945\u001b[0m ):\n",
      "\n",
      "\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n",
      "\n",
      "\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "\n",
      "\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\n",
      "\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\n",
      "\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\n",
      "\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\n",
      "\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\n",
      "\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n",
      "\n",
      "\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n",
      "\n",
      "\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\n",
      "\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n",
      "\n",
      "\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\n",
      "\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\n",
      "\u001b[0;32m   2494\u001b[0m   (graph_function,\n",
      "\n",
      "\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "\n",
      "\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "\n",
      "\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\n",
      "\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\n",
      "\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\n",
      "\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\n",
      "\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\n",
      "\u001b[0;32m   1865\u001b[0m     args,\n",
      "\n",
      "\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n",
      "\n",
      "\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n",
      "\n",
      "\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n",
      "\n",
      "\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\n",
      "\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\n",
      "\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n",
      "\n",
      "\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n",
      "\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\n",
      "\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n",
      "\n",
      "\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "\n",
      "\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\n",
      "\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\n",
      "\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\n",
      "\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update = False\n",
    "            \n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "verbose = 0\n",
    "        \n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for name in protein_names:\n",
    "    data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "    ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "    \n",
    "    # get X dataset\n",
    "    x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "    x_features = list(x_onehot.columns)\n",
    "    \n",
    "    # get Y dataset\n",
    "    y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "    y_labels = list(y_onehot.columns)\n",
    "    \n",
    "    for idx in ST_idx:\n",
    "        window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "        label_y  = np.array(y_onehot.iloc[idx])\n",
    "        \n",
    "        data_x.append(window_x)\n",
    "        data_y.append(label_y)\n",
    "        \n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "print('data x shape:', data_x.shape)\n",
    "print('data y shape:', data_y.shape)\n",
    "print('class y counts:', data_y.sum(0))\n",
    "print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits = 5, test_size = test_size, random_state = SEED)\n",
    "for cv_idx, (train_idx, test_idx) in enumerate(splitter.split(data_x, data_y)):\n",
    "    train_x, train_y = data_x[train_idx], data_y[train_idx]\n",
    "    train_x, train_y = upsample_data(train_x, train_y) # up-sample the training dataset\n",
    "    test_x , test_y  = data_x[test_idx],  data_y[test_idx]\n",
    "    \n",
    "    train_x, test_x = data_scaling(train_x, test_x)\n",
    "    \n",
    "    model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params)\n",
    "    model_name = name_model(f'{model_type}', params)\n",
    "    \n",
    "    \n",
    "    model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "    model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "    metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(model_path) or model_update:\n",
    "        time_start = time.time()\n",
    "        history = model.fit(train_x, train_y, verbose=verbose, \n",
    "                            epochs = 10000, callbacks = callbacks,\n",
    "                            validation_split = test_size/(1-test_size))\n",
    "        time_end = time.time()\n",
    "        training_time = round((time_end - time_start)/60, 3)\n",
    "        \n",
    "        model.save_weights(model_path)\n",
    "        \n",
    "        test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "        model_metrics = {\n",
    "            'model_id' : model_id,\n",
    "            'cv_idx'   : cv_idx,\n",
    "            **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "            'train_y'     : train_y.shape[-1],\n",
    "            'test_size'   : test_x.shape[0],\n",
    "            **params,\n",
    "            'regularizer_input' : params['regularizer']['input'],\n",
    "            'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "            'regularizer_bias' : params['regularizer']['bias'],\n",
    "            'training_time': training_time,\n",
    "            'test_loss': test_loss,\n",
    "            'accuracy': accuracy,\n",
    "            **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "            **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "            **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "        model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "        model_metrics.to_csv(metric_path, index=False)\n",
    "        \n",
    "    else:\n",
    "        model.load_weights(model_path)\n",
    "        model_metrics = pd.read_csv(metric_path, header=0)\n",
    "        \n",
    "    print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "    \n",
    "    METRICs.append(model_metrics)\n",
    "    MODELs.append(model)\n",
    "\n",
    "METRICs = pd.concat(METRICs)\n",
    "METRIC_MEAN = METRICs.groupby('model_id').mean()\n",
    "METRIC_STD = METRICs.groupby('model_id').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_STD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
