{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc03987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# function ConnectButton(){\n",
    "#     console.log(\"Connect pushed\");\n",
    "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
    "# }\n",
    "\n",
    "# setInterval(ConnectButton,60000);\n",
    "# '''\n",
    "\n",
    "# from google.colab import drive\n",
    "# from os import chdir\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# project_path = '/content/drive/MyDrive/Gproject/o-linked-site-prediction-feature-augment'\n",
    "# chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b246081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seed for the reproducible result\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41490bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of initial proteins: 104\n",
      "['A2ABU4', 'A2AHJ4', 'A2AKB9', 'A2AQ25', 'E9Q1P8', 'E9Q5G3', 'O08537', 'O09061', 'O35303', 'O70263']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/integrated_features' # we will get names from the augmented proteins\n",
    "protein_names = [x.split('.')[0] for x in os.listdir(data_dir) if x.split('.')[1] == 'csv'] # get protein name list to be processed for building machine learning models\n",
    "print('the number of initial proteins:', len(protein_names))\n",
    "print(protein_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55978831",
   "metadata": {},
   "source": [
    "## hyper parameter optimization by K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71be2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from ml_models import *\n",
    "\n",
    "epochs = 1000\n",
    "from keras.callbacks import EarlyStopping\n",
    "patience = 30\n",
    "callbacks = [EarlyStopping(patience=patience, restore_best_weights=True, monitor='val_loss')]\n",
    "\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4278b",
   "metadata": {},
   "source": [
    "### set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99162761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7789ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters\n",
      "rnn_layers     : 4\n",
      "rnn_neurons    : 64\n",
      "dnn_layers     : 3\n",
      "dnn_neurons    : 64\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "initial_params = default_params.copy()\n",
    "initial_params.update({\n",
    "    'window_size'    : 10,\n",
    "    'rnn_layers'     : 4,\n",
    "    'rnn_neurons'    : 64,\n",
    "    'dnn_layers'     : 3,\n",
    "    'dnn_neurons'    : 64\n",
    "    })\n",
    "\n",
    "print('initial parameters')\n",
    "for key, value in initial_params.items():\n",
    "    print(f'{key:<14} : {value}')\n",
    "\n",
    "search_space = {\n",
    "    'regularizer'    : [\n",
    "        {'input': 'L21_0.001',   'hidden': None,          'bias': None},\n",
    "        {'input': 'L21_0.001',   'hidden': 'L21_0.001',   'bias': None},\n",
    "        {'input': 'L21_0.0001',  'hidden': None,          'bias': None},\n",
    "        {'input': 'L21_0.0001',  'hidden': 'L21_0.0001',  'bias': None},\n",
    "        {'input': 'L21_0.00001', 'hidden': None,          'bias': None},\n",
    "        {'input': 'L21_0.00001', 'hidden': 'L21_0.00001', 'bias': None},\n",
    "        {'input': 'L21_0.000001', 'hidden': None,          'bias': None},\n",
    "        {'input': 'L21_0.000001', 'hidden': 'L21_0.000001', 'bias': None},\n",
    "\n",
    "        {'input': 'L1_0.001',   'hidden': None,         'bias': None},\n",
    "        {'input': 'L1_0.001',   'hidden': 'L1_0.001',   'bias': None},\n",
    "        {'input': 'L1_0.0001',  'hidden': None,         'bias': None},\n",
    "        {'input': 'L1_0.0001',  'hidden': 'L1_0.0001',  'bias': None},\n",
    "        {'input': 'L1_0.00001', 'hidden': None,         'bias': None},\n",
    "        {'input': 'L1_0.00001', 'hidden': 'L1_0.00001', 'bias': None},\n",
    "        {'input': 'L1_0.000001', 'hidden': None,         'bias': None},\n",
    "        {'input': 'L1_0.000001', 'hidden': 'L1_0.000001', 'bias': None},\n",
    "        ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f9241",
   "metadata": {},
   "source": [
    "## set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00ef1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of augmented features: 498\n",
      "continuous features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'number_hydrophobic_0A',\n",
       " 1: 'number_hydrophilic_0A',\n",
       " 2: 'number_polar_0A',\n",
       " 3: 'number_aromatic_0A',\n",
       " 4: 'number_aliphatic_0A',\n",
       " 5: 'number_charged_0A',\n",
       " 6: 'number_positive_0A',\n",
       " 7: 'number_negative_0A',\n",
       " 8: 'number_gly_0A',\n",
       " 9: 'number_very_small_0A',\n",
       " 10: 'number_small_0A',\n",
       " 11: 'number_normal_0A',\n",
       " 12: 'number_long_0A',\n",
       " 13: 'number_pro_0A',\n",
       " 14: 'number_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 15: 'number_b_polar_uncharged_with_amide_0A',\n",
       " 16: 'number_d_negatively_charged_polar_0A',\n",
       " 17: 'number_e_non_polar_suffered_0A',\n",
       " 18: 'number_f_non_polar_aromatic_0A',\n",
       " 19: 'number_ala_0A',\n",
       " 20: 'number_cys_0A',\n",
       " 21: 'number_asp_0A',\n",
       " 22: 'number_glu_0A',\n",
       " 23: 'number_phe_0A',\n",
       " 24: 'number_his_0A',\n",
       " 25: 'number_ile_0A',\n",
       " 26: 'number_lys_0A',\n",
       " 27: 'number_leu_0A',\n",
       " 28: 'number_met_0A',\n",
       " 29: 'number_asn_0A',\n",
       " 30: 'number_gln_0A',\n",
       " 31: 'number_arg_0A',\n",
       " 32: 'number_ser_0A',\n",
       " 33: 'number_thr_0A',\n",
       " 34: 'number_val_0A',\n",
       " 35: 'number_trp_0A',\n",
       " 36: 'number_tyr_0A',\n",
       " 37: 'sasa_hydrophobic_0A',\n",
       " 38: 'sasa_hydrophilic_0A',\n",
       " 39: 'sasa_polar_0A',\n",
       " 40: 'sasa_aromatic_0A',\n",
       " 41: 'sasa_aliphatic_0A',\n",
       " 42: 'sasa_charged_0A',\n",
       " 43: 'sasa_positive_0A',\n",
       " 44: 'sasa_negative_0A',\n",
       " 45: 'sasa_gly_0A',\n",
       " 46: 'sasa_very_small_0A',\n",
       " 47: 'sasa_small_0A',\n",
       " 48: 'sasa_normal_0A',\n",
       " 49: 'sasa_long_0A',\n",
       " 50: 'sasa_pro_0A',\n",
       " 51: 'sasa_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 52: 'sasa_b_polar_uncharged_with_amide_0A',\n",
       " 53: 'sasa_d_negatively_charged_polar_0A',\n",
       " 54: 'sasa_e_non_polar_suffered_0A',\n",
       " 55: 'sasa_f_non_polar_aromatic_0A',\n",
       " 56: 'sasa_ala_0A',\n",
       " 57: 'sasa_cys_0A',\n",
       " 58: 'sasa_asp_0A',\n",
       " 59: 'sasa_glu_0A',\n",
       " 60: 'sasa_phe_0A',\n",
       " 61: 'sasa_his_0A',\n",
       " 62: 'sasa_ile_0A',\n",
       " 63: 'sasa_lys_0A',\n",
       " 64: 'sasa_leu_0A',\n",
       " 65: 'sasa_met_0A',\n",
       " 66: 'sasa_asn_0A',\n",
       " 67: 'sasa_gln_0A',\n",
       " 68: 'sasa_arg_0A',\n",
       " 69: 'sasa_ser_0A',\n",
       " 70: 'sasa_thr_0A',\n",
       " 71: 'sasa_val_0A',\n",
       " 72: 'sasa_trp_0A',\n",
       " 73: 'sasa_tyr_0A',\n",
       " 74: 'sasa_back_0A',\n",
       " 75: 'sasa_side_0A',\n",
       " 76: 'sasa_target_ser_thr_0A',\n",
       " 77: 'net_charge_all_0A',\n",
       " 78: 'net_charge_backbone_0A',\n",
       " 79: 'net_charge_sidechain_0A',\n",
       " 80: 'net_charge_all_exposed_0A',\n",
       " 81: 'net_charge_backbone_exposed_0A',\n",
       " 82: 'net_charge_sidechain_exposed_0A',\n",
       " 83: 'number_hydrophobic_5A',\n",
       " 84: 'number_hydrophilic_5A',\n",
       " 85: 'number_polar_5A',\n",
       " 86: 'number_aromatic_5A',\n",
       " 87: 'number_aliphatic_5A',\n",
       " 88: 'number_charged_5A',\n",
       " 89: 'number_positive_5A',\n",
       " 90: 'number_negative_5A',\n",
       " 91: 'number_gly_5A',\n",
       " 92: 'number_very_small_5A',\n",
       " 93: 'number_small_5A',\n",
       " 94: 'number_normal_5A',\n",
       " 95: 'number_long_5A',\n",
       " 96: 'number_pro_5A',\n",
       " 97: 'number_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 98: 'number_b_polar_uncharged_with_amide_5A',\n",
       " 99: 'number_d_negatively_charged_polar_5A',\n",
       " 100: 'number_e_non_polar_suffered_5A',\n",
       " 101: 'number_f_non_polar_aromatic_5A',\n",
       " 102: 'number_ala_5A',\n",
       " 103: 'number_cys_5A',\n",
       " 104: 'number_asp_5A',\n",
       " 105: 'number_glu_5A',\n",
       " 106: 'number_phe_5A',\n",
       " 107: 'number_his_5A',\n",
       " 108: 'number_ile_5A',\n",
       " 109: 'number_lys_5A',\n",
       " 110: 'number_leu_5A',\n",
       " 111: 'number_met_5A',\n",
       " 112: 'number_asn_5A',\n",
       " 113: 'number_gln_5A',\n",
       " 114: 'number_arg_5A',\n",
       " 115: 'number_ser_5A',\n",
       " 116: 'number_thr_5A',\n",
       " 117: 'number_val_5A',\n",
       " 118: 'number_trp_5A',\n",
       " 119: 'number_tyr_5A',\n",
       " 120: 'sasa_hydrophobic_5A',\n",
       " 121: 'sasa_hydrophilic_5A',\n",
       " 122: 'sasa_polar_5A',\n",
       " 123: 'sasa_aromatic_5A',\n",
       " 124: 'sasa_aliphatic_5A',\n",
       " 125: 'sasa_charged_5A',\n",
       " 126: 'sasa_positive_5A',\n",
       " 127: 'sasa_negative_5A',\n",
       " 128: 'sasa_gly_5A',\n",
       " 129: 'sasa_very_small_5A',\n",
       " 130: 'sasa_small_5A',\n",
       " 131: 'sasa_normal_5A',\n",
       " 132: 'sasa_long_5A',\n",
       " 133: 'sasa_pro_5A',\n",
       " 134: 'sasa_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 135: 'sasa_b_polar_uncharged_with_amide_5A',\n",
       " 136: 'sasa_d_negatively_charged_polar_5A',\n",
       " 137: 'sasa_e_non_polar_suffered_5A',\n",
       " 138: 'sasa_f_non_polar_aromatic_5A',\n",
       " 139: 'sasa_ala_5A',\n",
       " 140: 'sasa_cys_5A',\n",
       " 141: 'sasa_asp_5A',\n",
       " 142: 'sasa_glu_5A',\n",
       " 143: 'sasa_phe_5A',\n",
       " 144: 'sasa_his_5A',\n",
       " 145: 'sasa_ile_5A',\n",
       " 146: 'sasa_lys_5A',\n",
       " 147: 'sasa_leu_5A',\n",
       " 148: 'sasa_met_5A',\n",
       " 149: 'sasa_asn_5A',\n",
       " 150: 'sasa_gln_5A',\n",
       " 151: 'sasa_arg_5A',\n",
       " 152: 'sasa_ser_5A',\n",
       " 153: 'sasa_thr_5A',\n",
       " 154: 'sasa_val_5A',\n",
       " 155: 'sasa_trp_5A',\n",
       " 156: 'sasa_tyr_5A',\n",
       " 157: 'sasa_back_5A',\n",
       " 158: 'sasa_side_5A',\n",
       " 159: 'sasa_target_ser_thr_5A',\n",
       " 160: 'net_charge_all_5A',\n",
       " 161: 'net_charge_backbone_5A',\n",
       " 162: 'net_charge_sidechain_5A',\n",
       " 163: 'net_charge_all_exposed_5A',\n",
       " 164: 'net_charge_backbone_exposed_5A',\n",
       " 165: 'net_charge_sidechain_exposed_5A',\n",
       " 166: 'number_hydrophobic_10A',\n",
       " 167: 'number_hydrophilic_10A',\n",
       " 168: 'number_polar_10A',\n",
       " 169: 'number_aromatic_10A',\n",
       " 170: 'number_aliphatic_10A',\n",
       " 171: 'number_charged_10A',\n",
       " 172: 'number_positive_10A',\n",
       " 173: 'number_negative_10A',\n",
       " 174: 'number_gly_10A',\n",
       " 175: 'number_very_small_10A',\n",
       " 176: 'number_small_10A',\n",
       " 177: 'number_normal_10A',\n",
       " 178: 'number_long_10A',\n",
       " 179: 'number_pro_10A',\n",
       " 180: 'number_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 181: 'number_b_polar_uncharged_with_amide_10A',\n",
       " 182: 'number_d_negatively_charged_polar_10A',\n",
       " 183: 'number_e_non_polar_suffered_10A',\n",
       " 184: 'number_f_non_polar_aromatic_10A',\n",
       " 185: 'number_ala_10A',\n",
       " 186: 'number_cys_10A',\n",
       " 187: 'number_asp_10A',\n",
       " 188: 'number_glu_10A',\n",
       " 189: 'number_phe_10A',\n",
       " 190: 'number_his_10A',\n",
       " 191: 'number_ile_10A',\n",
       " 192: 'number_lys_10A',\n",
       " 193: 'number_leu_10A',\n",
       " 194: 'number_met_10A',\n",
       " 195: 'number_asn_10A',\n",
       " 196: 'number_gln_10A',\n",
       " 197: 'number_arg_10A',\n",
       " 198: 'number_ser_10A',\n",
       " 199: 'number_thr_10A',\n",
       " 200: 'number_val_10A',\n",
       " 201: 'number_trp_10A',\n",
       " 202: 'number_tyr_10A',\n",
       " 203: 'sasa_hydrophobic_10A',\n",
       " 204: 'sasa_hydrophilic_10A',\n",
       " 205: 'sasa_polar_10A',\n",
       " 206: 'sasa_aromatic_10A',\n",
       " 207: 'sasa_aliphatic_10A',\n",
       " 208: 'sasa_charged_10A',\n",
       " 209: 'sasa_positive_10A',\n",
       " 210: 'sasa_negative_10A',\n",
       " 211: 'sasa_gly_10A',\n",
       " 212: 'sasa_very_small_10A',\n",
       " 213: 'sasa_small_10A',\n",
       " 214: 'sasa_normal_10A',\n",
       " 215: 'sasa_long_10A',\n",
       " 216: 'sasa_pro_10A',\n",
       " 217: 'sasa_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 218: 'sasa_b_polar_uncharged_with_amide_10A',\n",
       " 219: 'sasa_d_negatively_charged_polar_10A',\n",
       " 220: 'sasa_e_non_polar_suffered_10A',\n",
       " 221: 'sasa_f_non_polar_aromatic_10A',\n",
       " 222: 'sasa_ala_10A',\n",
       " 223: 'sasa_cys_10A',\n",
       " 224: 'sasa_asp_10A',\n",
       " 225: 'sasa_glu_10A',\n",
       " 226: 'sasa_phe_10A',\n",
       " 227: 'sasa_his_10A',\n",
       " 228: 'sasa_ile_10A',\n",
       " 229: 'sasa_lys_10A',\n",
       " 230: 'sasa_leu_10A',\n",
       " 231: 'sasa_met_10A',\n",
       " 232: 'sasa_asn_10A',\n",
       " 233: 'sasa_gln_10A',\n",
       " 234: 'sasa_arg_10A',\n",
       " 235: 'sasa_ser_10A',\n",
       " 236: 'sasa_thr_10A',\n",
       " 237: 'sasa_val_10A',\n",
       " 238: 'sasa_trp_10A',\n",
       " 239: 'sasa_tyr_10A',\n",
       " 240: 'sasa_back_10A',\n",
       " 241: 'sasa_side_10A',\n",
       " 242: 'sasa_target_ser_thr_10A',\n",
       " 243: 'net_charge_all_10A',\n",
       " 244: 'net_charge_backbone_10A',\n",
       " 245: 'net_charge_sidechain_10A',\n",
       " 246: 'net_charge_all_exposed_10A',\n",
       " 247: 'net_charge_backbone_exposed_10A',\n",
       " 248: 'net_charge_sidechain_exposed_10A',\n",
       " 249: 'number_hydrophobic_15A',\n",
       " 250: 'number_hydrophilic_15A',\n",
       " 251: 'number_polar_15A',\n",
       " 252: 'number_aromatic_15A',\n",
       " 253: 'number_aliphatic_15A',\n",
       " 254: 'number_charged_15A',\n",
       " 255: 'number_positive_15A',\n",
       " 256: 'number_negative_15A',\n",
       " 257: 'number_gly_15A',\n",
       " 258: 'number_very_small_15A',\n",
       " 259: 'number_small_15A',\n",
       " 260: 'number_normal_15A',\n",
       " 261: 'number_long_15A',\n",
       " 262: 'number_pro_15A',\n",
       " 263: 'number_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 264: 'number_b_polar_uncharged_with_amide_15A',\n",
       " 265: 'number_d_negatively_charged_polar_15A',\n",
       " 266: 'number_e_non_polar_suffered_15A',\n",
       " 267: 'number_f_non_polar_aromatic_15A',\n",
       " 268: 'number_ala_15A',\n",
       " 269: 'number_cys_15A',\n",
       " 270: 'number_asp_15A',\n",
       " 271: 'number_glu_15A',\n",
       " 272: 'number_phe_15A',\n",
       " 273: 'number_his_15A',\n",
       " 274: 'number_ile_15A',\n",
       " 275: 'number_lys_15A',\n",
       " 276: 'number_leu_15A',\n",
       " 277: 'number_met_15A',\n",
       " 278: 'number_asn_15A',\n",
       " 279: 'number_gln_15A',\n",
       " 280: 'number_arg_15A',\n",
       " 281: 'number_ser_15A',\n",
       " 282: 'number_thr_15A',\n",
       " 283: 'number_val_15A',\n",
       " 284: 'number_trp_15A',\n",
       " 285: 'number_tyr_15A',\n",
       " 286: 'sasa_hydrophobic_15A',\n",
       " 287: 'sasa_hydrophilic_15A',\n",
       " 288: 'sasa_polar_15A',\n",
       " 289: 'sasa_aromatic_15A',\n",
       " 290: 'sasa_aliphatic_15A',\n",
       " 291: 'sasa_charged_15A',\n",
       " 292: 'sasa_positive_15A',\n",
       " 293: 'sasa_negative_15A',\n",
       " 294: 'sasa_gly_15A',\n",
       " 295: 'sasa_very_small_15A',\n",
       " 296: 'sasa_small_15A',\n",
       " 297: 'sasa_normal_15A',\n",
       " 298: 'sasa_long_15A',\n",
       " 299: 'sasa_pro_15A',\n",
       " 300: 'sasa_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 301: 'sasa_b_polar_uncharged_with_amide_15A',\n",
       " 302: 'sasa_d_negatively_charged_polar_15A',\n",
       " 303: 'sasa_e_non_polar_suffered_15A',\n",
       " 304: 'sasa_f_non_polar_aromatic_15A',\n",
       " 305: 'sasa_ala_15A',\n",
       " 306: 'sasa_cys_15A',\n",
       " 307: 'sasa_asp_15A',\n",
       " 308: 'sasa_glu_15A',\n",
       " 309: 'sasa_phe_15A',\n",
       " 310: 'sasa_his_15A',\n",
       " 311: 'sasa_ile_15A',\n",
       " 312: 'sasa_lys_15A',\n",
       " 313: 'sasa_leu_15A',\n",
       " 314: 'sasa_met_15A',\n",
       " 315: 'sasa_asn_15A',\n",
       " 316: 'sasa_gln_15A',\n",
       " 317: 'sasa_arg_15A',\n",
       " 318: 'sasa_ser_15A',\n",
       " 319: 'sasa_thr_15A',\n",
       " 320: 'sasa_val_15A',\n",
       " 321: 'sasa_trp_15A',\n",
       " 322: 'sasa_tyr_15A',\n",
       " 323: 'sasa_back_15A',\n",
       " 324: 'sasa_side_15A',\n",
       " 325: 'sasa_target_ser_thr_15A',\n",
       " 326: 'net_charge_all_15A',\n",
       " 327: 'net_charge_backbone_15A',\n",
       " 328: 'net_charge_sidechain_15A',\n",
       " 329: 'net_charge_all_exposed_15A',\n",
       " 330: 'net_charge_backbone_exposed_15A',\n",
       " 331: 'net_charge_sidechain_exposed_15A',\n",
       " 332: 'number_hydrophobic_20A',\n",
       " 333: 'number_hydrophilic_20A',\n",
       " 334: 'number_polar_20A',\n",
       " 335: 'number_aromatic_20A',\n",
       " 336: 'number_aliphatic_20A',\n",
       " 337: 'number_charged_20A',\n",
       " 338: 'number_positive_20A',\n",
       " 339: 'number_negative_20A',\n",
       " 340: 'number_gly_20A',\n",
       " 341: 'number_very_small_20A',\n",
       " 342: 'number_small_20A',\n",
       " 343: 'number_normal_20A',\n",
       " 344: 'number_long_20A',\n",
       " 345: 'number_pro_20A',\n",
       " 346: 'number_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 347: 'number_b_polar_uncharged_with_amide_20A',\n",
       " 348: 'number_d_negatively_charged_polar_20A',\n",
       " 349: 'number_e_non_polar_suffered_20A',\n",
       " 350: 'number_f_non_polar_aromatic_20A',\n",
       " 351: 'number_ala_20A',\n",
       " 352: 'number_cys_20A',\n",
       " 353: 'number_asp_20A',\n",
       " 354: 'number_glu_20A',\n",
       " 355: 'number_phe_20A',\n",
       " 356: 'number_his_20A',\n",
       " 357: 'number_ile_20A',\n",
       " 358: 'number_lys_20A',\n",
       " 359: 'number_leu_20A',\n",
       " 360: 'number_met_20A',\n",
       " 361: 'number_asn_20A',\n",
       " 362: 'number_gln_20A',\n",
       " 363: 'number_arg_20A',\n",
       " 364: 'number_ser_20A',\n",
       " 365: 'number_thr_20A',\n",
       " 366: 'number_val_20A',\n",
       " 367: 'number_trp_20A',\n",
       " 368: 'number_tyr_20A',\n",
       " 369: 'sasa_hydrophobic_20A',\n",
       " 370: 'sasa_hydrophilic_20A',\n",
       " 371: 'sasa_polar_20A',\n",
       " 372: 'sasa_aromatic_20A',\n",
       " 373: 'sasa_aliphatic_20A',\n",
       " 374: 'sasa_charged_20A',\n",
       " 375: 'sasa_positive_20A',\n",
       " 376: 'sasa_negative_20A',\n",
       " 377: 'sasa_gly_20A',\n",
       " 378: 'sasa_very_small_20A',\n",
       " 379: 'sasa_small_20A',\n",
       " 380: 'sasa_normal_20A',\n",
       " 381: 'sasa_long_20A',\n",
       " 382: 'sasa_pro_20A',\n",
       " 383: 'sasa_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 384: 'sasa_b_polar_uncharged_with_amide_20A',\n",
       " 385: 'sasa_d_negatively_charged_polar_20A',\n",
       " 386: 'sasa_e_non_polar_suffered_20A',\n",
       " 387: 'sasa_f_non_polar_aromatic_20A',\n",
       " 388: 'sasa_ala_20A',\n",
       " 389: 'sasa_cys_20A',\n",
       " 390: 'sasa_asp_20A',\n",
       " 391: 'sasa_glu_20A',\n",
       " 392: 'sasa_phe_20A',\n",
       " 393: 'sasa_his_20A',\n",
       " 394: 'sasa_ile_20A',\n",
       " 395: 'sasa_lys_20A',\n",
       " 396: 'sasa_leu_20A',\n",
       " 397: 'sasa_met_20A',\n",
       " 398: 'sasa_asn_20A',\n",
       " 399: 'sasa_gln_20A',\n",
       " 400: 'sasa_arg_20A',\n",
       " 401: 'sasa_ser_20A',\n",
       " 402: 'sasa_thr_20A',\n",
       " 403: 'sasa_val_20A',\n",
       " 404: 'sasa_trp_20A',\n",
       " 405: 'sasa_tyr_20A',\n",
       " 406: 'sasa_back_20A',\n",
       " 407: 'sasa_side_20A',\n",
       " 408: 'sasa_target_ser_thr_20A',\n",
       " 409: 'net_charge_all_20A',\n",
       " 410: 'net_charge_backbone_20A',\n",
       " 411: 'net_charge_sidechain_20A',\n",
       " 412: 'net_charge_all_exposed_20A',\n",
       " 413: 'net_charge_backbone_exposed_20A',\n",
       " 414: 'net_charge_sidechain_exposed_20A',\n",
       " 415: 'number_hydrophobic_25A',\n",
       " 416: 'number_hydrophilic_25A',\n",
       " 417: 'number_polar_25A',\n",
       " 418: 'number_aromatic_25A',\n",
       " 419: 'number_aliphatic_25A',\n",
       " 420: 'number_charged_25A',\n",
       " 421: 'number_positive_25A',\n",
       " 422: 'number_negative_25A',\n",
       " 423: 'number_gly_25A',\n",
       " 424: 'number_very_small_25A',\n",
       " 425: 'number_small_25A',\n",
       " 426: 'number_normal_25A',\n",
       " 427: 'number_long_25A',\n",
       " 428: 'number_pro_25A',\n",
       " 429: 'number_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 430: 'number_b_polar_uncharged_with_amide_25A',\n",
       " 431: 'number_d_negatively_charged_polar_25A',\n",
       " 432: 'number_e_non_polar_suffered_25A',\n",
       " 433: 'number_f_non_polar_aromatic_25A',\n",
       " 434: 'number_ala_25A',\n",
       " 435: 'number_cys_25A',\n",
       " 436: 'number_asp_25A',\n",
       " 437: 'number_glu_25A',\n",
       " 438: 'number_phe_25A',\n",
       " 439: 'number_his_25A',\n",
       " 440: 'number_ile_25A',\n",
       " 441: 'number_lys_25A',\n",
       " 442: 'number_leu_25A',\n",
       " 443: 'number_met_25A',\n",
       " 444: 'number_asn_25A',\n",
       " 445: 'number_gln_25A',\n",
       " 446: 'number_arg_25A',\n",
       " 447: 'number_ser_25A',\n",
       " 448: 'number_thr_25A',\n",
       " 449: 'number_val_25A',\n",
       " 450: 'number_trp_25A',\n",
       " 451: 'number_tyr_25A',\n",
       " 452: 'sasa_hydrophobic_25A',\n",
       " 453: 'sasa_hydrophilic_25A',\n",
       " 454: 'sasa_polar_25A',\n",
       " 455: 'sasa_aromatic_25A',\n",
       " 456: 'sasa_aliphatic_25A',\n",
       " 457: 'sasa_charged_25A',\n",
       " 458: 'sasa_positive_25A',\n",
       " 459: 'sasa_negative_25A',\n",
       " 460: 'sasa_gly_25A',\n",
       " 461: 'sasa_very_small_25A',\n",
       " 462: 'sasa_small_25A',\n",
       " 463: 'sasa_normal_25A',\n",
       " 464: 'sasa_long_25A',\n",
       " 465: 'sasa_pro_25A',\n",
       " 466: 'sasa_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 467: 'sasa_b_polar_uncharged_with_amide_25A',\n",
       " 468: 'sasa_d_negatively_charged_polar_25A',\n",
       " 469: 'sasa_e_non_polar_suffered_25A',\n",
       " 470: 'sasa_f_non_polar_aromatic_25A',\n",
       " 471: 'sasa_ala_25A',\n",
       " 472: 'sasa_cys_25A',\n",
       " 473: 'sasa_asp_25A',\n",
       " 474: 'sasa_glu_25A',\n",
       " 475: 'sasa_phe_25A',\n",
       " 476: 'sasa_his_25A',\n",
       " 477: 'sasa_ile_25A',\n",
       " 478: 'sasa_lys_25A',\n",
       " 479: 'sasa_leu_25A',\n",
       " 480: 'sasa_met_25A',\n",
       " 481: 'sasa_asn_25A',\n",
       " 482: 'sasa_gln_25A',\n",
       " 483: 'sasa_arg_25A',\n",
       " 484: 'sasa_ser_25A',\n",
       " 485: 'sasa_thr_25A',\n",
       " 486: 'sasa_val_25A',\n",
       " 487: 'sasa_trp_25A',\n",
       " 488: 'sasa_tyr_25A',\n",
       " 489: 'sasa_back_25A',\n",
       " 490: 'sasa_side_25A',\n",
       " 491: 'sasa_target_ser_thr_25A',\n",
       " 492: 'net_charge_all_25A',\n",
       " 493: 'net_charge_backbone_25A',\n",
       " 494: 'net_charge_sidechain_25A',\n",
       " 495: 'net_charge_all_exposed_25A',\n",
       " 496: 'net_charge_backbone_exposed_25A',\n",
       " 497: 'net_charge_sidechain_exposed_25A'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:\n",
      "{0: 'residue'}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'SLSTM_UP_AUGMENT'\n",
    "\n",
    "augmented_columns = dict(pd.read_csv('./data/augmented_columns.csv', header=0).values.squeeze())\n",
    "print('# of augmented features:', len(augmented_columns))\n",
    "\n",
    "# set continuous input features\n",
    "x_cts = [x for x in augmented_columns.keys() if augmented_columns.get(x) != 'object']\n",
    "print('continuous features:')\n",
    "display(dict(zip(range(len(x_cts)), x_cts)))\n",
    "\n",
    "# set categorical input features\n",
    "x_cat = ['residue'] + \\\n",
    "        [x for x in augmented_columns.keys() if augmented_columns.get(x) == 'object']\n",
    "print('categorical features:')\n",
    "print(dict(zip(range(len(x_cat)), x_cat)))\n",
    "\n",
    "# input features\n",
    "x_var = x_cts + x_cat\n",
    "\n",
    "# set continuos output feature\n",
    "y_cts = []\n",
    "\n",
    "# set categorical output feature\n",
    "y_cat = ['positivity']\n",
    "\n",
    "# output features\n",
    "y_var = y_cts + y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c2c79",
   "metadata": {},
   "source": [
    "# build amino acid sequence dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da184fcc",
   "metadata": {},
   "source": [
    "### model training with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c7dc049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_0</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_2</th>\n",
       "      <th>train_y</th>\n",
       "      <th>test_size</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>rnn_neurons</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>dnn_neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>regularizer_bias</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0796</td>\n",
       "      <td>0.486763</td>\n",
       "      <td>86.004</td>\n",
       "      <td>97.300</td>\n",
       "      <td>11.498</td>\n",
       "      <td>87.956</td>\n",
       "      <td>35.582</td>\n",
       "      <td>92.168</td>\n",
       "      <td>14.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.3096</td>\n",
       "      <td>0.708349</td>\n",
       "      <td>96.270</td>\n",
       "      <td>96.270</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.100</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0076</td>\n",
       "      <td>0.385164</td>\n",
       "      <td>94.518</td>\n",
       "      <td>97.008</td>\n",
       "      <td>24.498</td>\n",
       "      <td>97.306</td>\n",
       "      <td>22.558</td>\n",
       "      <td>97.156</td>\n",
       "      <td>23.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1848</td>\n",
       "      <td>0.470403</td>\n",
       "      <td>90.320</td>\n",
       "      <td>97.144</td>\n",
       "      <td>17.148</td>\n",
       "      <td>92.676</td>\n",
       "      <td>29.534</td>\n",
       "      <td>94.788</td>\n",
       "      <td>19.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0282</td>\n",
       "      <td>0.327553</td>\n",
       "      <td>94.564</td>\n",
       "      <td>97.182</td>\n",
       "      <td>28.102</td>\n",
       "      <td>97.174</td>\n",
       "      <td>27.212</td>\n",
       "      <td>97.174</td>\n",
       "      <td>27.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7376</td>\n",
       "      <td>0.351533</td>\n",
       "      <td>94.814</td>\n",
       "      <td>97.042</td>\n",
       "      <td>27.240</td>\n",
       "      <td>97.584</td>\n",
       "      <td>23.258</td>\n",
       "      <td>97.316</td>\n",
       "      <td>25.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6174</td>\n",
       "      <td>0.420123</td>\n",
       "      <td>91.040</td>\n",
       "      <td>97.028</td>\n",
       "      <td>15.454</td>\n",
       "      <td>93.568</td>\n",
       "      <td>25.812</td>\n",
       "      <td>95.212</td>\n",
       "      <td>18.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.2542</td>\n",
       "      <td>0.487802</td>\n",
       "      <td>84.832</td>\n",
       "      <td>97.458</td>\n",
       "      <td>11.550</td>\n",
       "      <td>86.514</td>\n",
       "      <td>41.396</td>\n",
       "      <td>91.578</td>\n",
       "      <td>17.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2040</td>\n",
       "      <td>0.332221</td>\n",
       "      <td>94.830</td>\n",
       "      <td>97.170</td>\n",
       "      <td>29.588</td>\n",
       "      <td>97.468</td>\n",
       "      <td>26.744</td>\n",
       "      <td>97.318</td>\n",
       "      <td>27.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0994</td>\n",
       "      <td>0.367221</td>\n",
       "      <td>94.726</td>\n",
       "      <td>97.118</td>\n",
       "      <td>28.630</td>\n",
       "      <td>97.414</td>\n",
       "      <td>25.350</td>\n",
       "      <td>97.264</td>\n",
       "      <td>26.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5546</td>\n",
       "      <td>0.291238</td>\n",
       "      <td>94.608</td>\n",
       "      <td>97.004</td>\n",
       "      <td>25.720</td>\n",
       "      <td>97.404</td>\n",
       "      <td>22.324</td>\n",
       "      <td>97.204</td>\n",
       "      <td>23.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9598</td>\n",
       "      <td>0.302591</td>\n",
       "      <td>94.260</td>\n",
       "      <td>97.024</td>\n",
       "      <td>26.310</td>\n",
       "      <td>97.008</td>\n",
       "      <td>23.258</td>\n",
       "      <td>97.010</td>\n",
       "      <td>24.036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cv_idx  train_0  train_1  train_2  train_y  test_size  rnn_layers  \\\n",
       "model_id                                                                      \n",
       "1            2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "2            2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "3            2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "4            2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "5            2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "6            2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "7            2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "8            2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "9            2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "10           2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "11           2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "12           2.0   9222.0     21.0    518.0      2.0     2306.0         4.0   \n",
       "\n",
       "          rnn_neurons  dnn_layers  dnn_neurons  ...  regularizer_bias  \\\n",
       "model_id                                        ...                     \n",
       "1                64.0         3.0         64.0  ...               NaN   \n",
       "2                64.0         3.0         64.0  ...               NaN   \n",
       "3                64.0         3.0         64.0  ...               NaN   \n",
       "4                64.0         3.0         64.0  ...               NaN   \n",
       "5                64.0         3.0         64.0  ...               NaN   \n",
       "6                64.0         3.0         64.0  ...               NaN   \n",
       "7                64.0         3.0         64.0  ...               NaN   \n",
       "8                64.0         3.0         64.0  ...               NaN   \n",
       "9                64.0         3.0         64.0  ...               NaN   \n",
       "10               64.0         3.0         64.0  ...               NaN   \n",
       "11               64.0         3.0         64.0  ...               NaN   \n",
       "12               64.0         3.0         64.0  ...               NaN   \n",
       "\n",
       "          training_time  test_loss  accuracy  precision_0  precision_1  \\\n",
       "model_id                                                                 \n",
       "1                5.0796   0.486763    86.004       97.300       11.498   \n",
       "2                6.3096   0.708349    96.270       96.270        0.000   \n",
       "3                9.0076   0.385164    94.518       97.008       24.498   \n",
       "4                6.1848   0.470403    90.320       97.144       17.148   \n",
       "5                5.0282   0.327553    94.564       97.182       28.102   \n",
       "6                6.7376   0.351533    94.814       97.042       27.240   \n",
       "7                5.6174   0.420123    91.040       97.028       15.454   \n",
       "8                5.2542   0.487802    84.832       97.458       11.550   \n",
       "9                6.2040   0.332221    94.830       97.170       29.588   \n",
       "10               6.0994   0.367221    94.726       97.118       28.630   \n",
       "11               4.5546   0.291238    94.608       97.004       25.720   \n",
       "12               4.9598   0.302591    94.260       97.024       26.310   \n",
       "\n",
       "          recall_0  recall_1    f1_0    f1_1  \n",
       "model_id                                      \n",
       "1           87.956    35.582  92.168  14.942  \n",
       "2          100.000     0.000  98.100   0.000  \n",
       "3           97.306    22.558  97.156  23.170  \n",
       "4           92.676    29.534  94.788  19.996  \n",
       "5           97.174    27.212  97.174  27.068  \n",
       "6           97.584    23.258  97.316  25.060  \n",
       "7           93.568    25.812  95.212  18.210  \n",
       "8           86.514    41.396  91.578  17.208  \n",
       "9           97.468    26.744  97.318  27.864  \n",
       "10          97.414    25.350  97.264  26.618  \n",
       "11          97.404    22.324  97.204  23.704  \n",
       "12          97.008    23.258  97.010  24.036  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularizer    : [{'input': 'L21_0.001', 'hidden': None, 'bias': None}, {'input': 'L21_0.001', 'hidden': 'L21_0.001', 'bias': None}, {'input': 'L21_0.0001', 'hidden': None, 'bias': None}, {'input': 'L21_0.0001', 'hidden': 'L21_0.0001', 'bias': None}, {'input': 'L21_0.00001', 'hidden': None, 'bias': None}, {'input': 'L21_0.00001', 'hidden': 'L21_0.00001', 'bias': None}, {'input': 'L1_0.001', 'hidden': None, 'bias': None}, {'input': 'L1_0.001', 'hidden': 'L1_0.001', 'bias': None}, {'input': 'L1_0.0001', 'hidden': None, 'bias': None}, {'input': 'L1_0.0001', 'hidden': 'L1_0.0001', 'bias': None}, {'input': 'L1_0.00001', 'hidden': None, 'bias': None}, {'input': 'L1_0.00001', 'hidden': 'L1_0.00001', 'bias': None}, {'input': 'L2_0.001', 'hidden': None, 'bias': None}, {'input': 'L2_0.001', 'hidden': 'L2_0.001', 'bias': None}, {'input': 'L2_0.0001', 'hidden': None, 'bias': None}, {'input': 'L2_0.0001', 'hidden': 'L2_0.0001', 'bias': None}, {'input': 'L2_0.00001', 'hidden': None, 'bias': None}, {'input': 'L2_0.00001', 'hidden': 'L2_0.00001', 'bias': None}]\n",
      "data x shape: (11528, 21, 518)\n",
      "data y shape: (11528, 2)\n",
      "class y counts: [11100   428]\n",
      "class y ratio: [0.9629 0.0371]\n",
      "f1 score: 19.54\n",
      "f1 score: 32.32\n",
      "f1 score: 24.0\n",
      "f1 score: 26.76\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path) \u001b[38;5;129;01mor\u001b[39;00m model_update:\n\u001b[0;32m     84\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 85\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x_kf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y_kf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     89\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((time_end \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python39\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update  = False\n",
    "\n",
    "params = initial_params.copy()\n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "feature_weights = []\n",
    "\n",
    "model_id = 1\n",
    "verbose = 0\n",
    "for param_name, space in search_space.items():\n",
    "    for point in space:\n",
    "        clear_output(wait=True)\n",
    "        display(METRIC_MEAN)\n",
    "        params[param_name] = point\n",
    "        for key, value in search_space.items():\n",
    "            print(f'{key:<14} : {value}')\n",
    "        \n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        feature_weight = []\n",
    "\n",
    "        for name in protein_names:\n",
    "            data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "            ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "            \n",
    "            # get X dataset\n",
    "            x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "            x_features = list(x_onehot.columns)\n",
    "            \n",
    "            # get Y dataset\n",
    "            y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "            y_labels = list(y_onehot.columns)\n",
    "            \n",
    "            for idx in ST_idx:\n",
    "                window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "                label_y  = np.array(y_onehot.iloc[idx])\n",
    "                \n",
    "                data_x.append(window_x)\n",
    "                data_y.append(label_y)\n",
    "                \n",
    "        data_x = np.array(data_x)\n",
    "        data_y = np.array(data_y)\n",
    "        model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "        print('data x shape:', data_x.shape)\n",
    "        print('data y shape:', data_y.shape)\n",
    "        print('class y counts:', data_y.sum(0))\n",
    "        print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "        \n",
    "        splitter = StratifiedShuffleSplit(n_splits = 1, test_size = test_size, random_state = SEED)\n",
    "        train_idx, test_idx = list(splitter.split(data_x, data_y))[0]\n",
    "        \n",
    "        train_x = data_x[train_idx]\n",
    "        train_y = data_y[train_idx]\n",
    "        \n",
    "        test_x = data_x[test_idx]\n",
    "        test_y = data_y[test_idx]\n",
    "        \n",
    "        train_x, test_x = data_scaling(train_x, test_x)\n",
    "        \n",
    "        splitter_kf = KFold(n_splits = 5)\n",
    "        for cv_idx, (train_idx_kf, test_idx_kf) in enumerate(splitter_kf.split(train_x, train_y)):\n",
    "            train_x_kf, train_y_kf = train_x[train_idx_kf], train_y[train_idx_kf]\n",
    "            test_x_kf, test_y_kf   = train_x[test_idx_kf],  train_y[test_idx_kf]\n",
    "            \n",
    "            # up-sample the training dataset\n",
    "            train_x_kf, train_y_kf = upsample_data(train_x_kf, train_y_kf) \n",
    "            \n",
    "            model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) \n",
    "            model_name = name_model(f'{model_type}_KFOLD', params)\n",
    "            \n",
    "            model_folder  = f'./models/{model_name}_{data_x.shape}'\n",
    "            if not os.path.exists(model_folder):\n",
    "                os.makedirs(model_folder)\n",
    "            model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "            metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(model_path) or model_update:\n",
    "                time_start = time.time()\n",
    "                history = model.fit(train_x_kf, train_y_kf, verbose=verbose, \n",
    "                                    epochs = 10000, callbacks = callbacks,\n",
    "                                    validation_data = (test_x_kf, test_y_kf))\n",
    "                time_end = time.time()\n",
    "                training_time = round((time_end - time_start)/60, 3)\n",
    "                \n",
    "                model.save_weights(model_path)\n",
    "                \n",
    "                test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "                model_metrics = {\n",
    "                    'model_id' : model_id,\n",
    "                    'cv_idx'   : cv_idx,\n",
    "                    **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "                    'train_y'     : train_y.shape[-1],\n",
    "                    'test_size'   : test_x.shape[0],\n",
    "                    **params,\n",
    "                    'regularizer_input' : params['regularizer']['input'],\n",
    "                    'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "                    'regularizer_bias' : params['regularizer']['bias'],\n",
    "                    'training_time': training_time,\n",
    "                    'test_loss': test_loss,\n",
    "                    'accuracy': accuracy,\n",
    "                    **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "                    **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "                    **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "                \n",
    "                model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "                model_metrics.to_csv(metric_path, index=False)\n",
    "                \n",
    "            else:\n",
    "                model.load_weights(model_path)\n",
    "                model_metrics = pd.read_csv(metric_path, header=0)\n",
    "                \n",
    "            print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "            \n",
    "            model_metrics['model_id'] = model_id\n",
    "            METRICs.append(model_metrics)\n",
    "            MODELs.append(model)\n",
    "            weights = model.get_weights()\n",
    "            feature_weight.append(np.abs(weights[0].mean(1)).reshape(1,-1))\n",
    "        \n",
    "        METRIC_MEAN = pd.concat(METRICs).groupby('model_id').mean()\n",
    "        f1_best = METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0].f1_1\n",
    "        print(f'best f1 score: {f1_best}')\n",
    "        model_id += 1\n",
    "        feature_weight = np.concatenate(feature_weight, axis=0)\n",
    "        feature_weight = feature_weight.mean(0)\n",
    "        feature_weight = pd.Series(feature_weight, index=x_features)\n",
    "        feature_weight.to_csv(f'./weights/{model_name}_{data_x.shape}.csv')\n",
    "        feature_weights.append(feature_weight)\n",
    "\n",
    "    # if param_name in ['learning_rate']: # for float-type parameters\n",
    "    #     best_value = float(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "    #     params[param_name] = best_value\n",
    "    #     search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "\n",
    "    # else: # for int-type parameters\n",
    "    #     best_value = int(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "    #     params[param_name] = best_value\n",
    "    #     search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "    \n",
    "\n",
    "clear_output(wait=True)\n",
    "display(METRIC_MEAN)\n",
    "for key, value in search_space.items():\n",
    "    print(f'{key:<14} : {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape:  (12120, 420)\n",
      "data y shape:  (12120, 2)\n",
      "train x shape: (9696, 420)\n",
      "test  x shape: (2424, 2)\n"
     ]
    }
   ],
   "source": [
    "print('data x shape: ', data_x.shape)\n",
    "print('data y shape: ', data_y.shape)\n",
    "print('train x shape:', train_x.shape)\n",
    "print('test  x shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755e958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1f337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc39961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e89cb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e90781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 6\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70b98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 7\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a04c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 8\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9004d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 9\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd06db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfd903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 11\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fddea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "dnn_layers     : 4\n",
      "dnn_neurons    : 256\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "idx = 15\n",
    "weights = feature_weights[idx]\n",
    "n_features = len(x_features)\n",
    "plt.figure(figsize=(n_features/2, n_features/2*9/16))\n",
    "plt.grid(axis='both', color = \"grey\", linewidth = \"0.1\", linestyle = \"--\", zorder=0)\n",
    "\n",
    "plt.bar(range(len(weights)), weights, align='center')\n",
    "plt.xticks(ticks=range(n_features), labels=x_features, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
