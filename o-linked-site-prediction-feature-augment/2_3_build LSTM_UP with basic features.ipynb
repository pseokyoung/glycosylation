{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc03987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# function ConnectButton(){\n",
    "#     console.log(\"Connect pushed\");\n",
    "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
    "# }\n",
    "\n",
    "# setInterval(ConnectButton,60000);\n",
    "# '''\n",
    "\n",
    "# from google.colab import drive\n",
    "# from os import chdir\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# project_path = '/content/drive/MyDrive/Gproject/o-linked-site-prediction-feature-augment'\n",
    "# chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b246081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed for the reproducible result\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41490bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of initial proteins: 104\n",
      "['A2ABU4', 'A2AHJ4', 'A2AKB9', 'A2AQ25', 'E9Q1P8', 'E9Q5G3', 'O08537', 'O09061', 'O35303', 'O70263']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/integrated_features' # we will get names from the augmented proteins\n",
    "protein_names = [x.split('.')[0] for x in os.listdir(data_dir) if x.split('.')[1] == 'csv'] # get protein name list to be processed for building machine learning models\n",
    "print('the number of initial proteins:', len(protein_names))\n",
    "print(protein_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55978831",
   "metadata": {},
   "source": [
    "## hyper parameter optimization by K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71be2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from ml_models import *\n",
    "\n",
    "epochs = 1000\n",
    "from keras.callbacks import EarlyStopping\n",
    "patience = 30\n",
    "callbacks = [EarlyStopping(patience=patience, restore_best_weights=True, monitor='val_loss')]\n",
    "\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4278b",
   "metadata": {},
   "source": [
    "### set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99162761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7789ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters\n",
      "rnn_layers     : 1\n",
      "rnn_neurons    : 64\n",
      "dnn_layers     : 3\n",
      "dnn_neurons    : 64\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "initial_params = default_params.copy()\n",
    "initial_params.update({\n",
    "    'window_size'    : 10\n",
    "    })\n",
    "\n",
    "print('initial parameters')\n",
    "for key, value in initial_params.items():\n",
    "    print(f'{key:<14} : {value}')\n",
    "\n",
    "search_space = {\n",
    "    'rnn_layers'    : [1, 2, 3, 4, 5],\n",
    "    'rnn_neurons'   : [32, 64, 128, 256],\n",
    "    'dnn_layers'    : [1, 2, 3, 4, 5],\n",
    "    'dnn_neurons'   : [32, 64, 128, 256],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f9241",
   "metadata": {},
   "source": [
    "## set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ef1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of augmented features: 13\n",
      "continuous features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'npa(-3,-1)', 1: 'ppo(-7,-5)', 2: 'n(S/T)', 3: 'flexibility', 4: 'p(1)'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:\n",
      "{0: 'residue', 1: 'side_-1', 2: 'side_1', 3: 'side_2', 4: 'side_3', 5: 'side_4', 6: 'side_5', 7: 'ss', 8: 'ss_angle'}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'LSTM_UP_BASIC'\n",
    "\n",
    "basic_columns = dict(pd.read_csv('./data/basic_columns.csv', header=0).values.squeeze())\n",
    "print('# of augmented features:', len(basic_columns))\n",
    "\n",
    "# set continuous input features\n",
    "x_cts = [x for x in basic_columns.keys() if basic_columns.get(x) != 'object']\n",
    "print('continuous features:')\n",
    "display(dict(zip(range(len(x_cts)), x_cts)))\n",
    "\n",
    "# set categorical input features\n",
    "x_cat = ['residue'] + \\\n",
    "        [x for x in basic_columns.keys() if basic_columns.get(x) == 'object']\n",
    "print('categorical features:')\n",
    "print(dict(zip(range(len(x_cat)), x_cat)))\n",
    "\n",
    "# input features\n",
    "x_var = x_cts + x_cat\n",
    "\n",
    "# set continuos output feature\n",
    "y_cts = []\n",
    "\n",
    "# set categorical output feature\n",
    "y_cat = ['positivity']\n",
    "\n",
    "# output features\n",
    "y_var = y_cts + y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c2c79",
   "metadata": {},
   "source": [
    "# build amino acid sequence dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da184fcc",
   "metadata": {},
   "source": [
    "### model training with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c7dc049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_0</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_2</th>\n",
       "      <th>train_y</th>\n",
       "      <th>test_size</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>rnn_neurons</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>dnn_neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>regularizer_bias</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6876</td>\n",
       "      <td>0.318821</td>\n",
       "      <td>90.148</td>\n",
       "      <td>96.958</td>\n",
       "      <td>12.972</td>\n",
       "      <td>92.686</td>\n",
       "      <td>24.650</td>\n",
       "      <td>94.724</td>\n",
       "      <td>15.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0566</td>\n",
       "      <td>0.355052</td>\n",
       "      <td>89.706</td>\n",
       "      <td>97.214</td>\n",
       "      <td>15.480</td>\n",
       "      <td>91.948</td>\n",
       "      <td>31.860</td>\n",
       "      <td>94.456</td>\n",
       "      <td>19.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9598</td>\n",
       "      <td>0.272712</td>\n",
       "      <td>94.900</td>\n",
       "      <td>97.020</td>\n",
       "      <td>28.264</td>\n",
       "      <td>97.702</td>\n",
       "      <td>22.558</td>\n",
       "      <td>97.360</td>\n",
       "      <td>24.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3296</td>\n",
       "      <td>0.238907</td>\n",
       "      <td>94.408</td>\n",
       "      <td>97.050</td>\n",
       "      <td>25.344</td>\n",
       "      <td>97.144</td>\n",
       "      <td>23.722</td>\n",
       "      <td>97.092</td>\n",
       "      <td>23.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2898</td>\n",
       "      <td>0.251065</td>\n",
       "      <td>94.450</td>\n",
       "      <td>96.982</td>\n",
       "      <td>23.972</td>\n",
       "      <td>97.260</td>\n",
       "      <td>21.860</td>\n",
       "      <td>97.120</td>\n",
       "      <td>22.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3550</td>\n",
       "      <td>0.351971</td>\n",
       "      <td>89.296</td>\n",
       "      <td>97.270</td>\n",
       "      <td>14.908</td>\n",
       "      <td>91.460</td>\n",
       "      <td>33.488</td>\n",
       "      <td>94.200</td>\n",
       "      <td>19.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9598</td>\n",
       "      <td>0.272712</td>\n",
       "      <td>94.900</td>\n",
       "      <td>97.020</td>\n",
       "      <td>28.264</td>\n",
       "      <td>97.702</td>\n",
       "      <td>22.558</td>\n",
       "      <td>97.360</td>\n",
       "      <td>24.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4964</td>\n",
       "      <td>0.233586</td>\n",
       "      <td>94.400</td>\n",
       "      <td>96.938</td>\n",
       "      <td>23.204</td>\n",
       "      <td>97.252</td>\n",
       "      <td>20.696</td>\n",
       "      <td>97.096</td>\n",
       "      <td>21.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3342</td>\n",
       "      <td>0.237007</td>\n",
       "      <td>94.484</td>\n",
       "      <td>96.734</td>\n",
       "      <td>19.840</td>\n",
       "      <td>97.566</td>\n",
       "      <td>14.884</td>\n",
       "      <td>97.146</td>\n",
       "      <td>16.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7586</td>\n",
       "      <td>0.280655</td>\n",
       "      <td>94.876</td>\n",
       "      <td>97.046</td>\n",
       "      <td>27.662</td>\n",
       "      <td>97.650</td>\n",
       "      <td>23.254</td>\n",
       "      <td>97.346</td>\n",
       "      <td>25.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8846</td>\n",
       "      <td>0.264757</td>\n",
       "      <td>94.624</td>\n",
       "      <td>97.130</td>\n",
       "      <td>28.256</td>\n",
       "      <td>97.290</td>\n",
       "      <td>25.812</td>\n",
       "      <td>97.210</td>\n",
       "      <td>26.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9598</td>\n",
       "      <td>0.272712</td>\n",
       "      <td>94.900</td>\n",
       "      <td>97.020</td>\n",
       "      <td>28.264</td>\n",
       "      <td>97.702</td>\n",
       "      <td>22.558</td>\n",
       "      <td>97.360</td>\n",
       "      <td>24.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2502</td>\n",
       "      <td>0.271081</td>\n",
       "      <td>94.398</td>\n",
       "      <td>97.084</td>\n",
       "      <td>25.282</td>\n",
       "      <td>97.098</td>\n",
       "      <td>24.650</td>\n",
       "      <td>97.090</td>\n",
       "      <td>24.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5372</td>\n",
       "      <td>0.245640</td>\n",
       "      <td>94.674</td>\n",
       "      <td>97.038</td>\n",
       "      <td>26.278</td>\n",
       "      <td>97.440</td>\n",
       "      <td>23.256</td>\n",
       "      <td>97.238</td>\n",
       "      <td>24.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.2332</td>\n",
       "      <td>0.278567</td>\n",
       "      <td>94.772</td>\n",
       "      <td>97.008</td>\n",
       "      <td>27.254</td>\n",
       "      <td>97.576</td>\n",
       "      <td>22.326</td>\n",
       "      <td>97.290</td>\n",
       "      <td>24.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8846</td>\n",
       "      <td>0.264757</td>\n",
       "      <td>94.624</td>\n",
       "      <td>97.130</td>\n",
       "      <td>28.256</td>\n",
       "      <td>97.290</td>\n",
       "      <td>25.812</td>\n",
       "      <td>97.210</td>\n",
       "      <td>26.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8406</td>\n",
       "      <td>0.279563</td>\n",
       "      <td>94.538</td>\n",
       "      <td>96.976</td>\n",
       "      <td>24.490</td>\n",
       "      <td>97.362</td>\n",
       "      <td>21.626</td>\n",
       "      <td>97.168</td>\n",
       "      <td>22.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.2286</td>\n",
       "      <td>0.267459</td>\n",
       "      <td>94.780</td>\n",
       "      <td>96.934</td>\n",
       "      <td>26.054</td>\n",
       "      <td>97.668</td>\n",
       "      <td>20.234</td>\n",
       "      <td>97.298</td>\n",
       "      <td>22.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4166</td>\n",
       "      <td>0.311426</td>\n",
       "      <td>86.982</td>\n",
       "      <td>97.392</td>\n",
       "      <td>12.012</td>\n",
       "      <td>88.854</td>\n",
       "      <td>38.604</td>\n",
       "      <td>92.918</td>\n",
       "      <td>18.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8846</td>\n",
       "      <td>0.264757</td>\n",
       "      <td>94.624</td>\n",
       "      <td>97.130</td>\n",
       "      <td>28.256</td>\n",
       "      <td>97.290</td>\n",
       "      <td>25.812</td>\n",
       "      <td>97.210</td>\n",
       "      <td>26.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4712</td>\n",
       "      <td>0.240970</td>\n",
       "      <td>94.572</td>\n",
       "      <td>96.862</td>\n",
       "      <td>22.992</td>\n",
       "      <td>97.522</td>\n",
       "      <td>18.372</td>\n",
       "      <td>97.188</td>\n",
       "      <td>19.856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cv_idx  train_0  train_1  train_2  train_y  test_size  rnn_layers  \\\n",
       "model_id                                                                      \n",
       "1            2.0   9222.0     21.0     73.0      2.0     2306.0         1.0   \n",
       "2            2.0   9222.0     21.0     73.0      2.0     2306.0         2.0   \n",
       "3            2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "4            2.0   9222.0     21.0     73.0      2.0     2306.0         4.0   \n",
       "5            2.0   9222.0     21.0     73.0      2.0     2306.0         5.0   \n",
       "6            2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "7            2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "8            2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "9            2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "10           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "11           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "12           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "13           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "14           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "15           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "16           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "17           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "18           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "19           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "20           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "21           2.0   9222.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "\n",
       "          rnn_neurons  dnn_layers  dnn_neurons  ...  regularizer_bias  \\\n",
       "model_id                                        ...                     \n",
       "1                64.0         3.0         64.0  ...               NaN   \n",
       "2                64.0         3.0         64.0  ...               NaN   \n",
       "3                64.0         3.0         64.0  ...               NaN   \n",
       "4                64.0         3.0         64.0  ...               NaN   \n",
       "5                64.0         3.0         64.0  ...               NaN   \n",
       "6                32.0         3.0         64.0  ...               NaN   \n",
       "7                64.0         3.0         64.0  ...               NaN   \n",
       "8               128.0         3.0         64.0  ...               NaN   \n",
       "9               256.0         3.0         64.0  ...               NaN   \n",
       "10               64.0         1.0         64.0  ...               NaN   \n",
       "11               64.0         2.0         64.0  ...               NaN   \n",
       "12               64.0         3.0         64.0  ...               NaN   \n",
       "13               64.0         4.0         64.0  ...               NaN   \n",
       "14               64.0         5.0         64.0  ...               NaN   \n",
       "15               64.0         2.0         32.0  ...               NaN   \n",
       "16               64.0         2.0         64.0  ...               NaN   \n",
       "17               64.0         2.0        128.0  ...               NaN   \n",
       "18               64.0         2.0        256.0  ...               NaN   \n",
       "19               64.0         2.0         64.0  ...               NaN   \n",
       "20               64.0         2.0         64.0  ...               NaN   \n",
       "21               64.0         2.0         64.0  ...               NaN   \n",
       "\n",
       "          training_time  test_loss  accuracy  precision_0  precision_1  \\\n",
       "model_id                                                                 \n",
       "1                1.6876   0.318821    90.148       96.958       12.972   \n",
       "2                2.0566   0.355052    89.706       97.214       15.480   \n",
       "3                3.9598   0.272712    94.900       97.020       28.264   \n",
       "4                5.3296   0.238907    94.408       97.050       25.344   \n",
       "5                4.2898   0.251065    94.450       96.982       23.972   \n",
       "6                2.3550   0.351971    89.296       97.270       14.908   \n",
       "7                3.9598   0.272712    94.900       97.020       28.264   \n",
       "8                4.4964   0.233586    94.400       96.938       23.204   \n",
       "9                4.3342   0.237007    94.484       96.734       19.840   \n",
       "10               3.7586   0.280655    94.876       97.046       27.662   \n",
       "11               4.8846   0.264757    94.624       97.130       28.256   \n",
       "12               3.9598   0.272712    94.900       97.020       28.264   \n",
       "13               4.2502   0.271081    94.398       97.084       25.282   \n",
       "14               5.5372   0.245640    94.674       97.038       26.278   \n",
       "15               5.2332   0.278567    94.772       97.008       27.254   \n",
       "16               4.8846   0.264757    94.624       97.130       28.256   \n",
       "17               3.8406   0.279563    94.538       96.976       24.490   \n",
       "18               5.2286   0.267459    94.780       96.934       26.054   \n",
       "19               2.4166   0.311426    86.982       97.392       12.012   \n",
       "20               4.8846   0.264757    94.624       97.130       28.256   \n",
       "21               2.4712   0.240970    94.572       96.862       22.992   \n",
       "\n",
       "          recall_0  recall_1    f1_0    f1_1  \n",
       "model_id                                      \n",
       "1           92.686    24.650  94.724  15.642  \n",
       "2           91.948    31.860  94.456  19.472  \n",
       "3           97.702    22.558  97.360  24.702  \n",
       "4           97.144    23.722  97.092  23.698  \n",
       "5           97.260    21.860  97.120  22.758  \n",
       "6           91.460    33.488  94.200  19.888  \n",
       "7           97.702    22.558  97.360  24.702  \n",
       "8           97.252    20.696  97.096  21.686  \n",
       "9           97.566    14.884  97.146  16.158  \n",
       "10          97.650    23.254  97.346  25.160  \n",
       "11          97.290    25.812  97.210  26.614  \n",
       "12          97.702    22.558  97.360  24.702  \n",
       "13          97.098    24.650  97.090  24.748  \n",
       "14          97.440    23.256  97.238  24.548  \n",
       "15          97.576    22.326  97.290  24.290  \n",
       "16          97.290    25.812  97.210  26.614  \n",
       "17          97.362    21.626  97.168  22.880  \n",
       "18          97.668    20.234  97.298  22.508  \n",
       "19          88.854    38.604  92.918  18.248  \n",
       "20          97.290    25.812  97.210  26.614  \n",
       "21          97.522    18.372  97.188  19.856  \n",
       "\n",
       "[21 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_layers     : [1, 2, '3', 4, 5]\n",
      "rnn_neurons    : [32, '64', 128, 256]\n",
      "dnn_layers     : [1, '2', 3, 4, 5]\n",
      "dnn_neurons    : [32, '64', 128, 256]\n",
      "learning_rate  : [0.0001, '0.001', 0.01]\n"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update  = False\n",
    "\n",
    "params = initial_params.copy()\n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "model_id = 1\n",
    "verbose = 0\n",
    "for param_name, space in search_space.items():\n",
    "    for point in space:\n",
    "        clear_output(wait=True)\n",
    "        display(METRIC_MEAN)\n",
    "        params[param_name] = point\n",
    "        for key, value in search_space.items():\n",
    "            print(f'{key:<14} : {value}')\n",
    "        \n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        for name in protein_names:\n",
    "            data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "            ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "            \n",
    "            # get X dataset\n",
    "            x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "            x_features = list(x_onehot.columns)\n",
    "            \n",
    "            # get Y dataset\n",
    "            y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "            y_labels = list(y_onehot.columns)\n",
    "            \n",
    "            for idx in ST_idx:\n",
    "                window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "                label_y  = np.array(y_onehot.iloc[idx])\n",
    "                \n",
    "                data_x.append(window_x)\n",
    "                data_y.append(label_y)\n",
    "                \n",
    "        data_x = np.array(data_x)\n",
    "        data_y = np.array(data_y)\n",
    "        model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "        print('data x shape:', data_x.shape)\n",
    "        print('data y shape:', data_y.shape)\n",
    "        print('class y counts:', data_y.sum(0))\n",
    "        print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "        \n",
    "        splitter = StratifiedShuffleSplit(n_splits = 1, test_size = test_size, random_state = SEED)\n",
    "        train_idx, test_idx = list(splitter.split(data_x, data_y))[0]\n",
    "        \n",
    "        train_x = data_x[train_idx]\n",
    "        train_y = data_y[train_idx]\n",
    "        \n",
    "        test_x = data_x[test_idx]\n",
    "        test_y = data_y[test_idx]\n",
    "        \n",
    "        train_x, test_x = data_scaling(train_x, test_x)\n",
    "        \n",
    "        splitter_kf = KFold(n_splits = 5)\n",
    "        for cv_idx, (train_idx_kf, test_idx_kf) in enumerate(splitter_kf.split(train_x, train_y)):\n",
    "            train_x_kf, train_y_kf = train_x[train_idx_kf], train_y[train_idx_kf]\n",
    "            test_x_kf, test_y_kf   = train_x[test_idx_kf],  train_y[test_idx_kf]\n",
    "            \n",
    "            # up-sample the training dataset\n",
    "            train_x_kf, train_y_kf = upsample_data(train_x_kf, train_y_kf) \n",
    "            \n",
    "            model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) \n",
    "            model_name = name_model(f'{model_type}_KFOLD', params)\n",
    "            \n",
    "            model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "            if not os.path.exists(model_folder):\n",
    "                os.makedirs(model_folder)\n",
    "            model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "            metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(model_path) or model_update:\n",
    "                time_start = time.time()\n",
    "                history = model.fit(train_x_kf, train_y_kf, verbose=verbose, \n",
    "                                    epochs = 10000, callbacks = callbacks,\n",
    "                                    validation_data = (test_x_kf, test_y_kf))\n",
    "                time_end = time.time()\n",
    "                training_time = round((time_end - time_start)/60, 3)\n",
    "                \n",
    "                model.save_weights(model_path)\n",
    "                \n",
    "                test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "                model_metrics = {\n",
    "                    'model_id' : model_id,\n",
    "                    'cv_idx'   : cv_idx,\n",
    "                    **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "                    'train_y'     : train_y.shape[-1],\n",
    "                    'test_size'   : test_x.shape[0],\n",
    "                    **params,\n",
    "                    'regularizer_input' : params['regularizer']['input'],\n",
    "                    'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "                    'regularizer_bias' : params['regularizer']['bias'],\n",
    "                    'training_time': training_time,\n",
    "                    'test_loss': test_loss,\n",
    "                    'accuracy': accuracy,\n",
    "                    **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "                    **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "                    **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "                \n",
    "                model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "                model_metrics.to_csv(metric_path, index=False)\n",
    "                \n",
    "            else:\n",
    "                model.load_weights(model_path)\n",
    "                model_metrics = pd.read_csv(metric_path, header=0)\n",
    "                \n",
    "            print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "            \n",
    "            model_metrics['model_id'] = model_id\n",
    "            METRICs.append(model_metrics)\n",
    "            MODELs.append(model)\n",
    "        \n",
    "        METRIC_MEAN = pd.concat(METRICs).groupby('model_id').mean()\n",
    "        f1_best = METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0].f1_1\n",
    "        print(f'best f1 score: {f1_best}')\n",
    "        model_id += 1\n",
    "    if param_name in ['learning_rate']: # for float-type parameters\n",
    "        best_value = float(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "    else: # for int-type parameters\n",
    "        best_value = int(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(METRIC_MEAN)\n",
    "for key, value in search_space.items():\n",
    "    print(f'{key:<14} : {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605f263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape:  (11528, 21, 73)\n",
      "data y shape:  (11528, 2)\n",
      "train x shape: (9222, 21, 73)\n",
      "test  x shape: (2306, 2)\n"
     ]
    }
   ],
   "source": [
    "print('data x shape: ', data_x.shape)\n",
    "print('data y shape: ', data_y.shape)\n",
    "print('train x shape:', train_x.shape)\n",
    "print('test  x shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6755e958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "rnn_layers     : 3\n",
      "rnn_neurons    : 64\n",
      "dnn_layers     : 2\n",
      "dnn_neurons    : 64\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "for key, value in params.items():\n",
    "    print(f'{key:<14} : {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ff058",
   "metadata": {},
   "source": [
    "## evaluate model's general performance through Monte-Carlo cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05807f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape: (11528, 21, 73)\n",
      "data y shape: (11528, 2)\n",
      "class y counts: [11100   428]\n",
      "class y ratio: [0.9629 0.0371]\n",
      "f1 score: 29.09\n",
      "f1 score: 29.630000000000003\n",
      "f1 score: 19.39\n",
      "f1 score: 21.59\n",
      "f1 score: 26.58\n"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update = False\n",
    "            \n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "verbose = 0\n",
    "        \n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for name in protein_names:\n",
    "    data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "    ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "    \n",
    "    # get X dataset\n",
    "    x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "    x_features = list(x_onehot.columns)\n",
    "    \n",
    "    # get Y dataset\n",
    "    y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "    y_labels = list(y_onehot.columns)\n",
    "    \n",
    "    for idx in ST_idx:\n",
    "        window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "        label_y  = np.array(y_onehot.iloc[idx])\n",
    "        \n",
    "        data_x.append(window_x)\n",
    "        data_y.append(label_y)\n",
    "        \n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "print('data x shape:', data_x.shape)\n",
    "print('data y shape:', data_y.shape)\n",
    "print('class y counts:', data_y.sum(0))\n",
    "print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits = 5, test_size = test_size, random_state = SEED)\n",
    "for cv_idx, (train_idx, test_idx) in enumerate(splitter.split(data_x, data_y)):\n",
    "    train_x, train_y = data_x[train_idx], data_y[train_idx]\n",
    "    train_x, train_y = upsample_data(train_x, train_y) # up-sample the training dataset\n",
    "    test_x , test_y  = data_x[test_idx],  data_y[test_idx]\n",
    "    \n",
    "    train_x, test_x = data_scaling(train_x, test_x)\n",
    "    \n",
    "    model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params)\n",
    "    model_name = name_model(f'{model_type}', params)\n",
    "    \n",
    "    \n",
    "    model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "    model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "    metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(model_path) or model_update:\n",
    "        time_start = time.time()\n",
    "        history = model.fit(train_x, train_y, verbose=verbose, \n",
    "                            epochs = 10000, callbacks = callbacks,\n",
    "                            validation_split = test_size/(1-test_size))\n",
    "        time_end = time.time()\n",
    "        training_time = round((time_end - time_start)/60, 3)\n",
    "        \n",
    "        model.save_weights(model_path)\n",
    "        \n",
    "        test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "        model_metrics = {\n",
    "            'model_id' : model_id,\n",
    "            'cv_idx'   : cv_idx,\n",
    "            **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "            'train_y'     : train_y.shape[-1],\n",
    "            'test_size'   : test_x.shape[0],\n",
    "            **params,\n",
    "            'regularizer_input' : params['regularizer']['input'],\n",
    "            'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "            'regularizer_bias' : params['regularizer']['bias'],\n",
    "            'training_time': training_time,\n",
    "            'test_loss': test_loss,\n",
    "            'accuracy': accuracy,\n",
    "            **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "            **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "            **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "        model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "        model_metrics.to_csv(metric_path, index=False)\n",
    "        \n",
    "    else:\n",
    "        model.load_weights(model_path)\n",
    "        model_metrics = pd.read_csv(metric_path, header=0)\n",
    "        \n",
    "    print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "    \n",
    "    METRICs.append(model_metrics)\n",
    "    MODELs.append(model)\n",
    "\n",
    "METRICs = pd.concat(METRICs)\n",
    "METRIC_MEAN = METRICs.groupby('model_id').mean()\n",
    "METRIC_STD = METRICs.groupby('model_id').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b460f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_0</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_2</th>\n",
       "      <th>train_y</th>\n",
       "      <th>test_size</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>rnn_neurons</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>...</th>\n",
       "      <th>regularizer_bias</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>17760</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2306</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.885</td>\n",
       "      <td>0.246517</td>\n",
       "      <td>94.93</td>\n",
       "      <td>97.22</td>\n",
       "      <td>30.38</td>\n",
       "      <td>97.52</td>\n",
       "      <td>27.91</td>\n",
       "      <td>97.37</td>\n",
       "      <td>29.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>17760</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2306</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.301</td>\n",
       "      <td>0.346723</td>\n",
       "      <td>95.06</td>\n",
       "      <td>97.22</td>\n",
       "      <td>31.58</td>\n",
       "      <td>97.66</td>\n",
       "      <td>27.91</td>\n",
       "      <td>97.44</td>\n",
       "      <td>29.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>17760</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2306</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.040</td>\n",
       "      <td>0.481840</td>\n",
       "      <td>94.23</td>\n",
       "      <td>96.86</td>\n",
       "      <td>20.25</td>\n",
       "      <td>97.16</td>\n",
       "      <td>18.60</td>\n",
       "      <td>97.01</td>\n",
       "      <td>19.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>17760</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2306</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.506</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>94.02</td>\n",
       "      <td>96.98</td>\n",
       "      <td>21.11</td>\n",
       "      <td>96.80</td>\n",
       "      <td>22.09</td>\n",
       "      <td>96.89</td>\n",
       "      <td>21.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>17760</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>2306</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.234</td>\n",
       "      <td>0.296555</td>\n",
       "      <td>94.97</td>\n",
       "      <td>97.09</td>\n",
       "      <td>29.17</td>\n",
       "      <td>97.70</td>\n",
       "      <td>24.42</td>\n",
       "      <td>97.40</td>\n",
       "      <td>26.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id  cv_idx  train_0  train_1  train_2  train_y  test_size  \\\n",
       "0        22       0    17760       21       73        2       2306   \n",
       "0        22       1    17760       21       73        2       2306   \n",
       "0        22       2    17760       21       73        2       2306   \n",
       "0        22       3    17760       21       73        2       2306   \n",
       "0        22       4    17760       21       73        2       2306   \n",
       "\n",
       "   rnn_layers  rnn_neurons  dnn_layers  ...  regularizer_bias  training_time  \\\n",
       "0           3           64           2  ...               NaN          4.885   \n",
       "0           3           64           2  ...               NaN          4.301   \n",
       "0           3           64           2  ...               NaN          5.040   \n",
       "0           3           64           2  ...               NaN          3.506   \n",
       "0           3           64           2  ...               NaN          4.234   \n",
       "\n",
       "   test_loss  accuracy  precision_0  precision_1  recall_0  recall_1   f1_0  \\\n",
       "0   0.246517     94.93        97.22        30.38     97.52     27.91  97.37   \n",
       "0   0.346723     95.06        97.22        31.58     97.66     27.91  97.44   \n",
       "0   0.481840     94.23        96.86        20.25     97.16     18.60  97.01   \n",
       "0   0.358805     94.02        96.98        21.11     96.80     22.09  96.89   \n",
       "0   0.296555     94.97        97.09        29.17     97.70     24.42  97.40   \n",
       "\n",
       "    f1_1  \n",
       "0  29.09  \n",
       "0  29.63  \n",
       "0  19.39  \n",
       "0  21.59  \n",
       "0  26.58  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c23ab902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_0</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_2</th>\n",
       "      <th>train_y</th>\n",
       "      <th>test_size</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>rnn_neurons</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>dnn_neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>regularizer_bias</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17760.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3932</td>\n",
       "      <td>0.346088</td>\n",
       "      <td>94.642</td>\n",
       "      <td>97.074</td>\n",
       "      <td>26.498</td>\n",
       "      <td>97.368</td>\n",
       "      <td>24.186</td>\n",
       "      <td>97.222</td>\n",
       "      <td>25.256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cv_idx  train_0  train_1  train_2  train_y  test_size  rnn_layers  \\\n",
       "model_id                                                                      \n",
       "22           2.0  17760.0     21.0     73.0      2.0     2306.0         3.0   \n",
       "\n",
       "          rnn_neurons  dnn_layers  dnn_neurons  ...  regularizer_bias  \\\n",
       "model_id                                        ...                     \n",
       "22               64.0         2.0         64.0  ...               NaN   \n",
       "\n",
       "          training_time  test_loss  accuracy  precision_0  precision_1  \\\n",
       "model_id                                                                 \n",
       "22               4.3932   0.346088    94.642       97.074       26.498   \n",
       "\n",
       "          recall_0  recall_1    f1_0    f1_1  \n",
       "model_id                                      \n",
       "22          97.368    24.186  97.222  25.256  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRIC_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f54124b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_0</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_2</th>\n",
       "      <th>train_y</th>\n",
       "      <th>test_size</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>rnn_neurons</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>dnn_neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>regularizer_bias</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60852</td>\n",
       "      <td>0.087975</td>\n",
       "      <td>0.480073</td>\n",
       "      <td>0.156141</td>\n",
       "      <td>5.387585</td>\n",
       "      <td>0.382256</td>\n",
       "      <td>3.98082</td>\n",
       "      <td>0.253121</td>\n",
       "      <td>4.567108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cv_idx  train_0  train_1  train_2  train_y  test_size  rnn_layers  \\\n",
       "model_id                                                                        \n",
       "22        1.581139      0.0      0.0      0.0      0.0        0.0         0.0   \n",
       "\n",
       "          rnn_neurons  dnn_layers  dnn_neurons  ...  regularizer_bias  \\\n",
       "model_id                                        ...                     \n",
       "22                0.0         0.0          0.0  ...               NaN   \n",
       "\n",
       "          training_time  test_loss  accuracy  precision_0  precision_1  \\\n",
       "model_id                                                                 \n",
       "22              0.60852   0.087975  0.480073     0.156141     5.387585   \n",
       "\n",
       "          recall_0  recall_1      f1_0      f1_1  \n",
       "model_id                                          \n",
       "22        0.382256   3.98082  0.253121  4.567108  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRIC_STD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
