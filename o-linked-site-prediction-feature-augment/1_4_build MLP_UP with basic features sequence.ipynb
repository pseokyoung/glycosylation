{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b246081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed for the reproducible result\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41490bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of initial proteins: 121\n",
      "['24622_2', 'A0A024RAY2_P05783', 'A2ABU4', 'A2AHJ4', 'A2AKB9', 'A2AQ25', 'E9K9Z1', 'E9Q1P8', 'E9Q5G3', 'O08537']\n"
     ]
    }
   ],
   "source": [
    "augmented_dir = './data/_augmented_features' # we will get names from the augmented proteins\n",
    "augmented_proteins = [x[:-4] for x in os.listdir(augmented_dir) if x[-3:] == 'csv'] # get protein name list to be processed for building machine learning models\n",
    "print('the number of initial proteins:', len(augmented_proteins))\n",
    "print(augmented_proteins[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c2c79",
   "metadata": {},
   "source": [
    "# build amino acid sequence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2db99a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4501 entries, 0 to 4500\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   UniprotKB ID   4501 non-null   object \n",
      " 1   organism       4501 non-null   object \n",
      " 2   oglcnacscore   4501 non-null   float64\n",
      " 3   oglcnac sites  4501 non-null   object \n",
      " 4   sequence       4501 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 211.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniprotKB ID</th>\n",
       "      <th>organism</th>\n",
       "      <th>oglcnacscore</th>\n",
       "      <th>oglcnac sites</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>Q00587</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>12.207032</td>\n",
       "      <td>[132]</td>\n",
       "      <td>MPGPQGGRGAATMSLGKLSPVGWVSSSQGKRRLTADMISHPLGDFR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>Q9BQC3</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>27.611586</td>\n",
       "      <td>[467, 470, 474]</td>\n",
       "      <td>MESMFSSPAEAALQRETGVPGLLTPLPDLDGVYELERVAGFVRDLG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>Q9UIJ7</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>11.665506</td>\n",
       "      <td>[18]</td>\n",
       "      <td>MGASARLLRAVIMGAPGSGKGTVSSRITTHFELKHLSSGDLLRDNM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>Q9NQ66</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>6.005927</td>\n",
       "      <td>[187, 473]</td>\n",
       "      <td>MAGAQPGVHALQLKPVCVSDSLKKGTKFVKWDDDSTIVTPIILRTD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>O75152</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>5.077726</td>\n",
       "      <td>[382, 443, 543, 579]</td>\n",
       "      <td>MPNQGEDCYFFFYSTCTKGDSCPFRHCEAAIGNETVCTLWQEGRCF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>Q8N135</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>12.716548</td>\n",
       "      <td>[337]</td>\n",
       "      <td>MGGAGILLLLLAGAGVVVAWRPPKGKCPLRCSCSKDSALCEGSPDL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>Q14247</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>18.858372</td>\n",
       "      <td>[11, 240, 277, 322, 323, 328, 331, 332, 345, 401]</td>\n",
       "      <td>MWKASAGHAVSIAQDDAGADDWETDPDFVNDVSEKEQRWGAKTVQG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>E9Q555</td>\n",
       "      <td>Mus musculus</td>\n",
       "      <td>11.752367</td>\n",
       "      <td>[1202, 1206]</td>\n",
       "      <td>MECPQCGHVSSEKAPKFCSECGQKLPSAATVQGDLKNDNTLVVSST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>Q9H4A4</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>16.163186</td>\n",
       "      <td>[60, 247]</td>\n",
       "      <td>MASGEHSPGSGAARRPLHSAQAVDVASASNFRAFELLHLHLDLRAE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>Q80TE4</td>\n",
       "      <td>Mus musculus</td>\n",
       "      <td>20.868470</td>\n",
       "      <td>[1702, 1704]</td>\n",
       "      <td>MSDPRPSQAEKHKLGRAAAKLKDPSRTMQADDYFARKFKAINGSMG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniprotKB ID      organism  oglcnacscore  \\\n",
       "1634       Q00587  Homo sapiens     12.207032   \n",
       "3687       Q9BQC3  Homo sapiens     27.611586   \n",
       "4244       Q9UIJ7  Homo sapiens     11.665506   \n",
       "4005       Q9NQ66  Homo sapiens      6.005927   \n",
       "468        O75152  Homo sapiens      5.077726   \n",
       "3042       Q8N135  Homo sapiens     12.716548   \n",
       "1910       Q14247  Homo sapiens     18.858372   \n",
       "151        E9Q555  Mus musculus     11.752367   \n",
       "3896       Q9H4A4  Homo sapiens     16.163186   \n",
       "2749       Q80TE4  Mus musculus     20.868470   \n",
       "\n",
       "                                          oglcnac sites  \\\n",
       "1634                                              [132]   \n",
       "3687                                    [467, 470, 474]   \n",
       "4244                                               [18]   \n",
       "4005                                         [187, 473]   \n",
       "468                                [382, 443, 543, 579]   \n",
       "3042                                              [337]   \n",
       "1910  [11, 240, 277, 322, 323, 328, 331, 332, 345, 401]   \n",
       "151                                        [1202, 1206]   \n",
       "3896                                          [60, 247]   \n",
       "2749                                       [1702, 1704]   \n",
       "\n",
       "                                               sequence  \n",
       "1634  MPGPQGGRGAATMSLGKLSPVGWVSSSQGKRRLTADMISHPLGDFR...  \n",
       "3687  MESMFSSPAEAALQRETGVPGLLTPLPDLDGVYELERVAGFVRDLG...  \n",
       "4244  MGASARLLRAVIMGAPGSGKGTVSSRITTHFELKHLSSGDLLRDNM...  \n",
       "4005  MAGAQPGVHALQLKPVCVSDSLKKGTKFVKWDDDSTIVTPIILRTD...  \n",
       "468   MPNQGEDCYFFFYSTCTKGDSCPFRHCEAAIGNETVCTLWQEGRCF...  \n",
       "3042  MGGAGILLLLLAGAGVVVAWRPPKGKCPLRCSCSKDSALCEGSPDL...  \n",
       "1910  MWKASAGHAVSIAQDDAGADDWETDPDFVNDVSEKEQRWGAKTVQG...  \n",
       "151   MECPQCGHVSSEKAPKFCSECGQKLPSAATVQGDLKNDNTLVVSST...  \n",
       "3896  MASGEHSPGSGAARRPLHSAQAVDVASASNFRAFELLHLHLDLRAE...  \n",
       "2749  MSDPRPSQAEKHKLGRAAAKLKDPSRTMQADDYFARKFKAINGSMG...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oglcnac_data = pd.read_csv('./data\\oglcnacome_sites.csv', index_col=0) \n",
    "print(oglcnac_data.info())\n",
    "oglcnac_data.sample(10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5a49d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff6ffa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of matching proteins: 121 -> 105\n",
      "\n",
      "5 duplicated proteins\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'P05783': 'P05783',\n",
       " 'P0CG62_P0CG49': 'P0CG49',\n",
       " 'P63249_P63248': 'P63248',\n",
       " 'Q4R561_P60710': 'P60710',\n",
       " 'Q9WVB1_P35279': 'P35279'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 proteins not in o-glcnacome database\n",
      "['24622_2', 'E9K9Z1', 'O08984', 'P02470', 'P02488', 'P02505', 'P04799', 'P05451', 'P07756']\n",
      "\n",
      "2 proteins not in secondary database\n",
      "['P24622', 'P24622']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "augmented protein names include either single element like 'P53621' or multiple elements like 'A0A024RAY2_P05783'\n",
    "first step is to check if name elements exist in the o-glcnacome database column 'UniprotKB ID' \n",
    "if any element exists in the database, then build a dataset of the protein's amino acid sequence with its positive locations\n",
    "'''\n",
    "\n",
    "# Convert UniprotKB IDs to a set for faster lookup\n",
    "database_proteins = set(oglcnac_data['UniprotKB ID'].values)\n",
    "\n",
    "# Initialize dictionaries and list\n",
    "positivity_data = {}  # \"protein name : sequence with positive sites\"\n",
    "name_augmented_oglcnacome = {}  # names between augmented proteins and database\n",
    "not_in_database  = []  # proteins not in the database\n",
    "not_in_secondary = [] # proteins not in the database\n",
    "duplicated = {} # duplicated proteins\n",
    "\n",
    "for protein_name in augmented_proteins:\n",
    "    name_elements = protein_name.split('_')  # Split protein names by '_'\n",
    "    \n",
    "    for element in name_elements:\n",
    "        if element in database_proteins:\n",
    "            oglcnac_name = element\n",
    "            break\n",
    "        else:\n",
    "            oglcnac_name = None\n",
    "    \n",
    "    if oglcnac_name: \n",
    "        if oglcnac_name in positivity_data:\n",
    "            duplicated[protein_name] = oglcnac_name\n",
    "            \n",
    "        # Update name matching if protein name has multiple elements\n",
    "        if len(name_elements) > 1:\n",
    "            name_augmented_oglcnacome[protein_name] = oglcnac_name\n",
    "            protein_name = oglcnac_name\n",
    "            \n",
    "        if os.path.exists(f\"./data/_secondary_structure/dynamine_results/{protein_name}_backbone.pred\"):\n",
    "            # Retrieve sequence data and update dataset\n",
    "            protein_oglcnac = oglcnac_data[oglcnac_data['UniprotKB ID'] == oglcnac_name]\n",
    "            positivity_data[protein_name] = sequence_with_positivity(protein_oglcnac)\n",
    "        else:\n",
    "            not_in_secondary.append(protein_name)\n",
    "            \n",
    "    else:\n",
    "        not_in_database.append(protein_name)\n",
    "\n",
    "print(f'total number of matching proteins: {len(augmented_proteins)} -> {len(positivity_data)}\\n')\n",
    "\n",
    "print(f'{len(duplicated)} duplicated proteins')\n",
    "display(duplicated)\n",
    "\n",
    "print(f'{len(not_in_database)} proteins not in o-glcnacome database')\n",
    "print(not_in_database)\n",
    "\n",
    "print(f'\\n{len(not_in_secondary)} proteins not in secondary database')\n",
    "print(not_in_secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a297c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented proteins : o-glcnacome database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A0A024RAY2_P05783': 'P05783',\n",
       " 'P0CG62_P0CG49': 'P0CG49',\n",
       " 'P24622_2': 'P24622',\n",
       " 'P63249_P63248': 'P63248',\n",
       " 'P68406_P24622_2': 'P24622',\n",
       " 'Q4R561_P60710': 'P60710',\n",
       " 'Q9WVB1_P35279': 'P35279'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('augmented proteins : o-glcnacome database')\n",
    "display(name_augmented_oglcnacome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f38d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mauri_feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5a5adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 430 entries, 0 to 429\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   residue      430 non-null    object \n",
      " 1   side_-1      430 non-null    object \n",
      " 2   side_1       430 non-null    object \n",
      " 3   side_2       430 non-null    object \n",
      " 4   side_3       430 non-null    object \n",
      " 5   side_4       430 non-null    object \n",
      " 6   side_5       430 non-null    object \n",
      " 7   npa(-3,-1)   430 non-null    int64  \n",
      " 8   ppo(-7,-5)   430 non-null    int64  \n",
      " 9   s/t          430 non-null    int64  \n",
      " 10  flexibility  430 non-null    float64\n",
      " 11  ss           430 non-null    object \n",
      " 12  p(1)         430 non-null    int64  \n",
      " 13  ss_angle     430 non-null    object \n",
      " 14  positivity   430 non-null    int64  \n",
      "dtypes: float64(1), int64(5), object(9)\n",
      "memory usage: 50.5+ KB\n"
     ]
    }
   ],
   "source": [
    "different_length = [] # difference between length of secondary and flexibility dataset\n",
    "secondary_data = {}\n",
    "\n",
    "for protein_name in positivity_data:\n",
    "    # process flexibility data\n",
    "    flexibility = pd.read_fwf(f\"./data/_secondary_structure/dynamine_results/{protein_name}_backbone.pred\", header=None, names=['flexibility']).iloc[11:].reset_index(drop=True)\n",
    "    flexibility = flexibility['flexibility'].apply(lambda x: x.split()[1]).to_frame().astype({'flexibility':float})\n",
    "    \n",
    "    # process secondary structure data\n",
    "    temp   = pd.read_csv(f\"./data/_secondary_structure/spider3_results/{protein_name}.spd33\")\n",
    "    columns = temp.columns[0].split()\n",
    "    secondary = pd.DataFrame(columns=columns)\n",
    "    for i, column in enumerate(columns):\n",
    "        secondary[column] = temp.iloc[:,0].apply(lambda x: x.split()[i])\n",
    "        if i >= 3:\n",
    "            secondary[column] = secondary[column].astype('float')\n",
    "\n",
    "    secondary.index.name = protein_name\n",
    "    \n",
    "    if len(flexibility) == len(secondary):\n",
    "        mauri = secondary[['SEQ']].copy()\n",
    "        mauri = mauri.rename(columns = {'SEQ' : 'residue'})\n",
    "        sequence = mauri['residue'].sum()\n",
    "        \n",
    "        # make window for easier feature computation\n",
    "        mauri['window'] = pd.Series([make_window(mauri['residue'].sum(), x) for x in mauri.index])\n",
    "        # side chain -1 to 5\n",
    "        for num in range(-1, 6):\n",
    "            if num != 0:\n",
    "                mauri[f'side_{num}'] = mauri.window.apply(lambda x: mauri_side(x, num))\n",
    "        \n",
    "        # non-polar aliphatic -3 to -1\n",
    "        mauri['npa(-3,-1)'] = mauri.window.apply(mauri_npa)\n",
    "        \n",
    "        # polar positive -7 to -5\n",
    "        mauri['ppo(-7,-5)'] = mauri.window.apply(mauri_ppo)\n",
    "        \n",
    "        # number of S and T -10 to 10\n",
    "        mauri['s/t'] = mauri.window.apply(mauri_st)\n",
    "        \n",
    "        # flexibility\n",
    "        mauri = pd.concat([mauri, flexibility], axis=1)\n",
    "        \n",
    "        # secondary structure\n",
    "        mauri['ss'] = secondary['SS']\n",
    "        \n",
    "        # presence of proline at +1\n",
    "        mauri['p(1)'] = mauri.window.apply(is_proline)\n",
    "        \n",
    "        # secondary structure by phi and psi\n",
    "        mauri['ss_angle'] = secondary.apply(lambda x: ss_angle(x['Phi'], x['Psi']), axis=1)\n",
    "        \n",
    "        # nature of the site: S or T\n",
    "        mauri = pd.concat([mauri, positivity_data[protein_name][['positivity']]], axis=1)\n",
    "        \n",
    "        positivity_data[protein_name] = mauri.drop(['window'], axis=1)\n",
    "        \n",
    "    else:\n",
    "        different_length.append(protein_name)\n",
    "        \n",
    "next(iter(positivity_data.values())).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a7d8c7",
   "metadata": {},
   "source": [
    "## set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be395256",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_onehot = { # column_name : classes\n",
    "    # for input variables\n",
    "    'residue' : ['S', 'T'],\n",
    "    \n",
    "    # mauri's basic features\n",
    "    **{f'side_{num}' : ['very_small', 'small', 'normal', 'long', 'glycine', 'proline', 'aromatic'] for num in range(-1,6) if num != 0},\n",
    "    'ss' : ['C', 'E', 'H'],\n",
    "    'ss_angle' : ['alpha', 'other', 'beta'],\n",
    "    \n",
    "    # for output variables\n",
    "    'positivity' : [0, 1]\n",
    "}\n",
    "\n",
    "x_cts = ['npa(-3,-1)', 'ppo(-7,-5)', 's/t', 'flexibility', 'p(1)']\n",
    "x_cat = ['residue'] + \\\n",
    "    [f'side_{num}' for num in range(-1,6) if num != 0] + ['ss', 'ss_angle']\n",
    "x_var = x_cts + x_cat\n",
    "\n",
    "y_cts = []\n",
    "y_cat = ['positivity']\n",
    "y_var = y_cts + y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5d3ba",
   "metadata": {},
   "source": [
    "## hyper parameter optimization by K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a434108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from ml_models import *\n",
    "\n",
    "epochs = 1000\n",
    "from keras.callbacks import EarlyStopping\n",
    "patience = 30\n",
    "callbacks = [EarlyStopping(patience=patience, restore_best_weights=True, monitor='val_loss')]\n",
    "\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f185662",
   "metadata": {},
   "source": [
    "### set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfa4c4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters\n",
      "rnn_layers     : 1\n",
      "rnn_neurons    : 64\n",
      "dnn_layers     : 3\n",
      "dnn_neurons    : 64\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "model_type = 'MLP_UP_BASIC'\n",
    "\n",
    "initial_params = default_params.copy()\n",
    "initial_params.update({\n",
    "    'window_size'    : 10\n",
    "    })\n",
    "\n",
    "print('initial parameters')\n",
    "for key, value in initial_params.items():\n",
    "    print(f'{key:<14} : {value}')\n",
    "\n",
    "search_space = {\n",
    "    'dnn_layers'    : [1, 2, 3, 4, 5],\n",
    "    'dnn_neurons'   : [32, 64, 128, 256],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da184fcc",
   "metadata": {},
   "source": [
    "### model training with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c7dc049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_0</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_y</th>\n",
       "      <th>test_size</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>rnn_neurons</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>dnn_neurons</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>regularizer_bias</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9486.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.37</td>\n",
       "      <td>3.63</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.15</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9486.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.37</td>\n",
       "      <td>3.63</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.15</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9486.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.37</td>\n",
       "      <td>3.63</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.15</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9486.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.37</td>\n",
       "      <td>3.63</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.15</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cv_idx  train_0  train_1  train_y  test_size  rnn_layers  \\\n",
       "model_id                                                             \n",
       "1            2.0   9486.0   1155.0      2.0     2372.0         1.0   \n",
       "2            2.0   9486.0   1155.0      2.0     2372.0         1.0   \n",
       "3            2.0   9486.0   1155.0      2.0     2372.0         1.0   \n",
       "4            2.0   9486.0   1155.0      2.0     2372.0         1.0   \n",
       "\n",
       "          rnn_neurons  dnn_layers  dnn_neurons  learning_rate  ...  \\\n",
       "model_id                                                       ...   \n",
       "1                64.0         1.0         64.0          0.001  ...   \n",
       "2                64.0         2.0         64.0          0.001  ...   \n",
       "3                64.0         3.0         64.0          0.001  ...   \n",
       "4                64.0         4.0         64.0          0.001  ...   \n",
       "\n",
       "          regularizer_bias  training_time  test_loss  accuracy  precision_0  \\\n",
       "model_id                                                                      \n",
       "1                      NaN         0.5298        NaN       0.0        96.37   \n",
       "2                      NaN         0.5430        NaN       0.0        96.37   \n",
       "3                      NaN         0.5632        NaN       0.0        96.37   \n",
       "4                      NaN         0.6010        NaN       0.0        96.37   \n",
       "\n",
       "          precision_1  recall_0  recall_1   f1_0  f1_1  \n",
       "model_id                                                \n",
       "1                3.63     100.0     100.0  98.15   7.0  \n",
       "2                3.63     100.0     100.0  98.15   7.0  \n",
       "3                3.63     100.0     100.0  98.15   7.0  \n",
       "4                3.63     100.0     100.0  98.15   7.0  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_layers     : [1, 2, 3, 4, 5]\n",
      "dnn_neurons    : [32, 64, 128, 256]\n",
      "learning_rate  : [0.0001, 0.001, 0.01]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ss_angle_other'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\core\\frame.py:4110\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4110\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ss_angle_other'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m ST_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere((positivity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresidue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m|\u001b[39m (positivity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresidue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# get X dataset\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m x_onehot \u001b[38;5;241m=\u001b[39m \u001b[43mget_onehots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositivity\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_var\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfor_onehot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfor_onehot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m x_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(x_onehot\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# get Y dataset\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\honsu\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\functions.py:24\u001b[0m, in \u001b[0;36mget_onehots\u001b[1;34m(dataframe, columns, for_onehot)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m for_onehot[column]:\n\u001b[1;32m---> 24\u001b[0m         \u001b[43mdf_col\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcolumn\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df_col[column]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: is_equal(x, key))\n\u001b[0;32m     26\u001b[0m df_col \u001b[38;5;241m=\u001b[39m df_col\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat([df_col, df_not], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\core\\frame.py:4156\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[0;32m   4154\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m-> 4156\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4110\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[1;32m-> 4113\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value)\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1419\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[1;34m(self, loc, item, value)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_update_mgr_locs(loc)\n\u001b[1;32m-> 1419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_insert_update_blklocs_and_blknos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m new_axis\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (block,)\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1456\u001b[0m, in \u001b[0;36mBlockManager._insert_update_blklocs_and_blknos\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m   1454\u001b[0m     \u001b[38;5;66;03m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blknos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;66;03m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\honsu\\anaconda3\\envs\\python310\\lib\\site-packages\\numpy\\lib\\function_base.py:5617\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5615\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[0;32m   5616\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5617\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update  = False\n",
    "\n",
    "params = initial_params.copy()\n",
    "\n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "model_id = 1\n",
    "verbose = 0\n",
    "for param_name, space in search_space.items():\n",
    "    for point in space:\n",
    "        clear_output(wait=True)\n",
    "        display(METRIC_MEAN)\n",
    "        params[param_name] = point\n",
    "        for key, value in search_space.items():\n",
    "            print(f'{key:<14} : {value}')\n",
    "        \n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        for protein_name in positivity_data:\n",
    "            positivity = positivity_data.get(protein_name)\n",
    "            ST_idx = np.where((positivity['residue'] == 'S') | (positivity['residue'] == 'T'))[0]\n",
    "            \n",
    "            # get X dataset\n",
    "            x_onehot = get_onehots(positivity[x_var], columns = x_cat, for_onehot = for_onehot)\n",
    "            x_features = list(x_onehot.columns)\n",
    "            \n",
    "            # get Y dataset\n",
    "            y_onehot = get_onehots(positivity[y_var], columns = y_cat, for_onehot = for_onehot)\n",
    "            y_labels = list(y_onehot.columns)\n",
    "            \n",
    "            for idx in ST_idx:\n",
    "                window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "                window_x = window_x.reshape(-1)\n",
    "                label_y  = np.array(y_onehot.iloc[idx])\n",
    "                \n",
    "                data_x.append(window_x)\n",
    "                data_y.append(label_y)\n",
    "                \n",
    "        data_x = np.array(data_x)\n",
    "        data_y = np.array(data_y)\n",
    "        model = MLP_CLS(data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "        print('data x shape:', data_x.shape)\n",
    "        print('data y shape:', data_y.shape)\n",
    "        print('class y counts:', data_y.sum(0))\n",
    "        print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "        \n",
    "        splitter = StratifiedShuffleSplit(n_splits = 1, test_size = test_size, random_state = SEED)\n",
    "        train_idx, test_idx = list(splitter.split(data_x, data_y))[0]\n",
    "        \n",
    "        train_x = data_x[train_idx]\n",
    "        train_y = data_y[train_idx]\n",
    "        \n",
    "        test_x = data_x[test_idx]\n",
    "        test_y = data_y[test_idx]\n",
    "        \n",
    "        train_x, test_x = data_scaling(train_x, test_x)\n",
    "        \n",
    "        splitter_kf = KFold(n_splits = 5)\n",
    "        for cv_idx, (train_idx_kf, test_idx_kf) in enumerate(splitter_kf.split(train_x, train_y)):\n",
    "            train_x_kf, train_y_kf = train_x[train_idx_kf], train_y[train_idx_kf]\n",
    "            train_x_kf, train_y_kf = upsample_data(train_x_kf, train_y_kf) # up-sample the training dataset\n",
    "            test_x_kf, test_y_kf = train_x[test_idx_kf], train_y[test_idx_kf]\n",
    "            \n",
    "            model = MLP_CLS(data_x.shape[-1], data_y.shape[-1], params) \n",
    "            model_name = name_model(f'{model_type}_KFOLD', params)\n",
    "            \n",
    "            \n",
    "            model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "            if not os.path.exists(model_folder):\n",
    "                os.makedirs(model_folder)\n",
    "            model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "            metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(model_path) or model_update:\n",
    "                time_start = time.time()\n",
    "                history = model.fit(train_x_kf, train_y_kf, verbose=verbose, \n",
    "                                    epochs = 10000, callbacks = callbacks,\n",
    "                                    validation_data = (test_x_kf, test_y_kf))\n",
    "                time_end = time.time()\n",
    "                training_time = round((time_end - time_start)/60, 3)\n",
    "                \n",
    "                model.save_weights(model_path)\n",
    "                \n",
    "                test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "                model_metrics = {\n",
    "                    'model_id' : model_id,\n",
    "                    'cv_idx'   : cv_idx,\n",
    "                    **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "                    'train_y'     : train_y.shape[-1],\n",
    "                    'test_size'   : test_x.shape[0],\n",
    "                    **params,\n",
    "                    'regularizer_input' : params['regularizer']['input'],\n",
    "                    'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "                    'regularizer_bias' : params['regularizer']['bias'],\n",
    "                    'training_time': training_time,\n",
    "                    'test_loss': test_loss,\n",
    "                    'accuracy': accuracy,\n",
    "                    **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "                    **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "                    **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "                \n",
    "                model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "                model_metrics.to_csv(metric_path, index=False)\n",
    "                \n",
    "            else:\n",
    "                model.load_weights(model_path)\n",
    "                model_metrics = pd.read_csv(metric_path, header=0)\n",
    "                \n",
    "            print(f'f1 score: {model_metrics.f1_1[0]:.3f}')\n",
    "            \n",
    "            model_metrics['model_id'] = model_id\n",
    "            METRICs.append(model_metrics)\n",
    "            MODELs.append(model)\n",
    "        \n",
    "        METRIC_MEAN = pd.concat(METRICs).groupby('model_id').mean()\n",
    "        f1_best = METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0].f1_1\n",
    "        print(f'best f1 score: {f1_best}')\n",
    "        model_id += 1\n",
    "    if param_name in ['learning_rate']: # for float-type parameters\n",
    "        best_value = float(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "    else: # for int-type parameters\n",
    "        best_value = int(METRIC_MEAN.sort_values('f1_1', ascending=False).iloc[0][param_name])\n",
    "        params[param_name] = best_value\n",
    "        search_space[param_name][search_space[param_name].index(best_value)] = f\"{best_value}\"\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(METRIC_MEAN)\n",
    "for key, value in search_space.items():\n",
    "    print(f'{key:<14} : {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape:  (11858, 420)\n",
      "data y shape:  (11858, 2)\n",
      "train x shape: (9486, 420)\n",
      "test  x shape: (2372, 2)\n"
     ]
    }
   ],
   "source": [
    "print('data x shape: ', data_x.shape)\n",
    "print('data y shape: ', data_y.shape)\n",
    "print('train x shape:', train_x.shape)\n",
    "print('test  x shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755e958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "rnn_layers     : 1\n",
      "rnn_neurons    : 64\n",
      "dnn_layers     : 1\n",
      "dnn_neurons    : 64\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.0001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "for key, value in params.items():\n",
    "    print(f'{key:<14} : {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ff058",
   "metadata": {},
   "source": [
    "## evaluate model's general performance through Monte-Carlo cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05807f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x shape: (11858, 420)\n",
      "data y shape: (11858, 2)\n",
      "class y counts: [11429   429]\n",
      "class y ratio: [0.9638 0.0362]\n",
      "f1 score: 11.570\n",
      "f1 score: 13.080\n",
      "f1 score: 12.960\n",
      "f1 score: 11.710\n",
      "f1 score: 13.910\n"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update = False\n",
    "            \n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "verbose = 0\n",
    "        \n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for protein_name in positivity_data:\n",
    "    positivity = positivity_data.get(protein_name)\n",
    "    ST_idx = np.where((positivity['residue'] == 'S') | (positivity['residue'] == 'T'))[0]\n",
    "    \n",
    "    # get X dataset\n",
    "    x_onehot = get_onehots(positivity[x_var], columns = x_cat, for_onehot = for_onehot)\n",
    "    x_features = list(x_onehot.columns)\n",
    "    \n",
    "    # get Y dataset\n",
    "    y_onehot = get_onehots(positivity[y_var], columns = y_cat, for_onehot = for_onehot)\n",
    "    y_labels = list(y_onehot.columns)\n",
    "    \n",
    "    for idx in ST_idx:\n",
    "        window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "        window_x = window_x.reshape(-1)\n",
    "        label_y  = np.array(y_onehot.iloc[idx])\n",
    "        \n",
    "        data_x.append(window_x)\n",
    "        data_y.append(label_y)\n",
    "        \n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "\n",
    "print('data x shape:', data_x.shape)\n",
    "print('data y shape:', data_y.shape)\n",
    "print('class y counts:', data_y.sum(0))\n",
    "print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits = 5, test_size = test_size, random_state = SEED)\n",
    "for cv_idx, (train_idx, test_idx) in enumerate(splitter.split(data_x, data_y)):\n",
    "    train_x, train_y = data_x[train_idx], data_y[train_idx]\n",
    "    train_x, train_y = upsample_data(train_x, train_y) # up-sample the training dataset\n",
    "    test_x , test_y  = data_x[test_idx],  data_y[test_idx]\n",
    "    \n",
    "    train_x, test_x = data_scaling(train_x, test_x)\n",
    "    \n",
    "    model = MLP_CLS(data_x.shape[-1], data_y.shape[-1], params)\n",
    "    model_name = name_model(f'{model_type}', params)\n",
    "    \n",
    "    \n",
    "    model_folder  = f'./models/{model_name}_{train_x.shape}_{test_x.shape}'\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "    model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "    metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(model_path) or model_update:\n",
    "        time_start = time.time()\n",
    "        history = model.fit(train_x, train_y, verbose=verbose, \n",
    "                            epochs = 10000, callbacks = callbacks,\n",
    "                            validation_split = test_size/(1-test_size))\n",
    "        time_end = time.time()\n",
    "        training_time = round((time_end - time_start)/60, 3)\n",
    "        \n",
    "        model.save_weights(model_path)\n",
    "        \n",
    "        test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "        model_metrics = {\n",
    "            'model_id' : model_id,\n",
    "            'cv_idx'   : cv_idx,\n",
    "            **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "            'train_y'     : train_y.shape[-1],\n",
    "            'test_size'   : test_x.shape[0],\n",
    "            **params,\n",
    "            'regularizer_input' : params['regularizer']['input'],\n",
    "            'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "            'regularizer_bias' : params['regularizer']['bias'],\n",
    "            'training_time': training_time,\n",
    "            'test_loss': test_loss,\n",
    "            'accuracy': accuracy,\n",
    "            **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "            **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "            **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "        model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "        model_metrics.to_csv(metric_path, index=False)\n",
    "        \n",
    "    else:\n",
    "        model.load_weights(model_path)\n",
    "        model_metrics = pd.read_csv(metric_path, header=0)\n",
    "        \n",
    "    print(f'f1 score: {model_metrics.f1_1[0]:.3f}')\n",
    "    \n",
    "    METRICs.append(model_metrics)\n",
    "    MODELs.append(model)\n",
    "\n",
    "METRICs = pd.concat(METRICs)\n",
    "METRIC_MEAN = METRICs.groupby('model_id').mean()\n",
    "METRIC_STD = METRICs.groupby('model_id').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b460f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_0</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_y</th>\n",
       "      <th>test_size</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>rnn_neurons</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>dnn_neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>regularizer_bias</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>18286</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>2372</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.527061</td>\n",
       "      <td>75.51</td>\n",
       "      <td>97.33</td>\n",
       "      <td>6.65</td>\n",
       "      <td>76.68</td>\n",
       "      <td>44.19</td>\n",
       "      <td>85.78</td>\n",
       "      <td>11.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>18286</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>2372</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.550626</td>\n",
       "      <td>73.10</td>\n",
       "      <td>97.80</td>\n",
       "      <td>7.41</td>\n",
       "      <td>73.75</td>\n",
       "      <td>55.81</td>\n",
       "      <td>84.09</td>\n",
       "      <td>13.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>18286</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>2372</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.119</td>\n",
       "      <td>0.570571</td>\n",
       "      <td>73.95</td>\n",
       "      <td>97.71</td>\n",
       "      <td>7.37</td>\n",
       "      <td>74.72</td>\n",
       "      <td>53.49</td>\n",
       "      <td>84.68</td>\n",
       "      <td>12.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>18286</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>2372</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.283</td>\n",
       "      <td>0.568303</td>\n",
       "      <td>76.48</td>\n",
       "      <td>97.32</td>\n",
       "      <td>6.78</td>\n",
       "      <td>77.73</td>\n",
       "      <td>43.02</td>\n",
       "      <td>86.43</td>\n",
       "      <td>11.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>18286</td>\n",
       "      <td>420</td>\n",
       "      <td>2</td>\n",
       "      <td>2372</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.123</td>\n",
       "      <td>0.551692</td>\n",
       "      <td>74.96</td>\n",
       "      <td>97.85</td>\n",
       "      <td>7.95</td>\n",
       "      <td>75.68</td>\n",
       "      <td>55.81</td>\n",
       "      <td>85.35</td>\n",
       "      <td>13.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id  cv_idx  train_0  train_1  train_y  test_size  rnn_layers  \\\n",
       "0        13       0    18286      420        2       2372           1   \n",
       "0        13       1    18286      420        2       2372           1   \n",
       "0        13       2    18286      420        2       2372           1   \n",
       "0        13       3    18286      420        2       2372           1   \n",
       "0        13       4    18286      420        2       2372           1   \n",
       "\n",
       "   rnn_neurons  dnn_layers  dnn_neurons  ...  regularizer_bias  training_time  \\\n",
       "0           64           1           64  ...               NaN          0.781   \n",
       "0           64           1           64  ...               NaN          0.777   \n",
       "0           64           1           64  ...               NaN          2.119   \n",
       "0           64           1           64  ...               NaN          2.283   \n",
       "0           64           1           64  ...               NaN          3.123   \n",
       "\n",
       "   test_loss  accuracy  precision_0  precision_1  recall_0  recall_1   f1_0  \\\n",
       "0   0.527061     75.51        97.33         6.65     76.68     44.19  85.78   \n",
       "0   0.550626     73.10        97.80         7.41     73.75     55.81  84.09   \n",
       "0   0.570571     73.95        97.71         7.37     74.72     53.49  84.68   \n",
       "0   0.568303     76.48        97.32         6.78     77.73     43.02  86.43   \n",
       "0   0.551692     74.96        97.85         7.95     75.68     55.81  85.35   \n",
       "\n",
       "    f1_1  \n",
       "0  11.57  \n",
       "0  13.08  \n",
       "0  12.96  \n",
       "0  11.71  \n",
       "0  13.91  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ab902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_0</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_y</th>\n",
       "      <th>test_size</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>rnn_neurons</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>dnn_neurons</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>regularizer_bias</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18286.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8166</td>\n",
       "      <td>0.55365</td>\n",
       "      <td>74.8</td>\n",
       "      <td>97.602</td>\n",
       "      <td>7.232</td>\n",
       "      <td>75.712</td>\n",
       "      <td>50.464</td>\n",
       "      <td>85.266</td>\n",
       "      <td>12.646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cv_idx  train_0  train_1  train_y  test_size  rnn_layers  \\\n",
       "model_id                                                             \n",
       "13           2.0  18286.0    420.0      2.0     2372.0         1.0   \n",
       "\n",
       "          rnn_neurons  dnn_layers  dnn_neurons  learning_rate  ...  \\\n",
       "model_id                                                       ...   \n",
       "13               64.0         1.0         64.0         0.0001  ...   \n",
       "\n",
       "          regularizer_bias  training_time  test_loss  accuracy  precision_0  \\\n",
       "model_id                                                                      \n",
       "13                     NaN         1.8166    0.55365      74.8       97.602   \n",
       "\n",
       "          precision_1  recall_0  recall_1    f1_0    f1_1  \n",
       "model_id                                                   \n",
       "13              7.232    75.712    50.464  85.266  12.646  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRIC_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54124b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_0</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_y</th>\n",
       "      <th>test_size</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>rnn_neurons</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>dnn_neurons</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>regularizer_bias</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.020893</td>\n",
       "      <td>0.017471</td>\n",
       "      <td>1.319526</td>\n",
       "      <td>0.257818</td>\n",
       "      <td>0.526612</td>\n",
       "      <td>1.568748</td>\n",
       "      <td>6.346107</td>\n",
       "      <td>0.915494</td>\n",
       "      <td>0.989763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cv_idx  train_0  train_1  train_y  test_size  rnn_layers  \\\n",
       "model_id                                                               \n",
       "13        1.581139      0.0      0.0      0.0        0.0         0.0   \n",
       "\n",
       "          rnn_neurons  dnn_layers  dnn_neurons  learning_rate  ...  \\\n",
       "model_id                                                       ...   \n",
       "13                0.0         0.0          0.0            0.0  ...   \n",
       "\n",
       "          regularizer_bias  training_time  test_loss  accuracy  precision_0  \\\n",
       "model_id                                                                      \n",
       "13                     NaN       1.020893   0.017471  1.319526     0.257818   \n",
       "\n",
       "          precision_1  recall_0  recall_1      f1_0      f1_1  \n",
       "model_id                                                       \n",
       "13           0.526612  1.568748  6.346107  0.915494  0.989763  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRIC_STD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
